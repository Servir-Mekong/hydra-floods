{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the HYDRAFloods Documentation The Hydrologic Remote Sensing Analysis for Floods (or HYDRAFloods) is an open source Python application for downloading, processing, and delivering surface water maps derived from remote sensing data. The basis behind the tool is to provide sensor agnostic approaches to produce surface water maps. Furthermore, there are workflows that leverage multiple remote sensing dataset in conjunction to provide daily surface water maps for flood application. The HYDRAFloods application is built using Google Earth Engine and Google Cloud Platform (GCP) to leverage cloud computing for large-scale computations and handling high data volume outputs. The goal of the package is to allow users access to high-quality, cloud-based surface water mapping algorithms with minimal effort. To achieve this goal, hydrafloods provides a high-level API on top of the Earth Engine Python API to reduce code duplication, such as filtering or carrying metadata for image processing, and provide complex surface water algorithms. Furthermore, the package provides some GCP functionality to read and transfer data to be used within Earth Engine. Quick Start To highlight a quick example of the hydrafloods API and simplicity to produce high-quality surface water maps we provide a quick example of mapping surface water using Sentinel-1 over the confluence of the Mekong and Tonle Sap rivers in Cambodia, which experiences frequent flooding. # content of example.py Python file # import the hydrafloods and ee package import hydrafloods as hf import ee ee . Initialize () # specify start and end time as well as geographic region to process start_time = \"2019-10-05\" end_time = \"2019-10-06\" region = ee . Geometry . Rectangle ([ 104 , 11.5 , 106 , 12.5 ]) # get the Sentinel-1 collection # the hf.dataset classes performs the spatial-temporal filtering for you s1 = hf . datasets . Sentinel1 ( region , start_time , end_time ) # apply a water mapping function to the S1 dataset # this applies the \"Edge Otsu\" algorithm from https://doi.org/10.3390/rs12152469 water_imgs = s1 . apply_func ( hf . thresholding . edge_otsu , initial_threshold =- 14 , edge_buffer = 300 ) # take the mode from multiple images # since this is just imagery from one day, it will simply mosaic the images water_map = ee . Image ( water_imgs . collection . mode ()) # export the water map hf . geeutils . export_image ( water_map , region , \"users/<YOUR_USERNAME>/water_map_example\" , scale = 30 , ) (This script is complete, it should run \"as is\") At the end of the script execution, there will be an Earth Engine export task running the process on the EE servers for use later in the EE platform. The resulting surface water image should look like the following figure. It should be noted that hydrafloods can scale quickly and easily by simply changing the start or end time and region to process, allowing for processing of surface water maps with minimal effort in terms of coding. Figure 1. Sentinel-1 backscatter image (left) and resulting surface water map (right) from 2019-10-05 for a region in Cambodia as in the example. Learn more about how to use the package for processing see Getting Start in the docs. Get in touch Report bugs, suggest features or view the source code on GitHub . Contact us through a Technical Assistance Request and mention \"hydrafloods\" Contribute Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. Please see the Contributing Guidelines for details on where to contribute and how to get started. License hydrafloods is available under the open source GNU General Public License v3.0 .","title":"Overview"},{"location":"#welcome-to-the-hydrafloods-documentation","text":"The Hydrologic Remote Sensing Analysis for Floods (or HYDRAFloods) is an open source Python application for downloading, processing, and delivering surface water maps derived from remote sensing data. The basis behind the tool is to provide sensor agnostic approaches to produce surface water maps. Furthermore, there are workflows that leverage multiple remote sensing dataset in conjunction to provide daily surface water maps for flood application. The HYDRAFloods application is built using Google Earth Engine and Google Cloud Platform (GCP) to leverage cloud computing for large-scale computations and handling high data volume outputs. The goal of the package is to allow users access to high-quality, cloud-based surface water mapping algorithms with minimal effort. To achieve this goal, hydrafloods provides a high-level API on top of the Earth Engine Python API to reduce code duplication, such as filtering or carrying metadata for image processing, and provide complex surface water algorithms. Furthermore, the package provides some GCP functionality to read and transfer data to be used within Earth Engine.","title":"Welcome to the HYDRAFloods Documentation"},{"location":"#quick-start","text":"To highlight a quick example of the hydrafloods API and simplicity to produce high-quality surface water maps we provide a quick example of mapping surface water using Sentinel-1 over the confluence of the Mekong and Tonle Sap rivers in Cambodia, which experiences frequent flooding. # content of example.py Python file # import the hydrafloods and ee package import hydrafloods as hf import ee ee . Initialize () # specify start and end time as well as geographic region to process start_time = \"2019-10-05\" end_time = \"2019-10-06\" region = ee . Geometry . Rectangle ([ 104 , 11.5 , 106 , 12.5 ]) # get the Sentinel-1 collection # the hf.dataset classes performs the spatial-temporal filtering for you s1 = hf . datasets . Sentinel1 ( region , start_time , end_time ) # apply a water mapping function to the S1 dataset # this applies the \"Edge Otsu\" algorithm from https://doi.org/10.3390/rs12152469 water_imgs = s1 . apply_func ( hf . thresholding . edge_otsu , initial_threshold =- 14 , edge_buffer = 300 ) # take the mode from multiple images # since this is just imagery from one day, it will simply mosaic the images water_map = ee . Image ( water_imgs . collection . mode ()) # export the water map hf . geeutils . export_image ( water_map , region , \"users/<YOUR_USERNAME>/water_map_example\" , scale = 30 , ) (This script is complete, it should run \"as is\") At the end of the script execution, there will be an Earth Engine export task running the process on the EE servers for use later in the EE platform. The resulting surface water image should look like the following figure. It should be noted that hydrafloods can scale quickly and easily by simply changing the start or end time and region to process, allowing for processing of surface water maps with minimal effort in terms of coding. Figure 1. Sentinel-1 backscatter image (left) and resulting surface water map (right) from 2019-10-05 for a region in Cambodia as in the example. Learn more about how to use the package for processing see Getting Start in the docs.","title":"Quick Start"},{"location":"#get-in-touch","text":"Report bugs, suggest features or view the source code on GitHub . Contact us through a Technical Assistance Request and mention \"hydrafloods\"","title":"Get in touch"},{"location":"#contribute","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. Please see the Contributing Guidelines for details on where to contribute and how to get started.","title":"Contribute"},{"location":"#license","text":"hydrafloods is available under the open source GNU General Public License v3.0 .","title":"License"},{"location":"algorithms/","text":"Here are a more in depth examples of specific algorithms for surface water mapping workflows that are implemented within hydrafloods that users can call. It is expected that the code is run in an interactive python session such as IPython or in a Jupyter Notebook as later code blocks will use variables from previous ones. import ee ee . Initialize () import hydrafloods as hf SAR Speckle Filtering Algorithms SAR imagery is affected by artifacts called Speckle. Speckle looks like granular noise in synthetic aperture radar (SAR) data and is due to the interference of radar waves reflected from many elementary scatterers on the ground. Speckle in SAR imagery typically reduces the accuracy of image segmentation and classification so applying speckle filters is a common preprocessing step ( Lee et al., 2009 ). Multiple algorithms have been developed by the scientific community to alleviate the effects of Speckle in subsequent SAR image processing. hydrafloods has implemented a few of these Speckle filter algorithms in the package to help effectively use SAR imagery for image processing, in this case for surface water mapping. Here is a list of Speckle filter algorithms available: Lee Sigma: hydrafloods.lee_sigma ( Lee et al., 2008 ) Gamma Map: hydrafloods.gamma_map ( Beauchemin et al., 1995 ) Refined Lee: hydrafloods.refined_lee ( Lee, 1981 ) Here is a brief example of how one might apply these algorithms to SAR data using hydrafloods : # define a geographic region region = hf . country_bbox ( \"Cambodia\" ) # define start and end times start_time = \"2019-09-15\" end_time = \"2019-09-20\" # get the Sentinel 1 collection as a Dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) After we have our SAR collection, we can apply the functions on the image using the apply_func() method. Since these algorithms take an image as input and output and image we can easily apply on all imagery. Watch out though...some of these algorithms (specifically refined_lee() ) are extremely memory intensive and you will likely get a \"User memory limit exceeded\" error when applying over many (25+) images. In this case, it will work since we are only applying over a few images. lee_sigma_filtered = ( s1 . apply_func ( hf . lee_sigma ) . collection . first () ) gamma_map_filtered = ( s1 . apply_func ( hf . gamma_map ) . collection . first () ) refined_lee_filtered = ( s1 . apply_func ( hf . refined_lee ) . collection . first () ) original = s1 . collection . first () zoom_region = [ 104.60 , 15.10 , 104.95 , 15.35 ] viz_params = { \"min\" : - 25 , \"max\" : 0 , \"bands\" : \"VV\" , \"region\" : zoom_region , \"dimensions\" : 2000 , \"crs\" : \"epsg:4326\" } print ( original . getThumbURL ( viz_params )) print ( lee_sigma_filtered . getThumbURL ( viz_params )) print ( gamma_map_filtered . getThumbURL ( viz_params )) print ( refined_lee_filtered . getThumbURL ( viz_params )) Try opening the examples in a new tab to zoom in and really see the differences Original Lee Sigma filter Gamma Map filter Refined Lee filter For more information on the filtering algorithms and the specific arguments, please see the filtering module API reference Correction Algorithms Another common workflow when working with satelitte imagery is to correct for atmospheric and terrain effects. Most of the data collection on Earth Engine have atmospherically corrected data so hydrafloods has focused on correction algorithms for terrain (both SAR and optical) correction and a bidirectional reflectance distribution function (BRDF) correction for optical imagery. To begin, let's import the corrections module. For demonstrational purposes, we will focus on terrain flattening in Nepal, one of the most mountainous regions in the world! from hydrafloods import corrections region = hf . country_bbox ( \"Nepal\" ) start_time = \"2020-10-29\" end_time = \"2020-11-08\" Applying illumination correction on optical imagery # get landsat 8 dataset ls = hf . Landsat8 ( region , start_time , end_time ) # define the elevation dataset we want to calculate corrections from elv = ee . Image ( \"JAXA/ALOS/AW3D30/V2_2\" ) . select ( \"AVE_DSM\" ) # apply the illumination correction on every image in dataset ls_flat = ls . apply_func ( corrections . illumination_correction , elevation = elv ) # region to visualize view_box = ee . Geometry . Rectangle ([ 86.1177 , 27.1325 , 86.8716 , 27.5984 ]) vis_params = { \"bands\" : \"swir2,nir,green\" , \"min\" : 50 , \"max\" : 5500 , \"gamma\" : 1.5 , \"region\" : view_box , \"dimensions\" : 1500 } # reduce the datasets to an image for visualization original_img = ls . collection . median () corrected_img = ls_flat . collection . median () print ( original_img . getThumbURL ( vis_params )) print ( corrected_img . getThumbURL ( vis_params )) Original Landsat 8 Image Corrected Landsat 8 Image We can see that the algorithm corrected the poorly illuminated areas. This function is valid for both the Landsat8 and Sentinel2 imagery. More information on the illumination correction algorithm and the input arguments can be found at the corrections module page Applying slope correction on SAR imagery SAR imagery is fairly sensitive to terrain effects due to the signal being geometric in nature. Here we apply a slope correction algorithm developed by Vollrath et al., 2020 to reduce the effects of terrain on the data. This method however does not fully compensate for the radiometric distortions as compared to more advanced methods but still provides some correction. # get a Sentinel 1 dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) # apply slope correction on every image in collection s1_flat = s1 . apply_func ( corrections . slope_correction , elevation = elv , buffer = 30 ) # inspect the resulting bands VV and VH will have '_flat' appended print ( s1_flat . collection . first () . bandNames () . getInfo ()) # should equal ['VV_flat', 'VH_flat', 'angle', 'local_inc_angle'] vis_params = { \"bands\" : \"VV\" , \"min\" : - 25 , \"max\" : 0 , \"region\" : view_box , \"dimensions\" : 1500 } # get an image from original collection and flattened for visualization # note here we are getting a mosaic (i.e. first valid pixel) to prevent # visualization artifacts from ascending vs descending paths in dataset original_img = s1 . collection . mosaic () corrected_img = s1_flat . collection . mosaic () print ( original_img . getThumbURL ( vis_params )) print ( corrected_img . getThumbURL ( vis_params )) Original Sentinel 1 Image Corrected Sentinel 1 Image We can see that the effects of terrain are mostly removed. Note: the slope correction algorithm calculates area of terrain shadow and layover (i.e. areas that cannot be corrected) and mask those area, hince some transparent areas. More documentation regarding the slope correction algorithm and the input arguments can be found at the corrections module page Generic Water Mapping Algorithms The goal of hydrafloods is to provide efficient, easily accessible surface water maps. To that end, there are a few generic surface water mapping algorithms available that can be used with virtually any dataset (given some customization of parameters). Here is a list of the water mapping algorithms available: Edge Otsu: hydrafloods.edge_otsu ( Donchyts et al., 2016 ; Markert et al., 2020 ) Bmax Otsu: hydrafloods.bmax_otsu ( Cao et al.,2019 ; Markert et al., 2020 ) KMeans Extent: hydrafloods.kmeans_extent ( Chang et al., 2020 ) To begin, we will access optical and SAR data for a coincident time period following the example from Using Datasets : # area where overlap is known region = ee . Geometry . Rectangle ([ 103.6334 , 12.4368 , 104.8419 , 13.2615 ]) # month where we know coincident data start_time = \"2019-02-01\" end_time = \"2019-03-01\" # get Landsat 8 dataset lc8 = hf . Landsat8 ( region , start_time , end_time ) # add the mndwi water index to the lc8 dataset lc8 = lc8 . apply_func ( hf . add_indices , indices = [ \"mndwi\" ]) # get Sentinel 1 dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) # apply gamma map speckle filter s1 = s1 . apply_func ( hf . gamma_map ) # join the two datasets joined = lc8 . join ( s1 ) # create a composite image for the region composite = joined . collection . median () # define some visualization parameters to use water_viz = { \"min\" : 0 , \"max\" : 1 , \"palette\" : \"silver,navy\" , \"region\" : region , \"dimensions\" : 2000 } optical_viz = { \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"region\" : region , \"dimensions\" : 2000 } sar_viz = { \"min\" : - 25 , \"max\" : 0 , \"bands\" : \"VV\" , \"region\" : region , \"dimensions\" : 2000 } Now that we have our data here we will highlight how to use some generic surface water mapping algorithms, specifically the edge_otsu() algorithm: # apply the edge otsu algorithm on the MNDWI optical index optical_water = hf . edge_otsu ( composite , region = region , band = \"mndwi\" , initial_threshold = 0 , thresh_no_data =- 0.2 , edge_buffer = 300 , invert = True ) # apply edge otsu algorithm on the VV SAR band sar_water = hf . edge_otsu ( composite , region = region , band = \"VV\" , initial_threshold =- 16 , thresh_no_data =- 20 , edge_buffer = 300 ) # get thumb urls of results print ( composite . getThumbURL ( optical_viz )) print ( composite . getThumbURL ( sar_viz )) print ( optical_water . getThumbURL ( water_viz )) print ( sar_water . getThumbURL ( water_viz )) Landsat 8 Image SAR Image Landsat 8 Water Map SAR Water Map This is just one example of surface water mapping and there are additional water mapping algorithms as mentioned above. More documentation regarding the water mapping functions and the input arguments can be found at the thresholding module If there are other algorithms you would like to see in the hydrafloods package, please file an issue with specifics (and hopefully a link to the paper) on our GitHub repo.","title":"Algorithms"},{"location":"algorithms/#sar-speckle-filtering-algorithms","text":"SAR imagery is affected by artifacts called Speckle. Speckle looks like granular noise in synthetic aperture radar (SAR) data and is due to the interference of radar waves reflected from many elementary scatterers on the ground. Speckle in SAR imagery typically reduces the accuracy of image segmentation and classification so applying speckle filters is a common preprocessing step ( Lee et al., 2009 ). Multiple algorithms have been developed by the scientific community to alleviate the effects of Speckle in subsequent SAR image processing. hydrafloods has implemented a few of these Speckle filter algorithms in the package to help effectively use SAR imagery for image processing, in this case for surface water mapping. Here is a list of Speckle filter algorithms available: Lee Sigma: hydrafloods.lee_sigma ( Lee et al., 2008 ) Gamma Map: hydrafloods.gamma_map ( Beauchemin et al., 1995 ) Refined Lee: hydrafloods.refined_lee ( Lee, 1981 ) Here is a brief example of how one might apply these algorithms to SAR data using hydrafloods : # define a geographic region region = hf . country_bbox ( \"Cambodia\" ) # define start and end times start_time = \"2019-09-15\" end_time = \"2019-09-20\" # get the Sentinel 1 collection as a Dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) After we have our SAR collection, we can apply the functions on the image using the apply_func() method. Since these algorithms take an image as input and output and image we can easily apply on all imagery. Watch out though...some of these algorithms (specifically refined_lee() ) are extremely memory intensive and you will likely get a \"User memory limit exceeded\" error when applying over many (25+) images. In this case, it will work since we are only applying over a few images. lee_sigma_filtered = ( s1 . apply_func ( hf . lee_sigma ) . collection . first () ) gamma_map_filtered = ( s1 . apply_func ( hf . gamma_map ) . collection . first () ) refined_lee_filtered = ( s1 . apply_func ( hf . refined_lee ) . collection . first () ) original = s1 . collection . first () zoom_region = [ 104.60 , 15.10 , 104.95 , 15.35 ] viz_params = { \"min\" : - 25 , \"max\" : 0 , \"bands\" : \"VV\" , \"region\" : zoom_region , \"dimensions\" : 2000 , \"crs\" : \"epsg:4326\" } print ( original . getThumbURL ( viz_params )) print ( lee_sigma_filtered . getThumbURL ( viz_params )) print ( gamma_map_filtered . getThumbURL ( viz_params )) print ( refined_lee_filtered . getThumbURL ( viz_params )) Try opening the examples in a new tab to zoom in and really see the differences Original Lee Sigma filter Gamma Map filter Refined Lee filter For more information on the filtering algorithms and the specific arguments, please see the filtering module API reference","title":"SAR Speckle Filtering Algorithms"},{"location":"algorithms/#correction-algorithms","text":"Another common workflow when working with satelitte imagery is to correct for atmospheric and terrain effects. Most of the data collection on Earth Engine have atmospherically corrected data so hydrafloods has focused on correction algorithms for terrain (both SAR and optical) correction and a bidirectional reflectance distribution function (BRDF) correction for optical imagery. To begin, let's import the corrections module. For demonstrational purposes, we will focus on terrain flattening in Nepal, one of the most mountainous regions in the world! from hydrafloods import corrections region = hf . country_bbox ( \"Nepal\" ) start_time = \"2020-10-29\" end_time = \"2020-11-08\"","title":"Correction Algorithms"},{"location":"algorithms/#applying-illumination-correction-on-optical-imagery","text":"# get landsat 8 dataset ls = hf . Landsat8 ( region , start_time , end_time ) # define the elevation dataset we want to calculate corrections from elv = ee . Image ( \"JAXA/ALOS/AW3D30/V2_2\" ) . select ( \"AVE_DSM\" ) # apply the illumination correction on every image in dataset ls_flat = ls . apply_func ( corrections . illumination_correction , elevation = elv ) # region to visualize view_box = ee . Geometry . Rectangle ([ 86.1177 , 27.1325 , 86.8716 , 27.5984 ]) vis_params = { \"bands\" : \"swir2,nir,green\" , \"min\" : 50 , \"max\" : 5500 , \"gamma\" : 1.5 , \"region\" : view_box , \"dimensions\" : 1500 } # reduce the datasets to an image for visualization original_img = ls . collection . median () corrected_img = ls_flat . collection . median () print ( original_img . getThumbURL ( vis_params )) print ( corrected_img . getThumbURL ( vis_params )) Original Landsat 8 Image Corrected Landsat 8 Image We can see that the algorithm corrected the poorly illuminated areas. This function is valid for both the Landsat8 and Sentinel2 imagery. More information on the illumination correction algorithm and the input arguments can be found at the corrections module page","title":"Applying illumination correction on optical imagery"},{"location":"algorithms/#applying-slope-correction-on-sar-imagery","text":"SAR imagery is fairly sensitive to terrain effects due to the signal being geometric in nature. Here we apply a slope correction algorithm developed by Vollrath et al., 2020 to reduce the effects of terrain on the data. This method however does not fully compensate for the radiometric distortions as compared to more advanced methods but still provides some correction. # get a Sentinel 1 dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) # apply slope correction on every image in collection s1_flat = s1 . apply_func ( corrections . slope_correction , elevation = elv , buffer = 30 ) # inspect the resulting bands VV and VH will have '_flat' appended print ( s1_flat . collection . first () . bandNames () . getInfo ()) # should equal ['VV_flat', 'VH_flat', 'angle', 'local_inc_angle'] vis_params = { \"bands\" : \"VV\" , \"min\" : - 25 , \"max\" : 0 , \"region\" : view_box , \"dimensions\" : 1500 } # get an image from original collection and flattened for visualization # note here we are getting a mosaic (i.e. first valid pixel) to prevent # visualization artifacts from ascending vs descending paths in dataset original_img = s1 . collection . mosaic () corrected_img = s1_flat . collection . mosaic () print ( original_img . getThumbURL ( vis_params )) print ( corrected_img . getThumbURL ( vis_params )) Original Sentinel 1 Image Corrected Sentinel 1 Image We can see that the effects of terrain are mostly removed. Note: the slope correction algorithm calculates area of terrain shadow and layover (i.e. areas that cannot be corrected) and mask those area, hince some transparent areas. More documentation regarding the slope correction algorithm and the input arguments can be found at the corrections module page","title":"Applying slope correction on SAR imagery"},{"location":"algorithms/#generic-water-mapping-algorithms","text":"The goal of hydrafloods is to provide efficient, easily accessible surface water maps. To that end, there are a few generic surface water mapping algorithms available that can be used with virtually any dataset (given some customization of parameters). Here is a list of the water mapping algorithms available: Edge Otsu: hydrafloods.edge_otsu ( Donchyts et al., 2016 ; Markert et al., 2020 ) Bmax Otsu: hydrafloods.bmax_otsu ( Cao et al.,2019 ; Markert et al., 2020 ) KMeans Extent: hydrafloods.kmeans_extent ( Chang et al., 2020 ) To begin, we will access optical and SAR data for a coincident time period following the example from Using Datasets : # area where overlap is known region = ee . Geometry . Rectangle ([ 103.6334 , 12.4368 , 104.8419 , 13.2615 ]) # month where we know coincident data start_time = \"2019-02-01\" end_time = \"2019-03-01\" # get Landsat 8 dataset lc8 = hf . Landsat8 ( region , start_time , end_time ) # add the mndwi water index to the lc8 dataset lc8 = lc8 . apply_func ( hf . add_indices , indices = [ \"mndwi\" ]) # get Sentinel 1 dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) # apply gamma map speckle filter s1 = s1 . apply_func ( hf . gamma_map ) # join the two datasets joined = lc8 . join ( s1 ) # create a composite image for the region composite = joined . collection . median () # define some visualization parameters to use water_viz = { \"min\" : 0 , \"max\" : 1 , \"palette\" : \"silver,navy\" , \"region\" : region , \"dimensions\" : 2000 } optical_viz = { \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"region\" : region , \"dimensions\" : 2000 } sar_viz = { \"min\" : - 25 , \"max\" : 0 , \"bands\" : \"VV\" , \"region\" : region , \"dimensions\" : 2000 } Now that we have our data here we will highlight how to use some generic surface water mapping algorithms, specifically the edge_otsu() algorithm: # apply the edge otsu algorithm on the MNDWI optical index optical_water = hf . edge_otsu ( composite , region = region , band = \"mndwi\" , initial_threshold = 0 , thresh_no_data =- 0.2 , edge_buffer = 300 , invert = True ) # apply edge otsu algorithm on the VV SAR band sar_water = hf . edge_otsu ( composite , region = region , band = \"VV\" , initial_threshold =- 16 , thresh_no_data =- 20 , edge_buffer = 300 ) # get thumb urls of results print ( composite . getThumbURL ( optical_viz )) print ( composite . getThumbURL ( sar_viz )) print ( optical_water . getThumbURL ( water_viz )) print ( sar_water . getThumbURL ( water_viz )) Landsat 8 Image SAR Image Landsat 8 Water Map SAR Water Map This is just one example of surface water mapping and there are additional water mapping algorithms as mentioned above. More documentation regarding the water mapping functions and the input arguments can be found at the thresholding module If there are other algorithms you would like to see in the hydrafloods package, please file an issue with specifics (and hopefully a link to the paper) on our GitHub repo.","title":"Generic Water Mapping Algorithms"},{"location":"cli/","text":"\ud83d\udea7 Under construction \ud83d\udea7","title":"Command Line Interface"},{"location":"corrections/","text":"hydrafloods.corrections illumination_correction ( image , elevation , model = 'rotation' , scale = 90 , sensor = 'LC8' ) This function applies a terrain correction to optical imagery based on solar and viewing geometry Parameters: Name Type Description Default image ee.Image Optical image to perform correction on required elevation ee.Image Input DEM to calculate illumination corrections from required model str correction model to be applied. Options are 'cosine', 'c', 'scsc', or 'rotation' default = rotation 'rotation' scale int reduction scale to process satellite heading compared to ground. Increasing will reduce chance of OOM errors but reduce local scale correction accuracy. default = 90 90 sensor str name of sensor to correct. options are 'LC8' or 'S2' (lower case also accepted). default = LC8 'LC8' Returns: Type Description ee.Image illumination corrected optical imagery Exceptions: Type Description NotImplementedError when keyword sensor is not of 'LC8' or 'S2' NotImplementedError when keyword model is not of 'cosine', 'c', 'scsc', or 'rotation' Source code in hydrafloods/corrections.py @decorators . keep_attrs def illumination_correction ( image , elevation , model = \"rotation\" , scale = 90 , sensor = \"LC8\" ): \"\"\"This function applies a terrain correction to optical imagery based on solar and viewing geometry args: image (ee.Image): Optical image to perform correction on elevation (ee.Image): Input DEM to calculate illumination corrections from model (str, optional): correction model to be applied. Options are 'cosine', 'c', 'scsc', or 'rotation' default = rotation scale (int, optional): reduction scale to process satellite heading compared to ground. Increasing will reduce chance of OOM errors but reduce local scale correction accuracy. default = 90 sensor (str, optional): name of sensor to correct. options are 'LC8' or 'S2' (lower case also accepted). default = LC8 returns: ee.Image: illumination corrected optical imagery raises: NotImplementedError: when keyword sensor is not of 'LC8' or 'S2' NotImplementedError: when keyword model is not of 'cosine', 'c', 'scsc', or 'rotation' \"\"\" def _get_band_coeffs ( band_name ): \"\"\"Closure function to find illumination correction fit across the different bands args: band_name (str | ee.String): band name to find correction coefficients for \"\"\" # Create the image to apply the linear regression.The first band # is the cosi and the second band is the response variable, the reflectance (the bands). # L (y) = a + b*cosi(x); a = intercept, b = slope # Dependent: Reflectance y = image . select ([ band_name ]) # create an image with the three variables by concatenating them reg_image = ee . Image . cat ([ cosi , one , y ]) # specify the linear regression reducer lr_reducer = ee . Reducer . linearRegression ( numX = 2 , numY = 1 ) # fit the model fit = reg_image . reduceRegion ( reducer = lr_reducer , geometry = image . geometry (), scale = scale , maxPixels = 1e10 ) # Get the coefficients as a nested list, cast it to an array, and get # just the selected column slope = ee . Array ( fit . get ( \"coefficients\" )) . get ([ 0 , 0 ]) intercept = ee . Array ( fit . get ( \"coefficients\" )) . get ([ 1 , 0 ]) return ee . List ([ slope , intercept ]) if sensor . lower () == \"lc8\" : sz_property = \"SOLAR_ZENITH_ANGLE\" sa_property = \"SOLAR_AZIMUTH_ANGLE\" elif sensor . lower () == \"s2\" : sz_property = \"MEAN_SOLAR_ZENITH_ANGLE\" sa_property = \"MEAN_SOLAR_AZIMUTH_ANGLE\" else : raise NotImplementedError ( f \"Selected sensor, { sensor } , is not available. Options are 'LC8' or 'S2' (lower case also accepted)\" ) # value convert angle to radians to_radians = ee . Number (( math . pi / 180 )) # constand image of 1 one = ee . Image . constant ( 1 ) . rename ( \"one\" ) # calculate terrain info from elevation data terrain = ee . Algorithms . Terrain ( elevation ) # Extract slope in radians for each pixel in the image p = terrain . select ([ \"slope\" ]) . multiply ( to_radians ) # Extract aspect in radians for each pixel in the image o = terrain . select ([ \"aspect\" ]) . multiply ( to_radians ) # Extract solar zenith angle from the image z = ee . Image . constant ( ee . Number ( image . get ( sz_property )) . multiply ( to_radians )) # Extract solar azimuth from the image az = ee . Image . constant ( ee . Number ( image . get ( sa_property )) . multiply ( to_radians )) cosao = ( o . subtract ( az )) . cos () # cos(\u03d5a\u2212\u03d5o) # Calculate the cosine of the local solar incidence for every pixel in the image in radians (cosi=cosp*cosz+sinp*sinz*cos(\u03d5a\u2212\u03d5o) cosi = image . expression ( \"((cosp * cosz) + (sinp * sinz * cosao))\" , { \"cosp\" : p . cos (), \"cosz\" : z . cos (), \"sinp\" : p . sin (), \"sinz\" : z . sin (), \"cosao\" : cosao , }, ) if model == \"cosine\" : # if cosine model correction, return early as we don't need to do extra processing return image . expression ( \"((image * cosz) / cosi) \" , { \"image\" : image , \"cosz\" : z . cos (), \"cosi\" : cosi } ) bnames = image . bandNames () ab = ee . Array ( bnames . map ( _get_band_coeffs )) # get the coefficients as images a = ee . Image ( ee . Array ( ab . slice ( 1 , 0 , 1 ))) . arrayProject ([ 0 ]) . arrayFlatten ([ bnames ]) b = ee . Image ( ee . Array ( ab . slice ( 1 , 1 , 2 ))) . arrayProject ([ 0 ]) . arrayFlatten ([ bnames ]) C = b . divide ( a ) if model == \"c\" : newimage = image . expression ( \"((image * (cosz + C)) / (cosi + C))\" , { \"image\" : image , \"cosz\" : z . cos (), \"cosi\" : cosi , \"C\" : C }, ) elif model == \"scsc\" : newimage = image . expression ( \"((image * ((cosp * cosz) + C))/(cosi + C))\" , { \"image\" : image , \"cosp\" : p . cos (), \"cosz\" : z . cos (), \"cosi\" : cosi , \"C\" : C }, ) elif model == \"rotation\" : # Apply the empirical rotation model newimage = image . expression ( \"image - a * (cosi - cosz)\" , { \"image\" : image , \"cosz\" : z . cos (), \"cosi\" : cosi , \"a\" : a }, ) else : raise NotImplementedError ( f \"Defined model, { model } , has not been implemented. Options are 'cosine', 'c', 'scsc', or 'rotation'\" ) return newimage slope_correction ( image , elevation , model = 'volume' , buffer = 0 , scale = 1000 , in_units = 'db' , out_units = 'same' ) This function applies the slope correction on a Sentinel-1 image. Function based on https:# doi.org/10.3390/rs12111867. Adapted from https:# github.com/ESA-PhiLab/radiometric-slope-correction/blob/master/notebooks/1%20-%20Generate%20Data.ipynb Parameters: Name Type Description Default image ee.Image Sentinel-1 to perform correction on required elevation ee.Image Input DEM to calculate slope corrections from required model str physical reference model to be applied. Options are 'volume' or 'surface'. default = volume 'volume' buffer int buffer in meters for layover/shadow mask. If zero then no buffer will be applied. default = 0 0 scale int reduction scale to process satellite heading compared to ground. Increasing will reduce chance of OOM errors but reduce local scale correction accuracy. default = 1000 1000 Returns: Type Description ee.Image slope corrected SAR imagery with look and local incidence angle bands Exceptions: Type Description NotImplementedError when keyword model is not of 'volume' or 'surface' Source code in hydrafloods/corrections.py @decorators . keep_attrs def slope_correction ( image , elevation , model = \"volume\" , buffer = 0 , scale = 1000 , in_units = \"db\" , out_units = \"same\" , ): \"\"\"This function applies the slope correction on a Sentinel-1 image. Function based on https:# doi.org/10.3390/rs12111867. Adapted from https:# github.com/ESA-PhiLab/radiometric-slope-correction/blob/master/notebooks/1%20-%20Generate%20Data.ipynb args: image (ee.Image): Sentinel-1 to perform correction on elevation (ee.Image): Input DEM to calculate slope corrections from model (str, optional): physical reference model to be applied. Options are 'volume' or 'surface'. default = volume buffer (int, optional): buffer in meters for layover/shadow mask. If zero then no buffer will be applied. default = 0 scale (int, optional): reduction scale to process satellite heading compared to ground. Increasing will reduce chance of OOM errors but reduce local scale correction accuracy. default = 1000 returns: ee.Image: slope corrected SAR imagery with look and local incidence angle bands raises: NotImplementedError: when keyword model is not of 'volume' or 'surface' \"\"\" def _volumetric_model_SCF ( theta_iRad , alpha_rRad ): \"\"\"Closure funnction for calculation of volumetric model SCF args: theta_iRad (ee.Image): incidence angle in radians alpha_rRad (ee.Image): slope steepness in range returns: ee.Image \"\"\" # model nominator = ( ninetyRad . subtract ( theta_iRad ) . add ( alpha_rRad )) . tan () denominator = ( ninetyRad . subtract ( theta_iRad )) . tan () return nominator . divide ( denominator ) def _surface_model_SCF ( theta_iRad , alpha_rRad , alpha_azRad ): \"\"\"Closure funnction for calculation of direct model SCF args: theta_iRad (ee.Image): incidence angle in radians alpha_rRad (ee.Image): slope steepness in range alpha_azRad (ee.Image): slope steepness in azimuth returns: ee.Image \"\"\" # model nominator = ( ninetyRad . subtract ( theta_iRad )) . cos () denominator = alpha_azRad . cos () . multiply ( ( ninetyRad . subtract ( theta_iRad ) . add ( alpha_rRad )) . cos () ) return nominator . divide ( denominator ) def _erode ( image , distance ): \"\"\"Closure function to buffer raster values args: image (ee.Image): image that should be buffered distance (int): distance of buffer in meters returns: ee.Image \"\"\" d = ( image . Not () . unmask ( 1 ) . fastDistanceTransform ( 10 ) . sqrt () . multiply ( ee . Image . pixelArea () . sqrt ()) ) return image . updateMask ( d . gt ( distance )) def _masking ( alpha_rRad , theta_iRad , buffer ): \"\"\"Closure function for masking of layover and shadow args: alpha_rRad (ee.Image): slope steepness in range theta_iRad (ee.Image): incidence angle in radians buffer (int): buffer in meters returns: ee.Image \"\"\" # layover, where slope > radar viewing angle layover = alpha_rRad . lt ( theta_iRad ) . rename ( \"layover\" ) # shadow shadow = alpha_rRad . gt ( ee . Image . constant ( - 1 ) . multiply ( ninetyRad . subtract ( theta_iRad )) ) . rename ( \"shadow\" ) # add buffer to layover and shadow if buffer > 0 : layover = _erode ( layover , buffer ) shadow = _erode ( shadow , buffer ) # combine layover and shadow no_data_mask = layover . And ( shadow ) . rename ( \"no_data_mask\" ) return no_data_mask # get the image geometry and projection geom = image . geometry ( scale ) proj = image . select ( 1 ) . projection () angle_band = image . select ( \"angle\" ) # image to convert angle to radians to_radians = ee . Image . constant (( math . pi / 180 )) # create a 90 degree image in radians ninetyRad = ee . Image . constant ( 90 ) . multiply ( to_radians ) # calculate the look direction heading = ( ee . Terrain . aspect ( image . select ( \"angle\" )) . reduceRegion ( ee . Reducer . mean (), geom , scale ) . get ( \"aspect\" ) ) if in_units not in [ \"db\" , \"power\" ]: raise ValueError ( \"could not understand input units. needs to be either 'db' or 'power'\" ) if out_units not in [ \"same\" , \"other\" , None ]: raise ValueError ( \"could not understand output units option. needs to be either 'same' or 'other'\" ) # Sigma0 to Power of input image if in_units == \"db\" : sigma0Pow = geeutils . db_to_power ( image ) else : sigma0Pow = image # the numbering follows the article chapters # 2.1.1 Radar geometry theta_iRad = image . select ( \"angle\" ) . multiply ( to_radians ) phi_iRad = ee . Image . constant ( heading ) . multiply ( to_radians ) # 2.1.2 Terrain geometry alpha_sRad = ( ee . Terrain . slope ( elevation ) . select ( \"slope\" ) . multiply ( to_radians ) . setDefaultProjection ( proj ) ) phi_sRad = ( ee . Terrain . aspect ( elevation ) . select ( \"aspect\" ) . multiply ( to_radians ) . setDefaultProjection ( proj ) ) # 2.1.3 Model geometry # reduce to 3 angle phi_rRad = phi_iRad . subtract ( phi_sRad ) # slope steepness in range (eq. 2) alpha_rRad = ( alpha_sRad . tan () . multiply ( phi_rRad . cos ())) . atan () # slope steepness in azimuth (eq 3) alpha_azRad = ( alpha_sRad . tan () . multiply ( phi_rRad . sin ())) . atan () # local incidence angle (eq. 4) theta_liaRad = ( alpha_azRad . cos () . multiply (( theta_iRad . subtract ( alpha_rRad )) . cos ()) ) . acos () theta_liaDeg = theta_liaRad . multiply ( 180 / math . pi ) # 2.2 # Gamma_nought gamma0 = sigma0Pow . divide ( theta_iRad . cos ()) gamma0dB = geeutils . db_to_power ( gamma0 ) if model == \"volume\" : scf = _volumetric_model_SCF ( theta_iRad , alpha_rRad ) elif model == \"surface\" : scf = _surface_model_SCF ( theta_iRad , alpha_rRad , alpha_azRad ) else : raise NotImplementedError ( f \"Defined model, { model } , has not been implemented. Options are 'volume' or 'surface'\" ) # apply model for Gamm0_f gamma0_flat = gamma0 . divide ( scf ) if out_units == \"same\" and in_units == \"db\" : gamma0_flatDB = geeutils . power_to_db ( gamma0_flat ) . select ([ \"^(V).*\" ]) elif out_units != \"same\" and in_units == \"power\" : gamma0_flatDB = geeutils . power_to_db ( gamma0_flat ) . select ([ \"^(V).*\" ]) else : gamma0_flatDB = gamma0_flat . select ([ \"^(V).*\" ]) # calculate layover and shadow mask masks = _masking ( alpha_rRad , theta_iRad , buffer ) return ( gamma0_flatDB . updateMask ( masks ) . addBands ( angle_band ) . addBands ( theta_liaDeg . rename ( \"local_inc_angle\" )) )","title":"corrections module"},{"location":"corrections/#hydrafloods.corrections","text":"","title":"corrections"},{"location":"corrections/#hydrafloods.corrections.illumination_correction","text":"This function applies a terrain correction to optical imagery based on solar and viewing geometry Parameters: Name Type Description Default image ee.Image Optical image to perform correction on required elevation ee.Image Input DEM to calculate illumination corrections from required model str correction model to be applied. Options are 'cosine', 'c', 'scsc', or 'rotation' default = rotation 'rotation' scale int reduction scale to process satellite heading compared to ground. Increasing will reduce chance of OOM errors but reduce local scale correction accuracy. default = 90 90 sensor str name of sensor to correct. options are 'LC8' or 'S2' (lower case also accepted). default = LC8 'LC8' Returns: Type Description ee.Image illumination corrected optical imagery Exceptions: Type Description NotImplementedError when keyword sensor is not of 'LC8' or 'S2' NotImplementedError when keyword model is not of 'cosine', 'c', 'scsc', or 'rotation' Source code in hydrafloods/corrections.py @decorators . keep_attrs def illumination_correction ( image , elevation , model = \"rotation\" , scale = 90 , sensor = \"LC8\" ): \"\"\"This function applies a terrain correction to optical imagery based on solar and viewing geometry args: image (ee.Image): Optical image to perform correction on elevation (ee.Image): Input DEM to calculate illumination corrections from model (str, optional): correction model to be applied. Options are 'cosine', 'c', 'scsc', or 'rotation' default = rotation scale (int, optional): reduction scale to process satellite heading compared to ground. Increasing will reduce chance of OOM errors but reduce local scale correction accuracy. default = 90 sensor (str, optional): name of sensor to correct. options are 'LC8' or 'S2' (lower case also accepted). default = LC8 returns: ee.Image: illumination corrected optical imagery raises: NotImplementedError: when keyword sensor is not of 'LC8' or 'S2' NotImplementedError: when keyword model is not of 'cosine', 'c', 'scsc', or 'rotation' \"\"\" def _get_band_coeffs ( band_name ): \"\"\"Closure function to find illumination correction fit across the different bands args: band_name (str | ee.String): band name to find correction coefficients for \"\"\" # Create the image to apply the linear regression.The first band # is the cosi and the second band is the response variable, the reflectance (the bands). # L (y) = a + b*cosi(x); a = intercept, b = slope # Dependent: Reflectance y = image . select ([ band_name ]) # create an image with the three variables by concatenating them reg_image = ee . Image . cat ([ cosi , one , y ]) # specify the linear regression reducer lr_reducer = ee . Reducer . linearRegression ( numX = 2 , numY = 1 ) # fit the model fit = reg_image . reduceRegion ( reducer = lr_reducer , geometry = image . geometry (), scale = scale , maxPixels = 1e10 ) # Get the coefficients as a nested list, cast it to an array, and get # just the selected column slope = ee . Array ( fit . get ( \"coefficients\" )) . get ([ 0 , 0 ]) intercept = ee . Array ( fit . get ( \"coefficients\" )) . get ([ 1 , 0 ]) return ee . List ([ slope , intercept ]) if sensor . lower () == \"lc8\" : sz_property = \"SOLAR_ZENITH_ANGLE\" sa_property = \"SOLAR_AZIMUTH_ANGLE\" elif sensor . lower () == \"s2\" : sz_property = \"MEAN_SOLAR_ZENITH_ANGLE\" sa_property = \"MEAN_SOLAR_AZIMUTH_ANGLE\" else : raise NotImplementedError ( f \"Selected sensor, { sensor } , is not available. Options are 'LC8' or 'S2' (lower case also accepted)\" ) # value convert angle to radians to_radians = ee . Number (( math . pi / 180 )) # constand image of 1 one = ee . Image . constant ( 1 ) . rename ( \"one\" ) # calculate terrain info from elevation data terrain = ee . Algorithms . Terrain ( elevation ) # Extract slope in radians for each pixel in the image p = terrain . select ([ \"slope\" ]) . multiply ( to_radians ) # Extract aspect in radians for each pixel in the image o = terrain . select ([ \"aspect\" ]) . multiply ( to_radians ) # Extract solar zenith angle from the image z = ee . Image . constant ( ee . Number ( image . get ( sz_property )) . multiply ( to_radians )) # Extract solar azimuth from the image az = ee . Image . constant ( ee . Number ( image . get ( sa_property )) . multiply ( to_radians )) cosao = ( o . subtract ( az )) . cos () # cos(\u03d5a\u2212\u03d5o) # Calculate the cosine of the local solar incidence for every pixel in the image in radians (cosi=cosp*cosz+sinp*sinz*cos(\u03d5a\u2212\u03d5o) cosi = image . expression ( \"((cosp * cosz) + (sinp * sinz * cosao))\" , { \"cosp\" : p . cos (), \"cosz\" : z . cos (), \"sinp\" : p . sin (), \"sinz\" : z . sin (), \"cosao\" : cosao , }, ) if model == \"cosine\" : # if cosine model correction, return early as we don't need to do extra processing return image . expression ( \"((image * cosz) / cosi) \" , { \"image\" : image , \"cosz\" : z . cos (), \"cosi\" : cosi } ) bnames = image . bandNames () ab = ee . Array ( bnames . map ( _get_band_coeffs )) # get the coefficients as images a = ee . Image ( ee . Array ( ab . slice ( 1 , 0 , 1 ))) . arrayProject ([ 0 ]) . arrayFlatten ([ bnames ]) b = ee . Image ( ee . Array ( ab . slice ( 1 , 1 , 2 ))) . arrayProject ([ 0 ]) . arrayFlatten ([ bnames ]) C = b . divide ( a ) if model == \"c\" : newimage = image . expression ( \"((image * (cosz + C)) / (cosi + C))\" , { \"image\" : image , \"cosz\" : z . cos (), \"cosi\" : cosi , \"C\" : C }, ) elif model == \"scsc\" : newimage = image . expression ( \"((image * ((cosp * cosz) + C))/(cosi + C))\" , { \"image\" : image , \"cosp\" : p . cos (), \"cosz\" : z . cos (), \"cosi\" : cosi , \"C\" : C }, ) elif model == \"rotation\" : # Apply the empirical rotation model newimage = image . expression ( \"image - a * (cosi - cosz)\" , { \"image\" : image , \"cosz\" : z . cos (), \"cosi\" : cosi , \"a\" : a }, ) else : raise NotImplementedError ( f \"Defined model, { model } , has not been implemented. Options are 'cosine', 'c', 'scsc', or 'rotation'\" ) return newimage","title":"illumination_correction()"},{"location":"corrections/#hydrafloods.corrections.slope_correction","text":"This function applies the slope correction on a Sentinel-1 image. Function based on https:# doi.org/10.3390/rs12111867. Adapted from https:# github.com/ESA-PhiLab/radiometric-slope-correction/blob/master/notebooks/1%20-%20Generate%20Data.ipynb Parameters: Name Type Description Default image ee.Image Sentinel-1 to perform correction on required elevation ee.Image Input DEM to calculate slope corrections from required model str physical reference model to be applied. Options are 'volume' or 'surface'. default = volume 'volume' buffer int buffer in meters for layover/shadow mask. If zero then no buffer will be applied. default = 0 0 scale int reduction scale to process satellite heading compared to ground. Increasing will reduce chance of OOM errors but reduce local scale correction accuracy. default = 1000 1000 Returns: Type Description ee.Image slope corrected SAR imagery with look and local incidence angle bands Exceptions: Type Description NotImplementedError when keyword model is not of 'volume' or 'surface' Source code in hydrafloods/corrections.py @decorators . keep_attrs def slope_correction ( image , elevation , model = \"volume\" , buffer = 0 , scale = 1000 , in_units = \"db\" , out_units = \"same\" , ): \"\"\"This function applies the slope correction on a Sentinel-1 image. Function based on https:# doi.org/10.3390/rs12111867. Adapted from https:# github.com/ESA-PhiLab/radiometric-slope-correction/blob/master/notebooks/1%20-%20Generate%20Data.ipynb args: image (ee.Image): Sentinel-1 to perform correction on elevation (ee.Image): Input DEM to calculate slope corrections from model (str, optional): physical reference model to be applied. Options are 'volume' or 'surface'. default = volume buffer (int, optional): buffer in meters for layover/shadow mask. If zero then no buffer will be applied. default = 0 scale (int, optional): reduction scale to process satellite heading compared to ground. Increasing will reduce chance of OOM errors but reduce local scale correction accuracy. default = 1000 returns: ee.Image: slope corrected SAR imagery with look and local incidence angle bands raises: NotImplementedError: when keyword model is not of 'volume' or 'surface' \"\"\" def _volumetric_model_SCF ( theta_iRad , alpha_rRad ): \"\"\"Closure funnction for calculation of volumetric model SCF args: theta_iRad (ee.Image): incidence angle in radians alpha_rRad (ee.Image): slope steepness in range returns: ee.Image \"\"\" # model nominator = ( ninetyRad . subtract ( theta_iRad ) . add ( alpha_rRad )) . tan () denominator = ( ninetyRad . subtract ( theta_iRad )) . tan () return nominator . divide ( denominator ) def _surface_model_SCF ( theta_iRad , alpha_rRad , alpha_azRad ): \"\"\"Closure funnction for calculation of direct model SCF args: theta_iRad (ee.Image): incidence angle in radians alpha_rRad (ee.Image): slope steepness in range alpha_azRad (ee.Image): slope steepness in azimuth returns: ee.Image \"\"\" # model nominator = ( ninetyRad . subtract ( theta_iRad )) . cos () denominator = alpha_azRad . cos () . multiply ( ( ninetyRad . subtract ( theta_iRad ) . add ( alpha_rRad )) . cos () ) return nominator . divide ( denominator ) def _erode ( image , distance ): \"\"\"Closure function to buffer raster values args: image (ee.Image): image that should be buffered distance (int): distance of buffer in meters returns: ee.Image \"\"\" d = ( image . Not () . unmask ( 1 ) . fastDistanceTransform ( 10 ) . sqrt () . multiply ( ee . Image . pixelArea () . sqrt ()) ) return image . updateMask ( d . gt ( distance )) def _masking ( alpha_rRad , theta_iRad , buffer ): \"\"\"Closure function for masking of layover and shadow args: alpha_rRad (ee.Image): slope steepness in range theta_iRad (ee.Image): incidence angle in radians buffer (int): buffer in meters returns: ee.Image \"\"\" # layover, where slope > radar viewing angle layover = alpha_rRad . lt ( theta_iRad ) . rename ( \"layover\" ) # shadow shadow = alpha_rRad . gt ( ee . Image . constant ( - 1 ) . multiply ( ninetyRad . subtract ( theta_iRad )) ) . rename ( \"shadow\" ) # add buffer to layover and shadow if buffer > 0 : layover = _erode ( layover , buffer ) shadow = _erode ( shadow , buffer ) # combine layover and shadow no_data_mask = layover . And ( shadow ) . rename ( \"no_data_mask\" ) return no_data_mask # get the image geometry and projection geom = image . geometry ( scale ) proj = image . select ( 1 ) . projection () angle_band = image . select ( \"angle\" ) # image to convert angle to radians to_radians = ee . Image . constant (( math . pi / 180 )) # create a 90 degree image in radians ninetyRad = ee . Image . constant ( 90 ) . multiply ( to_radians ) # calculate the look direction heading = ( ee . Terrain . aspect ( image . select ( \"angle\" )) . reduceRegion ( ee . Reducer . mean (), geom , scale ) . get ( \"aspect\" ) ) if in_units not in [ \"db\" , \"power\" ]: raise ValueError ( \"could not understand input units. needs to be either 'db' or 'power'\" ) if out_units not in [ \"same\" , \"other\" , None ]: raise ValueError ( \"could not understand output units option. needs to be either 'same' or 'other'\" ) # Sigma0 to Power of input image if in_units == \"db\" : sigma0Pow = geeutils . db_to_power ( image ) else : sigma0Pow = image # the numbering follows the article chapters # 2.1.1 Radar geometry theta_iRad = image . select ( \"angle\" ) . multiply ( to_radians ) phi_iRad = ee . Image . constant ( heading ) . multiply ( to_radians ) # 2.1.2 Terrain geometry alpha_sRad = ( ee . Terrain . slope ( elevation ) . select ( \"slope\" ) . multiply ( to_radians ) . setDefaultProjection ( proj ) ) phi_sRad = ( ee . Terrain . aspect ( elevation ) . select ( \"aspect\" ) . multiply ( to_radians ) . setDefaultProjection ( proj ) ) # 2.1.3 Model geometry # reduce to 3 angle phi_rRad = phi_iRad . subtract ( phi_sRad ) # slope steepness in range (eq. 2) alpha_rRad = ( alpha_sRad . tan () . multiply ( phi_rRad . cos ())) . atan () # slope steepness in azimuth (eq 3) alpha_azRad = ( alpha_sRad . tan () . multiply ( phi_rRad . sin ())) . atan () # local incidence angle (eq. 4) theta_liaRad = ( alpha_azRad . cos () . multiply (( theta_iRad . subtract ( alpha_rRad )) . cos ()) ) . acos () theta_liaDeg = theta_liaRad . multiply ( 180 / math . pi ) # 2.2 # Gamma_nought gamma0 = sigma0Pow . divide ( theta_iRad . cos ()) gamma0dB = geeutils . db_to_power ( gamma0 ) if model == \"volume\" : scf = _volumetric_model_SCF ( theta_iRad , alpha_rRad ) elif model == \"surface\" : scf = _surface_model_SCF ( theta_iRad , alpha_rRad , alpha_azRad ) else : raise NotImplementedError ( f \"Defined model, { model } , has not been implemented. Options are 'volume' or 'surface'\" ) # apply model for Gamm0_f gamma0_flat = gamma0 . divide ( scf ) if out_units == \"same\" and in_units == \"db\" : gamma0_flatDB = geeutils . power_to_db ( gamma0_flat ) . select ([ \"^(V).*\" ]) elif out_units != \"same\" and in_units == \"power\" : gamma0_flatDB = geeutils . power_to_db ( gamma0_flat ) . select ([ \"^(V).*\" ]) else : gamma0_flatDB = gamma0_flat . select ([ \"^(V).*\" ]) # calculate layover and shadow mask masks = _masking ( alpha_rRad , theta_iRad , buffer ) return ( gamma0_flatDB . updateMask ( masks ) . addBands ( angle_band ) . addBands ( theta_liaDeg . rename ( \"local_inc_angle\" )) )","title":"slope_correction()"},{"location":"datasets/","text":"hydrafloods.datasets.Dataset Base dataset class used to define an EE image collection by datetime and geographic region A dataset wraps an ee.ImageCollection by applying the spatial and temporal filtering upon init. Provides utility functionality to make working with and managing image collections less verbose Examples: Create a dataset object for Sentinel-1 data over Alabama for 2019 >>> ds = Dataset ( ... region = ee . Geometry . Rectangle ([ - 88.473227 , 30.223334 , - 84.88908 , 35.008028 ]), ... start_time = \"2019-01-01\" , ... end_time = \"2020-01-01\" , ... asset_id = \"COPERNICUS/S1_GRD\" ... ) >>> ds HYDRAFloods Dataset : { 'asset_id' : 'COPERNICUS/S1_GRD' , 'end_time' : '2020-01-01' , 'name' : 'Dataset' , 'region' : [[[ ... ], [ ... ], [ ... ], [ ... ], [ ... ]]], 'start_time' : '2019-01-01' } Source code in hydrafloods/datasets.py class Dataset : \"\"\"Base dataset class used to define an EE image collection by datetime and geographic region A dataset wraps an ee.ImageCollection by applying the spatial and temporal filtering upon init. Provides utility functionality to make working with and managing image collections less verbose Example: Create a dataset object for Sentinel-1 data over Alabama for 2019 >>> ds = Dataset( ... region = ee.Geometry.Rectangle([ -88.473227, 30.223334, -84.88908, 35.008028 ]), ... start_time = \"2019-01-01\", ... end_time = \"2020-01-01\", ... asset_id = \"COPERNICUS/S1_GRD\" ... ) >>> ds HYDRAFloods Dataset: {'asset_id': 'COPERNICUS/S1_GRD', 'end_time': '2020-01-01', 'name': 'Dataset', 'region': [[[...], [...], [...], [...], [...]]], 'start_time': '2019-01-01'} \"\"\" def __init__ ( self , region , start_time , end_time , asset_id , use_qa = False ): \"\"\"Initialize Dataset class args: region (ee.Geometry): earth engine geometry object to filter image collection by start_time (str | datetime.datetime): start time used to filter image collection end_time (str | datetime.datetime): end time used to filter image collection asset_id (str): asset id of earth engine collection use_qa (bool, optional): boolean to determine to use an internal function qa(). Used for definining custom dataset objects raises: AttributeError: if qa() method is not defined and use_qa is True \"\"\" # TODO: add exceptions to check datatypes self . region = region # dtype = ee.Geometry self . start_time = start_time self . end_time = end_time self . asset_id = asset_id self . use_qa = use_qa # dictionary mapping of band names used to harmonized optical datasets to same names self . BANDREMAP = ee . Dictionary ( { \"landsat7\" : ee . List ([ \"SR_B1\" , \"SR_B2\" , \"SR_B3\" , \"SR_B4\" , \"SR_B5\" , \"SR_B7\" ]), \"landsat8\" : ee . List ([ \"SR_B2\" , \"SR_B3\" , \"SR_B4\" , \"SR_B5\" , \"SR_B6\" , \"SR_B7\" ]), \"viirs\" : ee . List ([ \"M2\" , \"M4\" , \"I1\" , \"I2\" , \"I3\" , \"M11\" ]), \"sen2\" : ee . List ([ \"B2\" , \"B3\" , \"B4\" , \"B8\" , \"B11\" , \"B12\" ]), \"modis\" : ee . List ( [ \"sur_refl_b03\" , \"sur_refl_b04\" , \"sur_refl_b01\" , \"sur_refl_b02\" , \"sur_refl_b06\" , \"sur_refl_b07\" , ] ), \"new\" : ee . List ([ \"blue\" , \"green\" , \"red\" , \"nir\" , \"swir1\" , \"swir2\" ]), } ) # get the image collection and filter by geographic region and date time imgcollection = ( ee . ImageCollection ( self . asset_id ) . filterBounds ( self . region ) . filterDate ( self . start_time , self . end_time ) ) # check if to apply arbitrary qa process on collection # qa function can be defined in custom objects extending dataset if self . use_qa : try : imgcollection = imgcollection . map ( self . qa ) except AttributeError : raise AttributeError ( \"qa() method is not defined...please define one or set `use_qa` to False\" ) self . collection = imgcollection def __repr__ ( self ): # format datetime information if isinstance ( self . start_time , datetime . datetime ): ststr = self . start_time . strftime ( \"%Y-%m- %d \" ) else : ststr = self . start_time if isinstance ( self . end_time , datetime . datetime ): etstr = self . end_time . strftime ( \"%Y-%m- %d \" ) else : etstr = self . end_time # create dict of dataset information objDict = { \"name\" : self . __class__ . __name__ , \"asset_id\" : self . asset_id , \"start_time\" : ststr , \"end_time\" : etstr , \"region\" : self . region . coordinates () . getInfo (), } # pretty format dict and return information strRepr = pformat ( objDict , depth = 3 ) return f \"HYDRAFloods Dataset: \\n { strRepr } \" @property def collection ( self ): \"\"\"image collection object property wrapped by dataset\"\"\" return self . _collection @collection . setter def collection ( self , value ): \"\"\"setter function for collection property\"\"\" self . _collection = value return @property def n_images ( self ): \"\"\"Number of images contained in the dataset\"\"\" return self . collection . size () . getInfo () @property def dates ( self ): \"\"\"Dates of imagery contained in the image collection\"\"\" eeDates = self . collection . aggregate_array ( \"system:time_start\" ) . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd HH:mm:ss.SSS\" ) ) return eeDates . getInfo () @staticmethod def from_imgcollection ( img_collection ): \"\"\"Static method to convert an ee.ImageCollection object to a hf.Dataset object. This method will take some time as it uses computed ee Objects from the image collection propeties to populate the Dataset object properties (passing info from server to client) args: img_collection (ee.ImageCollection): computed ee.ImageCollection object to create a hf.Dataset returns: hf.Dataset: dataset object with property information directly from the ee.ImageCollection \"\"\" # get region and date information region = ( img_collection . map ( geeutils . get_geoms ) . union ( maxError = 100 ) . geometry ( maxError = 100 ) ) # convert ee.Date info to string format dates = ( img_collection . aggregate_array ( \"system:time_start\" ) . sort () . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd HH:mm:ss.S\" )) ) # pull the date info to local strings start_time = dates . get ( 0 ) . getInfo () end_time = dates . get ( - 1 ) . getInfo () # get the collection id for `.asset_id` property collection_id = img_collection . get ( \"system:id\" ) . getInfo () if collection_id == \"None\" : collection_id = \"Custom ImageCollection\" # make a dummy dataset dummy_ds = Dataset ( region , start_time , end_time , asset_id = \"NOAA/VIIRS/001/VNP09GA\" , use_qa = False , ) # override the dummy dataset information with the correct data fr dummy_ds . asset_id = collection_id dummy_ds . collection = img_collection return dummy_ds def qa ( self , ): return def _inplace_wrapper ( self , collection , inplace ): \"\"\"Private helper function to replace the collection info for a class typically used when other class methods have inplace \"\"\" if inplace : self . collection = collection return else : outCls = self . copy () outCls . collection = collection return outCls def copy ( self ): \"\"\"returns a deep copy of the hydrafloods dataset class\"\"\" return copy . deepcopy ( self ) def apply_func ( self , func , inplace = False , * args , ** kwargs ): \"\"\"Wrapper method to apply a function to all of the image in the dataset. Makes a copy of the collection and reassigns the image collection property. Function must accept an ee.ImageCollection and return an ee.ImageCollection args: func (object): Function to map across image collection. Function must accept ee.Image as first argument inplace (bool, optional): define whether to return another dataset object or update inplace. default = False **kwargs: arbitrary keyword to pass to `func` returns: Dataset | None: copy of class with results from `func` as image within collection property \"\"\" # get a partial function to map over imagery with the keywords applied # expects that the first positional arg is an func = partial ( func , ** kwargs ) out_coll = self . collection . map ( func ) return self . _inplace_wrapper ( out_coll , inplace ) def apply ( self , func , inplace = False , * args , ** kwargs ): \"\"\"Alias for the `apply_func` method args: func (object): Function to map across image collection. Function must accept ee.Image as first argument inplace (bool, optional): define whether to return another dataset object or update inplace. default = False **kwargs: arbitrary keyword to pass to `func` returns: Dataset | None: copy of class with results from `func` as image within collection property \"\"\" return self . apply_func ( func , inplace , * args , * kwargs ) def filter ( self , filter , inplace = False ): \"\"\"Wrapper method for applying a filter to a datset collection. args: filter (ee.Filter): an `ee.Filter` object to apply to the dataset collection. returns: Dataset | None: returns the dataset with the filtered collection. \"\"\" filtered = self . collection . filter ( filter ) return self . _inplace_wrapper ( filtered , inplace ) def select ( self , * args , inplace = False ): \"\"\"Wrapper method for selecting bands from dataset collection args: *args: arbitrary arguments to pass to the `ee.ImageCollection.select()` method inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns the dataset with the collection with selected bands. \"\"\" selected = self . collection . select ( * args ) return self . _inplace_wrapper ( selected , inplace ) def clip_to_region ( self , inplace = False ): \"\"\"Clips all of the images to the geographic extent defined by region. Useful for setting geometries on unbounded imagery in collection (e.g. MODIS or VIIRS imagery) args: inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset with imagery clipped to self.region or none depending on inplace \"\"\" @decorators . keep_attrs def clip ( img ): \"\"\"Closure function to perform the clipping while carrying metadata\"\"\" return ee . Image ( img . clip ( self . region )) out_coll = self . collection . map ( clip ) return self . _inplace_wrapper ( out_coll , inplace ) def merge ( self , dataset , inplace = False ): \"\"\"Merge the collection of two datasets into one where self.collection will contain imagery from self and dataset arg. Results will be sorted by time args: dataset (Dataset): dataset object to merge inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection is merged imagery or none depending on inplace \"\"\" merged = self . collection . merge ( dataset . collection ) . sort ( \"system:time_start\" ) return self . _inplace_wrapper ( merged , inplace ) def join ( self , dataset , inplace = False ): \"\"\"Performs spatiotemporal join between self.collection and dataset.collection. Result will be a dataset where the collection is colocated imagery in space and time args: dataset (Dataset): dataset object to apply join with. Used as right in join operations inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection with joined imagery or none depending on inplace \"\"\" def _merge ( img ): \"\"\"Closure func to take results from the join and combine into one image with overlaping region\"\"\" join_coll = ee . ImageCollection . fromImages ( img . get ( key )) img_geom = img . geometry ( 100 ) join_geom = join_coll . map ( geeutils . get_geoms ) . union ( 100 ) . geometry ( 100 ) overlap = img_geom . intersection ( join_geom , 100 ) join_data = join_coll . mosaic () return img . addBands ( join_data ) . clip ( overlap ) key = str ( dataset . __class__ . __name__ ) # get a time and space filter filter = ee . Filter . And ( ee . Filter . maxDifference ( ** { \"difference\" : 1000 * 60 * 60 * 24 , # One day in milliseconds \"leftField\" : \"system:time_start\" , \"rightField\" : \"system:time_start\" , } ), ee . Filter . intersects ( ** { \"leftField\" : \".geo\" , \"rightField\" : \".geo\" , \"maxError\" : 100 } ), ) # apply join on collections and save all results joined = ee . ImageCollection ( ee . Join . saveAll ( key ) . apply ( primary = self . collection , secondary = dataset . collection , condition = filter ) ) # map over all filtered imagery, mosaic joined matches, and add bands to imagery joined = joined . map ( _merge ) return self . _inplace_wrapper ( joined , inplace ) def aggregate_time ( self , dates = None , period = 1 , period_unit = \"day\" , reducer = \"mean\" , rename = True , clip_to_area = False , inplace = False , ): \"\"\"Aggregates multiple images into one based on time periods and a user defined reducer. Useful for mosaicing images from same date or time period. Expects the images in this dataset to be homogenous (same band names and types) args: dates (list[str], optional): list of dates defined as beginning time period of aggregatation. default = None, all available uniques dates in collection will be used period (int, optional): number of days to advance from dates for aggregation. default = 1 period_unit (str, optional): time unit to advance period for aggregation. default = \"day\" reducer (str | ee.Reducer, optional): reducer to apply to images for aggregation, accepts string reducer name or ee.Reducer opbject, default = \"mean\" clip_to_area (bool): switch to clip imagery that has been merged to the overlaping region of imagery, default=False inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection with aggregated imagery or none depending on inplace \"\"\" def _aggregation ( d ): \"\"\"Closure function to map through days and reduce data within a given time period\"\"\" t1 = ee . Date ( d ) t2 = t1 . advance ( period , period_unit ) img = ( self . collection . filterDate ( t1 , t2 ) . reduce ( reducer ) . set ( \"system:time_start\" , t1 . millis ()) ) if rename : img = img . rename ( band_names ) geom = ( ee . FeatureCollection ( self . collection . filterDate ( t1 , t2 ) . map ( geeutils . get_geoms ) ) . union ( 100 ) . geometry ( 100 ) ) outimg = ee . Algorithms . If ( clip_to_area , img . clip ( geom ), img ) return outimg if dates is None : dates = ( self . collection . aggregate_array ( \"system:time_start\" ) . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd\" )) . distinct () ) else : dates = ee . List ( dates ) band_names = ee . Image ( self . collection . first ()) . bandNames () out_coll = ee . ImageCollection . fromImages ( dates . map ( _aggregation )) return self . _inplace_wrapper ( out_coll , inplace ) @decorators . keep_attrs def band_pass_adjustment ( self , img ): \"\"\"Method to apply linear band transformation to dataset image collection. Expects that dataset has properties `self.gain` and `self.bias` set args: img (ee.Image): image to apply regression on \"\"\" # linear regression coefficients for adjustment return ( img . multiply ( self . gain ) . add ( self . bias ) . set ( \"system:time_start\" , img . get ( \"system:time_start\" )) ) def pipe ( self , steps , inplace = False , keep_attrs = True ): \"\"\"Method to pipe imagery within dataset through multiple functions at once. Assumes the first argument into piped functions are and ee.Image args: steps (list | tuple): iterable of functions/steps to apply to imagery. list must be in the form of (func,func) or with a tuple of function/keyword ((func,kwargs),func) inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection with piped functions applied Example: ```python s1 = hf.Sentinel1(ee.Geometry.Point(105.03,11.72),\"2019-10-03\",\"2019-10-05\") water = s1.pipe( ( hf.gamma_map, #apply speckle filter (hf.egde_ostu,{'initial_threshold:-16}) # apply water mapping ) ) ``` \"\"\" def _piper ( funcs ): \"\"\"Closure function to nest list of functions\"\"\" if len ( funcs ) > 1 : one_shotter = funcs [ 0 ] for func in funcs [ 1 :]: one_shotter = pipe | one_shotter | func else : one_shotter = funcs [ 0 ] return one_shotter fs = [] # loop through the steps and create partial funcs is kwargs are provided for step in steps : try : func , kwargs = step except TypeError : func = step kwargs = None if kwargs is not None : pfunc = partial ( func , ** kwargs ) else : pfunc = func fs . append ( pfunc ) # get the piped function if keep_attrs : one_shot = decorators . keep_attrs ( _piper ( fs )) else : one_shot = _piper ( fs ) # apply pipe to each image out_coll = self . collection . map ( lambda img : one_shot ( img )) return self . _inplace_wrapper ( out_coll , inplace ) collection property writable image collection object property wrapped by dataset dates property readonly Dates of imagery contained in the image collection n_images property readonly Number of images contained in the dataset __init__ ( self , region , start_time , end_time , asset_id , use_qa = False ) special Initialize Dataset class Parameters: Name Type Description Default region ee.Geometry earth engine geometry object to filter image collection by required start_time str | datetime.datetime start time used to filter image collection required end_time str | datetime.datetime end time used to filter image collection required asset_id str asset id of earth engine collection required use_qa bool boolean to determine to use an internal function qa(). Used for definining custom dataset objects False Exceptions: Type Description AttributeError if qa() method is not defined and use_qa is True Source code in hydrafloods/datasets.py def __init__ ( self , region , start_time , end_time , asset_id , use_qa = False ): \"\"\"Initialize Dataset class args: region (ee.Geometry): earth engine geometry object to filter image collection by start_time (str | datetime.datetime): start time used to filter image collection end_time (str | datetime.datetime): end time used to filter image collection asset_id (str): asset id of earth engine collection use_qa (bool, optional): boolean to determine to use an internal function qa(). Used for definining custom dataset objects raises: AttributeError: if qa() method is not defined and use_qa is True \"\"\" # TODO: add exceptions to check datatypes self . region = region # dtype = ee.Geometry self . start_time = start_time self . end_time = end_time self . asset_id = asset_id self . use_qa = use_qa # dictionary mapping of band names used to harmonized optical datasets to same names self . BANDREMAP = ee . Dictionary ( { \"landsat7\" : ee . List ([ \"SR_B1\" , \"SR_B2\" , \"SR_B3\" , \"SR_B4\" , \"SR_B5\" , \"SR_B7\" ]), \"landsat8\" : ee . List ([ \"SR_B2\" , \"SR_B3\" , \"SR_B4\" , \"SR_B5\" , \"SR_B6\" , \"SR_B7\" ]), \"viirs\" : ee . List ([ \"M2\" , \"M4\" , \"I1\" , \"I2\" , \"I3\" , \"M11\" ]), \"sen2\" : ee . List ([ \"B2\" , \"B3\" , \"B4\" , \"B8\" , \"B11\" , \"B12\" ]), \"modis\" : ee . List ( [ \"sur_refl_b03\" , \"sur_refl_b04\" , \"sur_refl_b01\" , \"sur_refl_b02\" , \"sur_refl_b06\" , \"sur_refl_b07\" , ] ), \"new\" : ee . List ([ \"blue\" , \"green\" , \"red\" , \"nir\" , \"swir1\" , \"swir2\" ]), } ) # get the image collection and filter by geographic region and date time imgcollection = ( ee . ImageCollection ( self . asset_id ) . filterBounds ( self . region ) . filterDate ( self . start_time , self . end_time ) ) # check if to apply arbitrary qa process on collection # qa function can be defined in custom objects extending dataset if self . use_qa : try : imgcollection = imgcollection . map ( self . qa ) except AttributeError : raise AttributeError ( \"qa() method is not defined...please define one or set `use_qa` to False\" ) self . collection = imgcollection aggregate_time ( self , dates = None , period = 1 , period_unit = 'day' , reducer = 'mean' , rename = True , clip_to_area = False , inplace = False ) Aggregates multiple images into one based on time periods and a user defined reducer. Useful for mosaicing images from same date or time period. Expects the images in this dataset to be homogenous (same band names and types) Parameters: Name Type Description Default dates list[str] list of dates defined as beginning time period of aggregatation. default = None, all available uniques dates in collection will be used None period int number of days to advance from dates for aggregation. default = 1 1 period_unit str time unit to advance period for aggregation. default = \"day\" 'day' reducer str | ee.Reducer reducer to apply to images for aggregation, accepts string reducer name or ee.Reducer opbject, default = \"mean\" 'mean' clip_to_area bool switch to clip imagery that has been merged to the overlaping region of imagery, default=False False inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset.collection with aggregated imagery or none depending on inplace Source code in hydrafloods/datasets.py def aggregate_time ( self , dates = None , period = 1 , period_unit = \"day\" , reducer = \"mean\" , rename = True , clip_to_area = False , inplace = False , ): \"\"\"Aggregates multiple images into one based on time periods and a user defined reducer. Useful for mosaicing images from same date or time period. Expects the images in this dataset to be homogenous (same band names and types) args: dates (list[str], optional): list of dates defined as beginning time period of aggregatation. default = None, all available uniques dates in collection will be used period (int, optional): number of days to advance from dates for aggregation. default = 1 period_unit (str, optional): time unit to advance period for aggregation. default = \"day\" reducer (str | ee.Reducer, optional): reducer to apply to images for aggregation, accepts string reducer name or ee.Reducer opbject, default = \"mean\" clip_to_area (bool): switch to clip imagery that has been merged to the overlaping region of imagery, default=False inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection with aggregated imagery or none depending on inplace \"\"\" def _aggregation ( d ): \"\"\"Closure function to map through days and reduce data within a given time period\"\"\" t1 = ee . Date ( d ) t2 = t1 . advance ( period , period_unit ) img = ( self . collection . filterDate ( t1 , t2 ) . reduce ( reducer ) . set ( \"system:time_start\" , t1 . millis ()) ) if rename : img = img . rename ( band_names ) geom = ( ee . FeatureCollection ( self . collection . filterDate ( t1 , t2 ) . map ( geeutils . get_geoms ) ) . union ( 100 ) . geometry ( 100 ) ) outimg = ee . Algorithms . If ( clip_to_area , img . clip ( geom ), img ) return outimg if dates is None : dates = ( self . collection . aggregate_array ( \"system:time_start\" ) . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd\" )) . distinct () ) else : dates = ee . List ( dates ) band_names = ee . Image ( self . collection . first ()) . bandNames () out_coll = ee . ImageCollection . fromImages ( dates . map ( _aggregation )) return self . _inplace_wrapper ( out_coll , inplace ) apply ( self , func , inplace = False , * args , ** kwargs ) Alias for the apply_func method Parameters: Name Type Description Default func object Function to map across image collection. Function must accept ee.Image as first argument required inplace bool define whether to return another dataset object or update inplace. default = False False **kwargs arbitrary keyword to pass to func {} Returns: Type Description Dataset | None copy of class with results from func as image within collection property Source code in hydrafloods/datasets.py def apply ( self , func , inplace = False , * args , ** kwargs ): \"\"\"Alias for the `apply_func` method args: func (object): Function to map across image collection. Function must accept ee.Image as first argument inplace (bool, optional): define whether to return another dataset object or update inplace. default = False **kwargs: arbitrary keyword to pass to `func` returns: Dataset | None: copy of class with results from `func` as image within collection property \"\"\" return self . apply_func ( func , inplace , * args , * kwargs ) apply_func ( self , func , inplace = False , * args , ** kwargs ) Wrapper method to apply a function to all of the image in the dataset. Makes a copy of the collection and reassigns the image collection property. Function must accept an ee.ImageCollection and return an ee.ImageCollection Parameters: Name Type Description Default func object Function to map across image collection. Function must accept ee.Image as first argument required inplace bool define whether to return another dataset object or update inplace. default = False False **kwargs arbitrary keyword to pass to func {} Returns: Type Description Dataset | None copy of class with results from func as image within collection property Source code in hydrafloods/datasets.py def apply_func ( self , func , inplace = False , * args , ** kwargs ): \"\"\"Wrapper method to apply a function to all of the image in the dataset. Makes a copy of the collection and reassigns the image collection property. Function must accept an ee.ImageCollection and return an ee.ImageCollection args: func (object): Function to map across image collection. Function must accept ee.Image as first argument inplace (bool, optional): define whether to return another dataset object or update inplace. default = False **kwargs: arbitrary keyword to pass to `func` returns: Dataset | None: copy of class with results from `func` as image within collection property \"\"\" # get a partial function to map over imagery with the keywords applied # expects that the first positional arg is an func = partial ( func , ** kwargs ) out_coll = self . collection . map ( func ) return self . _inplace_wrapper ( out_coll , inplace ) band_pass_adjustment ( self , img ) Method to apply linear band transformation to dataset image collection. Expects that dataset has properties self.gain and self.bias set Parameters: Name Type Description Default img ee.Image image to apply regression on required Source code in hydrafloods/datasets.py @decorators . keep_attrs def band_pass_adjustment ( self , img ): \"\"\"Method to apply linear band transformation to dataset image collection. Expects that dataset has properties `self.gain` and `self.bias` set args: img (ee.Image): image to apply regression on \"\"\" # linear regression coefficients for adjustment return ( img . multiply ( self . gain ) . add ( self . bias ) . set ( \"system:time_start\" , img . get ( \"system:time_start\" )) ) clip_to_region ( self , inplace = False ) Clips all of the images to the geographic extent defined by region. Useful for setting geometries on unbounded imagery in collection (e.g. MODIS or VIIRS imagery) Parameters: Name Type Description Default inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset with imagery clipped to self.region or none depending on inplace Source code in hydrafloods/datasets.py def clip_to_region ( self , inplace = False ): \"\"\"Clips all of the images to the geographic extent defined by region. Useful for setting geometries on unbounded imagery in collection (e.g. MODIS or VIIRS imagery) args: inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset with imagery clipped to self.region or none depending on inplace \"\"\" @decorators . keep_attrs def clip ( img ): \"\"\"Closure function to perform the clipping while carrying metadata\"\"\" return ee . Image ( img . clip ( self . region )) out_coll = self . collection . map ( clip ) return self . _inplace_wrapper ( out_coll , inplace ) copy ( self ) returns a deep copy of the hydrafloods dataset class Source code in hydrafloods/datasets.py def copy ( self ): \"\"\"returns a deep copy of the hydrafloods dataset class\"\"\" return copy . deepcopy ( self ) filter ( self , filter , inplace = False ) Wrapper method for applying a filter to a datset collection. Parameters: Name Type Description Default filter ee.Filter an ee.Filter object to apply to the dataset collection. required Returns: Type Description Dataset | None returns the dataset with the filtered collection. Source code in hydrafloods/datasets.py def filter ( self , filter , inplace = False ): \"\"\"Wrapper method for applying a filter to a datset collection. args: filter (ee.Filter): an `ee.Filter` object to apply to the dataset collection. returns: Dataset | None: returns the dataset with the filtered collection. \"\"\" filtered = self . collection . filter ( filter ) return self . _inplace_wrapper ( filtered , inplace ) from_imgcollection ( img_collection ) staticmethod Static method to convert an ee.ImageCollection object to a hf.Dataset object. This method will take some time as it uses computed ee Objects from the image collection propeties to populate the Dataset object properties (passing info from server to client) Parameters: Name Type Description Default img_collection ee.ImageCollection computed ee.ImageCollection object to create a hf.Dataset required Returns: Type Description hf.Dataset dataset object with property information directly from the ee.ImageCollection Source code in hydrafloods/datasets.py @staticmethod def from_imgcollection ( img_collection ): \"\"\"Static method to convert an ee.ImageCollection object to a hf.Dataset object. This method will take some time as it uses computed ee Objects from the image collection propeties to populate the Dataset object properties (passing info from server to client) args: img_collection (ee.ImageCollection): computed ee.ImageCollection object to create a hf.Dataset returns: hf.Dataset: dataset object with property information directly from the ee.ImageCollection \"\"\" # get region and date information region = ( img_collection . map ( geeutils . get_geoms ) . union ( maxError = 100 ) . geometry ( maxError = 100 ) ) # convert ee.Date info to string format dates = ( img_collection . aggregate_array ( \"system:time_start\" ) . sort () . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd HH:mm:ss.S\" )) ) # pull the date info to local strings start_time = dates . get ( 0 ) . getInfo () end_time = dates . get ( - 1 ) . getInfo () # get the collection id for `.asset_id` property collection_id = img_collection . get ( \"system:id\" ) . getInfo () if collection_id == \"None\" : collection_id = \"Custom ImageCollection\" # make a dummy dataset dummy_ds = Dataset ( region , start_time , end_time , asset_id = \"NOAA/VIIRS/001/VNP09GA\" , use_qa = False , ) # override the dummy dataset information with the correct data fr dummy_ds . asset_id = collection_id dummy_ds . collection = img_collection return dummy_ds join ( self , dataset , inplace = False ) Performs spatiotemporal join between self.collection and dataset.collection. Result will be a dataset where the collection is colocated imagery in space and time Parameters: Name Type Description Default dataset Dataset dataset object to apply join with. Used as right in join operations required inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset where collection with joined imagery or none depending on inplace Source code in hydrafloods/datasets.py def join ( self , dataset , inplace = False ): \"\"\"Performs spatiotemporal join between self.collection and dataset.collection. Result will be a dataset where the collection is colocated imagery in space and time args: dataset (Dataset): dataset object to apply join with. Used as right in join operations inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection with joined imagery or none depending on inplace \"\"\" def _merge ( img ): \"\"\"Closure func to take results from the join and combine into one image with overlaping region\"\"\" join_coll = ee . ImageCollection . fromImages ( img . get ( key )) img_geom = img . geometry ( 100 ) join_geom = join_coll . map ( geeutils . get_geoms ) . union ( 100 ) . geometry ( 100 ) overlap = img_geom . intersection ( join_geom , 100 ) join_data = join_coll . mosaic () return img . addBands ( join_data ) . clip ( overlap ) key = str ( dataset . __class__ . __name__ ) # get a time and space filter filter = ee . Filter . And ( ee . Filter . maxDifference ( ** { \"difference\" : 1000 * 60 * 60 * 24 , # One day in milliseconds \"leftField\" : \"system:time_start\" , \"rightField\" : \"system:time_start\" , } ), ee . Filter . intersects ( ** { \"leftField\" : \".geo\" , \"rightField\" : \".geo\" , \"maxError\" : 100 } ), ) # apply join on collections and save all results joined = ee . ImageCollection ( ee . Join . saveAll ( key ) . apply ( primary = self . collection , secondary = dataset . collection , condition = filter ) ) # map over all filtered imagery, mosaic joined matches, and add bands to imagery joined = joined . map ( _merge ) return self . _inplace_wrapper ( joined , inplace ) merge ( self , dataset , inplace = False ) Merge the collection of two datasets into one where self.collection will contain imagery from self and dataset arg. Results will be sorted by time Parameters: Name Type Description Default dataset Dataset dataset object to merge required inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset where collection is merged imagery or none depending on inplace Source code in hydrafloods/datasets.py def merge ( self , dataset , inplace = False ): \"\"\"Merge the collection of two datasets into one where self.collection will contain imagery from self and dataset arg. Results will be sorted by time args: dataset (Dataset): dataset object to merge inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection is merged imagery or none depending on inplace \"\"\" merged = self . collection . merge ( dataset . collection ) . sort ( \"system:time_start\" ) return self . _inplace_wrapper ( merged , inplace ) pipe ( self , steps , inplace = False , keep_attrs = True ) Method to pipe imagery within dataset through multiple functions at once. Assumes the first argument into piped functions are and ee.Image Parameters: Name Type Description Default steps list | tuple iterable of functions/steps to apply to imagery. list must be in the form of (func,func) or with a tuple of function/keyword ((func,kwargs),func) required inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset.collection with piped functions applied Examples: s1 = hf . Sentinel1 ( ee . Geometry . Point ( 105.03 , 11.72 ), \"2019-10-03\" , \"2019-10-05\" ) water = s1 . pipe ( ( hf . gamma_map , #apply speckle filter ( hf . egde_ostu ,{ 'initial_threshold:-16}) # apply water mapping ) ) Source code in hydrafloods/datasets.py def pipe ( self , steps , inplace = False , keep_attrs = True ): \"\"\"Method to pipe imagery within dataset through multiple functions at once. Assumes the first argument into piped functions are and ee.Image args: steps (list | tuple): iterable of functions/steps to apply to imagery. list must be in the form of (func,func) or with a tuple of function/keyword ((func,kwargs),func) inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection with piped functions applied Example: ```python s1 = hf.Sentinel1(ee.Geometry.Point(105.03,11.72),\"2019-10-03\",\"2019-10-05\") water = s1.pipe( ( hf.gamma_map, #apply speckle filter (hf.egde_ostu,{'initial_threshold:-16}) # apply water mapping ) ) ``` \"\"\" def _piper ( funcs ): \"\"\"Closure function to nest list of functions\"\"\" if len ( funcs ) > 1 : one_shotter = funcs [ 0 ] for func in funcs [ 1 :]: one_shotter = pipe | one_shotter | func else : one_shotter = funcs [ 0 ] return one_shotter fs = [] # loop through the steps and create partial funcs is kwargs are provided for step in steps : try : func , kwargs = step except TypeError : func = step kwargs = None if kwargs is not None : pfunc = partial ( func , ** kwargs ) else : pfunc = func fs . append ( pfunc ) # get the piped function if keep_attrs : one_shot = decorators . keep_attrs ( _piper ( fs )) else : one_shot = _piper ( fs ) # apply pipe to each image out_coll = self . collection . map ( lambda img : one_shot ( img )) return self . _inplace_wrapper ( out_coll , inplace ) select ( self , * args , * , inplace = False ) Wrapper method for selecting bands from dataset collection Parameters: Name Type Description Default *args arbitrary arguments to pass to the ee.ImageCollection.select() method () inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns the dataset with the collection with selected bands. Source code in hydrafloods/datasets.py def select ( self , * args , inplace = False ): \"\"\"Wrapper method for selecting bands from dataset collection args: *args: arbitrary arguments to pass to the `ee.ImageCollection.select()` method inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns the dataset with the collection with selected bands. \"\"\" selected = self . collection . select ( * args ) return self . _inplace_wrapper ( selected , inplace ) hydrafloods.datasets.Sentinel1 ( Dataset ) Class extending dataset for the Sentinel 1 collection This Sentinel 1 dataset is in backscatter units Source code in hydrafloods/datasets.py class Sentinel1 ( Dataset ): \"\"\"Class extending dataset for the Sentinel 1 collection This Sentinel 1 dataset is in backscatter units \"\"\" def __init__ ( self , * args , asset_id = \"COPERNICUS/S1_GRD\" , use_qa = True , ** kwargs ): \"\"\"Initialize Sentinel1 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel 1 earth engine collection. default=\"COPERNICUS/S1_GRD\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel1 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . filter ( ee . Filter . listContains ( \"transmitterReceiverPolarisation\" , \"VH\" ) ) return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel1 backscatter based on view angle Angle threshold values taken from https://doi.org/10.3390/rs13101954 \"\"\" angle = img . select ( \"angle\" ) angle_mask = angle . lt ( 45.23993 ) . And ( angle . gt ( 30.63993 )) return img . updateMask ( angle_mask ) def add_orbit_band ( self , inplace = False ): \"\"\"Method to add orbit band from S1 image metadata Useful for determining if pixels are from ascending or descending orbits args: inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection where imagery has the added bands \"\"\" def _add_features ( img ): \"\"\"Closure function to add features as bands to the images\"\"\" bounds = img . geometry ( 100 ) orbit = ee . String ( img . get ( \"orbitProperties_pass\" )) orbit_band = ee . Algorithms . If ( orbit . compareTo ( \"DESCENDING\" ), ee . Image ( 1 ), ee . Image ( 0 ) ) extraFeatures = ee . Image ( orbit_band ) . rename ( \"orbit\" ) return img . addBands ( extraFeatures . clip ( bounds )) return self . apply_func ( _add_features , inplace = inplace ) def to_db ( self , inplace = False ): \"\"\"Convience method to convert units from power to db\"\"\" out_coll = self . collection . map ( geeutils . power_to_db ) if inplace : self . collection = out_coll return else : outCls = self . copy () outCls . collection = out_coll return outCls def to_power ( self , inplace = False ): \"\"\"Convience method to convert units from db to power\"\"\" out_coll = self . collection . map ( geeutils . db_to_power ) if inplace : self . collection = out_coll return else : outCls = self . copy () outCls . collection = out_coll return outCls __init__ ( self , * args , * , asset_id = 'COPERNICUS/S1_GRD' , use_qa = True , ** kwargs ) special Initialize Sentinel1 Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Sentinel 1 earth engine collection. default=\"COPERNICUS/S1_GRD\" 'COPERNICUS/S1_GRD' use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"COPERNICUS/S1_GRD\" , use_qa = True , ** kwargs ): \"\"\"Initialize Sentinel1 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel 1 earth engine collection. default=\"COPERNICUS/S1_GRD\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel1 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . filter ( ee . Filter . listContains ( \"transmitterReceiverPolarisation\" , \"VH\" ) ) return add_orbit_band ( self , inplace = False ) Method to add orbit band from S1 image metadata Useful for determining if pixels are from ascending or descending orbits Parameters: Name Type Description Default inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset.collection where imagery has the added bands Source code in hydrafloods/datasets.py def add_orbit_band ( self , inplace = False ): \"\"\"Method to add orbit band from S1 image metadata Useful for determining if pixels are from ascending or descending orbits args: inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection where imagery has the added bands \"\"\" def _add_features ( img ): \"\"\"Closure function to add features as bands to the images\"\"\" bounds = img . geometry ( 100 ) orbit = ee . String ( img . get ( \"orbitProperties_pass\" )) orbit_band = ee . Algorithms . If ( orbit . compareTo ( \"DESCENDING\" ), ee . Image ( 1 ), ee . Image ( 0 ) ) extraFeatures = ee . Image ( orbit_band ) . rename ( \"orbit\" ) return img . addBands ( extraFeatures . clip ( bounds )) return self . apply_func ( _add_features , inplace = inplace ) qa ( self , img ) Custom QA masking method for Sentinel1 backscatter based on view angle Angle threshold values taken from https://doi.org/10.3390/rs13101954 Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel1 backscatter based on view angle Angle threshold values taken from https://doi.org/10.3390/rs13101954 \"\"\" angle = img . select ( \"angle\" ) angle_mask = angle . lt ( 45.23993 ) . And ( angle . gt ( 30.63993 )) return img . updateMask ( angle_mask ) to_db ( self , inplace = False ) Convience method to convert units from power to db Source code in hydrafloods/datasets.py def to_db ( self , inplace = False ): \"\"\"Convience method to convert units from power to db\"\"\" out_coll = self . collection . map ( geeutils . power_to_db ) if inplace : self . collection = out_coll return else : outCls = self . copy () outCls . collection = out_coll return outCls to_power ( self , inplace = False ) Convience method to convert units from db to power Source code in hydrafloods/datasets.py def to_power ( self , inplace = False ): \"\"\"Convience method to convert units from db to power\"\"\" out_coll = self . collection . map ( geeutils . db_to_power ) if inplace : self . collection = out_coll return else : outCls = self . copy () outCls . collection = out_coll return outCls hydrafloods.datasets.Sentinel2 ( Dataset ) Source code in hydrafloods/datasets.py class Sentinel2 ( Dataset ): def __init__ ( self , * args , asset_id = \"COPERNICUS/S2_SR\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize Sentinel2 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel2 earth engine collection. default=\"COPERNICUS/S2_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel2 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"sen2\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken HLS project https://hls.gsfc.nasa.gov/algorithms/bandpass-adjustment/ # slope coefficients self . gain = ee . Image . constant ( [ 0.9778 , 1.0053 , 0.9765 , 0.9983 , 0.9987 , 1.003 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ - 0.00411 , - 0.00093 , 0.00094 , - 0.0001 , - 0.0015 , - 0.0012 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel2 surface reflectance dataset\"\"\" CLD_PRB_THRESH = 40 NIR_DRK_THRESH = 0.175 * 1e4 CLD_PRJ_DIST = 3 BUFFER = 100 CRS = img . select ( 0 ) . projection () # Get s2cloudless image, subset the probability band. cld_prb = ee . Image ( ee . ImageCollection ( \"COPERNICUS/S2_CLOUD_PROBABILITY\" ) . filter ( ee . Filter . eq ( \"system:index\" , img . get ( \"system:index\" ))) . first () ) . select ( \"probability\" ) # Condition s2cloudless by the probability threshold value. is_cloud = cld_prb . gt ( CLD_PRB_THRESH ) # Identify water pixels from the SCL band, invert. not_water = img . select ( \"SCL\" ) . neq ( 6 ) # Identify dark NIR pixels that are not water (potential cloud shadow pixels). dark_pixels = img . select ( \"B8\" ) . lt ( NIR_DRK_THRESH ) . multiply ( not_water ) # Determine the direction to project cloud shadow from clouds (assumes UTM projection). shadow_azimuth = ee . Number ( 90 ) . subtract ( ee . Number ( img . get ( \"MEAN_SOLAR_AZIMUTH_ANGLE\" )) ) # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input. cld_proj = ( is_cloud . directionalDistanceTransform ( shadow_azimuth , CLD_PRJ_DIST * 10 ) . reproject ( ** { \"crs\" : CRS , \"scale\" : 120 }) . select ( \"distance\" ) . mask () ) # Identify the intersection of dark pixels with cloud shadow projection. is_shadow = cld_proj . multiply ( dark_pixels ) # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0. is_cld_shdw = is_cloud . add ( is_shadow ) . gt ( 0 ) # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input. # 20 m scale is for speed, and assumes clouds don't require 10 m precision. is_cld_shdw = ( is_cld_shdw . focal_min ( 2 ) . focal_max ( BUFFER * 2 / 20 ) . reproject ( ** { \"crs\" : CRS , \"scale\" : 60 }) . rename ( \"cloudmask\" ) ) # Subset reflectance bands and update their masks, return the result. return geeutils . rescale ( img ) . select ( \"B.*\" ) . updateMask ( is_cld_shdw . Not ()) __init__ ( self , * args , * , asset_id = 'COPERNICUS/S2_SR' , use_qa = True , apply_band_adjustment = False , ** kwargs ) special Initialize Sentinel2 Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Sentinel2 earth engine collection. default=\"COPERNICUS/S2_SR\" 'COPERNICUS/S2_SR' use_qa bool boolean to determine to use a private self.qa() function. default=True True apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False rescale bool boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False required **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"COPERNICUS/S2_SR\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize Sentinel2 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel2 earth engine collection. default=\"COPERNICUS/S2_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel2 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"sen2\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken HLS project https://hls.gsfc.nasa.gov/algorithms/bandpass-adjustment/ # slope coefficients self . gain = ee . Image . constant ( [ 0.9778 , 1.0053 , 0.9765 , 0.9983 , 0.9987 , 1.003 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ - 0.00411 , - 0.00093 , 0.00094 , - 0.0001 , - 0.0015 , - 0.0012 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return qa ( self , img ) Custom QA masking method for Sentinel2 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel2 surface reflectance dataset\"\"\" CLD_PRB_THRESH = 40 NIR_DRK_THRESH = 0.175 * 1e4 CLD_PRJ_DIST = 3 BUFFER = 100 CRS = img . select ( 0 ) . projection () # Get s2cloudless image, subset the probability band. cld_prb = ee . Image ( ee . ImageCollection ( \"COPERNICUS/S2_CLOUD_PROBABILITY\" ) . filter ( ee . Filter . eq ( \"system:index\" , img . get ( \"system:index\" ))) . first () ) . select ( \"probability\" ) # Condition s2cloudless by the probability threshold value. is_cloud = cld_prb . gt ( CLD_PRB_THRESH ) # Identify water pixels from the SCL band, invert. not_water = img . select ( \"SCL\" ) . neq ( 6 ) # Identify dark NIR pixels that are not water (potential cloud shadow pixels). dark_pixels = img . select ( \"B8\" ) . lt ( NIR_DRK_THRESH ) . multiply ( not_water ) # Determine the direction to project cloud shadow from clouds (assumes UTM projection). shadow_azimuth = ee . Number ( 90 ) . subtract ( ee . Number ( img . get ( \"MEAN_SOLAR_AZIMUTH_ANGLE\" )) ) # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input. cld_proj = ( is_cloud . directionalDistanceTransform ( shadow_azimuth , CLD_PRJ_DIST * 10 ) . reproject ( ** { \"crs\" : CRS , \"scale\" : 120 }) . select ( \"distance\" ) . mask () ) # Identify the intersection of dark pixels with cloud shadow projection. is_shadow = cld_proj . multiply ( dark_pixels ) # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0. is_cld_shdw = is_cloud . add ( is_shadow ) . gt ( 0 ) # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input. # 20 m scale is for speed, and assumes clouds don't require 10 m precision. is_cld_shdw = ( is_cld_shdw . focal_min ( 2 ) . focal_max ( BUFFER * 2 / 20 ) . reproject ( ** { \"crs\" : CRS , \"scale\" : 60 }) . rename ( \"cloudmask\" ) ) # Subset reflectance bands and update their masks, return the result. return geeutils . rescale ( img ) . select ( \"B.*\" ) . updateMask ( is_cld_shdw . Not ()) hydrafloods.datasets.Landsat8 ( Dataset ) Source code in hydrafloods/datasets.py class Landsat8 ( Dataset ): def __init__ ( self , * args , asset_id = \"LANDSAT/LC08/C02/T1_L2\" , use_qa = True , ** kwargs , ): \"\"\"Initialize Landsat8 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat earth engine collection. default=\"LANDSAT/LC08/C01/T1_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat8 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"landsat8\" ), self . BANDREMAP . get ( \"new\" ) ) return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Landsat8 surface reflectance dataset\"\"\" qa_band = img . select ( \"QA_PIXEL\" ) qa_flag = int ( '111111' , 2 ) sat_mask = img . select ( 'QA_RADSAT' ) . eq ( 0 ); mask = qa_band . bitwiseAnd ( qa_flag ) . eq ( 0 ) . And ( sat_mask ) return geeutils . rescale ( img , scale = 0.0000275 , offset = - 0.2 ) . updateMask ( mask ) __init__ ( self , * args , * , asset_id = 'LANDSAT/LC08/C02/T1_L2' , use_qa = True , ** kwargs ) special Initialize Landsat8 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Landsat earth engine collection. default=\"LANDSAT/LC08/C01/T1_SR\" 'LANDSAT/LC08/C02/T1_L2' use_qa bool boolean to determine to use a private self.qa() function. default=True True rescale bool boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False required **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"LANDSAT/LC08/C02/T1_L2\" , use_qa = True , ** kwargs , ): \"\"\"Initialize Landsat8 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat earth engine collection. default=\"LANDSAT/LC08/C01/T1_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat8 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"landsat8\" ), self . BANDREMAP . get ( \"new\" ) ) return qa ( self , img ) Custom QA masking method for Landsat8 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Landsat8 surface reflectance dataset\"\"\" qa_band = img . select ( \"QA_PIXEL\" ) qa_flag = int ( '111111' , 2 ) sat_mask = img . select ( 'QA_RADSAT' ) . eq ( 0 ); mask = qa_band . bitwiseAnd ( qa_flag ) . eq ( 0 ) . And ( sat_mask ) return geeutils . rescale ( img , scale = 0.0000275 , offset = - 0.2 ) . updateMask ( mask ) hydrafloods.datasets.Landsat7 ( Dataset ) Source code in hydrafloods/datasets.py class Landsat7 ( Dataset ): def __init__ ( self , * args , asset_id = \"LANDSAT/LE07/C02/T1_L2\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize Landsat7 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat7 earth engine collection. default=\"LANDSAT/LE07/C01/T1_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat7 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"landsat7\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken from Roy et al., 2016 http://dx.doi.org/10.1016/j.rse.2015.12.024 # slope coefficients self . gain = ee . Image . constant ( [ 0.8474 , 0.8483 , 0.9047 , 0.8462 , 0.8937 , 0.9071 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.0003 , 0.0088 , 0.0061 , 0.0412 , 0.0254 , 0.0172 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Landsat7 surface reflectance dataset\"\"\" qa_band = img . select ( \"QA_PIXEL\" ) qa_flag = int ( '111111' , 2 ) sat_mask = img . select ( 'QA_RADSAT' ) . eq ( 0 ); mask = qa_band . bitwiseAnd ( qa_flag ) . eq ( 0 ) . And ( sat_mask ) return geeutils . rescale ( img , scale = 0.0000275 , offset = - 0.2 ) . updateMask ( mask ) __init__ ( self , * args , * , asset_id = 'LANDSAT/LE07/C02/T1_L2' , use_qa = True , apply_band_adjustment = False , ** kwargs ) special Initialize Landsat7 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Landsat7 earth engine collection. default=\"LANDSAT/LE07/C01/T1_SR\" 'LANDSAT/LE07/C02/T1_L2' use_qa bool boolean to determine to use a private self.qa() function. default=True True apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False rescale bool boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False required **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"LANDSAT/LE07/C02/T1_L2\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize Landsat7 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat7 earth engine collection. default=\"LANDSAT/LE07/C01/T1_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat7 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"landsat7\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken from Roy et al., 2016 http://dx.doi.org/10.1016/j.rse.2015.12.024 # slope coefficients self . gain = ee . Image . constant ( [ 0.8474 , 0.8483 , 0.9047 , 0.8462 , 0.8937 , 0.9071 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.0003 , 0.0088 , 0.0061 , 0.0412 , 0.0254 , 0.0172 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return qa ( self , img ) Custom QA masking method for Landsat7 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Landsat7 surface reflectance dataset\"\"\" qa_band = img . select ( \"QA_PIXEL\" ) qa_flag = int ( '111111' , 2 ) sat_mask = img . select ( 'QA_RADSAT' ) . eq ( 0 ); mask = qa_band . bitwiseAnd ( qa_flag ) . eq ( 0 ) . And ( sat_mask ) return geeutils . rescale ( img , scale = 0.0000275 , offset = - 0.2 ) . updateMask ( mask ) hydrafloods.datasets.Viirs ( Dataset ) Source code in hydrafloods/datasets.py class Viirs ( Dataset ): def __init__ ( self , * args , asset_id = \"NOAA/VIIRS/001/VNP09GA\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize VIIRS Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the VIIRS earth engine collection. default=\"NOAA/VIIRS/001/VNP09GA\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Viirs , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) # get the bands and rename to common optical names coll = self . collection . select ( self . BANDREMAP . get ( \"viirs\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken calculated from https://code.earthengine.google.com/876f53861690e483fb3e3439a3571f27 # slope coefficients self . gain = ee . Image . constant ( [ 0.68328 , 0.66604 , 0.78901 , 0.95324 , 0.98593 , 0.88941 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.016728 , 0.030814 , 0.023199 , 0.036571 , 0.026923 , 0.021615 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for VIIRS VNP09GA dataset\"\"\" cloudMask = geeutils . extract_bits ( img . select ( \"QF1\" ), 2 , end = 3 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 3 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 5 , new_name = \"snow_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) env_mask = cloudMask . And ( shadowMask ) . And ( sensorZenith ) # internal pixel quality masks pixal_quality_3 = img . select ( \"QF3\" ) pixal_quality_4 = img . select ( \"QF4\" ) m2_qual = geeutils . extract_bits ( pixal_quality_3 , 1 , new_name = \"m2_quality\" ) . eq ( 0 ) m4_qual = geeutils . extract_bits ( pixal_quality_3 , 3 , new_name = \"m4_quality\" ) . eq ( 0 ) m11_qual = geeutils . extract_bits ( pixal_quality_4 , 0 , new_name = \"m11_quality\" ) . eq ( 0 ) i1_qual = geeutils . extract_bits ( pixal_quality_4 , 1 , new_name = \"i1_quality\" ) . eq ( 0 ) i2_qual = geeutils . extract_bits ( pixal_quality_4 , 2 , new_name = \"i2_quality\" ) . eq ( 0 ) i3_qual = geeutils . extract_bits ( pixal_quality_4 , 3 , new_name = \"i3_quality\" ) . eq ( 0 ) qual_mask = m2_qual . And ( m4_qual ) . And ( m11_qual ) . And ( i1_qual ) . And ( i2_qual ) . And ( i3_qual ) mask = env_mask . And ( qual_mask ) return geeutils . rescale ( img ) . updateMask ( mask ) __init__ ( self , * args , * , asset_id = 'NOAA/VIIRS/001/VNP09GA' , use_qa = True , apply_band_adjustment = False , ** kwargs ) special Initialize VIIRS Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the VIIRS earth engine collection. default=\"NOAA/VIIRS/001/VNP09GA\" 'NOAA/VIIRS/001/VNP09GA' use_qa bool boolean to determine to use a private self.qa() function. default=True True apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False rescale bool boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False required **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"NOAA/VIIRS/001/VNP09GA\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize VIIRS Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the VIIRS earth engine collection. default=\"NOAA/VIIRS/001/VNP09GA\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Viirs , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) # get the bands and rename to common optical names coll = self . collection . select ( self . BANDREMAP . get ( \"viirs\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken calculated from https://code.earthengine.google.com/876f53861690e483fb3e3439a3571f27 # slope coefficients self . gain = ee . Image . constant ( [ 0.68328 , 0.66604 , 0.78901 , 0.95324 , 0.98593 , 0.88941 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.016728 , 0.030814 , 0.023199 , 0.036571 , 0.026923 , 0.021615 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return qa ( self , img ) Custom QA masking method for VIIRS VNP09GA dataset Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for VIIRS VNP09GA dataset\"\"\" cloudMask = geeutils . extract_bits ( img . select ( \"QF1\" ), 2 , end = 3 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 3 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 5 , new_name = \"snow_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) env_mask = cloudMask . And ( shadowMask ) . And ( sensorZenith ) # internal pixel quality masks pixal_quality_3 = img . select ( \"QF3\" ) pixal_quality_4 = img . select ( \"QF4\" ) m2_qual = geeutils . extract_bits ( pixal_quality_3 , 1 , new_name = \"m2_quality\" ) . eq ( 0 ) m4_qual = geeutils . extract_bits ( pixal_quality_3 , 3 , new_name = \"m4_quality\" ) . eq ( 0 ) m11_qual = geeutils . extract_bits ( pixal_quality_4 , 0 , new_name = \"m11_quality\" ) . eq ( 0 ) i1_qual = geeutils . extract_bits ( pixal_quality_4 , 1 , new_name = \"i1_quality\" ) . eq ( 0 ) i2_qual = geeutils . extract_bits ( pixal_quality_4 , 2 , new_name = \"i2_quality\" ) . eq ( 0 ) i3_qual = geeutils . extract_bits ( pixal_quality_4 , 3 , new_name = \"i3_quality\" ) . eq ( 0 ) qual_mask = m2_qual . And ( m4_qual ) . And ( m11_qual ) . And ( i1_qual ) . And ( i2_qual ) . And ( i3_qual ) mask = env_mask . And ( qual_mask ) return geeutils . rescale ( img ) . updateMask ( mask ) hydrafloods.datasets.Modis ( Dataset ) Source code in hydrafloods/datasets.py class Modis ( Dataset ): def __init__ ( self , * args , asset_id = \"MODIS/006/MOD09GA\" , use_qa = True , ** kwargs ): \"\"\"Initialize MODIS Dataset class Can be used with MOD09GA and MYD09GA args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the MODIS earth engine collection. default=\"MODIS/006/MOD09GA\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Modis , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"modis\" ), self . BANDREMAP . get ( \"new\" ) ) return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for MODIS MXD09GA dataset\"\"\" # internal env masks qa = img . select ( \"state_1km\" ) cloudMask = geeutils . extract_bits ( qa , 10 , end = 11 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( qa , 2 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( qa , 12 , new_name = \"snow_qa\" ) . Not () cloudAdjMask = geeutils . extract_bits ( qa , 13 , new_name = \"cloud_adjacency_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) env_mask = cloudMask . And ( shadowMask ) . And ( snowMask ) . And ( sensorZenith ) . And ( cloudAdjMask ) # internal pixel quality masks pixal_quality = img . select ( \"QC_500m\" ) b1_qual = geeutils . extract_bits ( pixal_quality , 2 , end = 5 , new_name = \"b1_quality\" ) . eq ( 0 ) b2_qual = geeutils . extract_bits ( pixal_quality , 6 , end = 9 , new_name = \"b1_quality\" ) . eq ( 0 ) b3_qual = geeutils . extract_bits ( pixal_quality , 10 , end = 13 , new_name = \"b1_quality\" ) . eq ( 0 ) b4_qual = geeutils . extract_bits ( pixal_quality , 14 , end = 17 , new_name = \"b1_quality\" ) . eq ( 0 ) b6_qual = geeutils . extract_bits ( pixal_quality , 22 , end = 25 , new_name = \"b1_quality\" ) . eq ( 0 ) b7_qual = geeutils . extract_bits ( pixal_quality , 26 , end = 29 , new_name = \"b1_quality\" ) . eq ( 0 ) qual_mask = b1_qual . And ( b2_qual ) . And ( b3_qual ) . And ( b4_qual ) . And ( b6_qual ) . And ( b7_qual ) mask = env_mask . And ( qual_mask ) return geeutils . rescale ( img ) . updateMask ( mask ) __init__ ( self , * args , * , asset_id = 'MODIS/006/MOD09GA' , use_qa = True , ** kwargs ) special Initialize MODIS Dataset class Can be used with MOD09GA and MYD09GA Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the MODIS earth engine collection. default=\"MODIS/006/MOD09GA\" 'MODIS/006/MOD09GA' use_qa bool boolean to determine to use a private self.qa() function. default=True True rescale bool boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False required **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"MODIS/006/MOD09GA\" , use_qa = True , ** kwargs ): \"\"\"Initialize MODIS Dataset class Can be used with MOD09GA and MYD09GA args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the MODIS earth engine collection. default=\"MODIS/006/MOD09GA\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Modis , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"modis\" ), self . BANDREMAP . get ( \"new\" ) ) return qa ( self , img ) Custom QA masking method for MODIS MXD09GA dataset Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for MODIS MXD09GA dataset\"\"\" # internal env masks qa = img . select ( \"state_1km\" ) cloudMask = geeutils . extract_bits ( qa , 10 , end = 11 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( qa , 2 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( qa , 12 , new_name = \"snow_qa\" ) . Not () cloudAdjMask = geeutils . extract_bits ( qa , 13 , new_name = \"cloud_adjacency_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) env_mask = cloudMask . And ( shadowMask ) . And ( snowMask ) . And ( sensorZenith ) . And ( cloudAdjMask ) # internal pixel quality masks pixal_quality = img . select ( \"QC_500m\" ) b1_qual = geeutils . extract_bits ( pixal_quality , 2 , end = 5 , new_name = \"b1_quality\" ) . eq ( 0 ) b2_qual = geeutils . extract_bits ( pixal_quality , 6 , end = 9 , new_name = \"b1_quality\" ) . eq ( 0 ) b3_qual = geeutils . extract_bits ( pixal_quality , 10 , end = 13 , new_name = \"b1_quality\" ) . eq ( 0 ) b4_qual = geeutils . extract_bits ( pixal_quality , 14 , end = 17 , new_name = \"b1_quality\" ) . eq ( 0 ) b6_qual = geeutils . extract_bits ( pixal_quality , 22 , end = 25 , new_name = \"b1_quality\" ) . eq ( 0 ) b7_qual = geeutils . extract_bits ( pixal_quality , 26 , end = 29 , new_name = \"b1_quality\" ) . eq ( 0 ) qual_mask = b1_qual . And ( b2_qual ) . And ( b3_qual ) . And ( b4_qual ) . And ( b6_qual ) . And ( b7_qual ) mask = env_mask . And ( qual_mask ) return geeutils . rescale ( img ) . updateMask ( mask )","title":"datasets module"},{"location":"datasets/#hydrafloods.datasets.Dataset","text":"Base dataset class used to define an EE image collection by datetime and geographic region A dataset wraps an ee.ImageCollection by applying the spatial and temporal filtering upon init. Provides utility functionality to make working with and managing image collections less verbose Examples: Create a dataset object for Sentinel-1 data over Alabama for 2019 >>> ds = Dataset ( ... region = ee . Geometry . Rectangle ([ - 88.473227 , 30.223334 , - 84.88908 , 35.008028 ]), ... start_time = \"2019-01-01\" , ... end_time = \"2020-01-01\" , ... asset_id = \"COPERNICUS/S1_GRD\" ... ) >>> ds HYDRAFloods Dataset : { 'asset_id' : 'COPERNICUS/S1_GRD' , 'end_time' : '2020-01-01' , 'name' : 'Dataset' , 'region' : [[[ ... ], [ ... ], [ ... ], [ ... ], [ ... ]]], 'start_time' : '2019-01-01' } Source code in hydrafloods/datasets.py class Dataset : \"\"\"Base dataset class used to define an EE image collection by datetime and geographic region A dataset wraps an ee.ImageCollection by applying the spatial and temporal filtering upon init. Provides utility functionality to make working with and managing image collections less verbose Example: Create a dataset object for Sentinel-1 data over Alabama for 2019 >>> ds = Dataset( ... region = ee.Geometry.Rectangle([ -88.473227, 30.223334, -84.88908, 35.008028 ]), ... start_time = \"2019-01-01\", ... end_time = \"2020-01-01\", ... asset_id = \"COPERNICUS/S1_GRD\" ... ) >>> ds HYDRAFloods Dataset: {'asset_id': 'COPERNICUS/S1_GRD', 'end_time': '2020-01-01', 'name': 'Dataset', 'region': [[[...], [...], [...], [...], [...]]], 'start_time': '2019-01-01'} \"\"\" def __init__ ( self , region , start_time , end_time , asset_id , use_qa = False ): \"\"\"Initialize Dataset class args: region (ee.Geometry): earth engine geometry object to filter image collection by start_time (str | datetime.datetime): start time used to filter image collection end_time (str | datetime.datetime): end time used to filter image collection asset_id (str): asset id of earth engine collection use_qa (bool, optional): boolean to determine to use an internal function qa(). Used for definining custom dataset objects raises: AttributeError: if qa() method is not defined and use_qa is True \"\"\" # TODO: add exceptions to check datatypes self . region = region # dtype = ee.Geometry self . start_time = start_time self . end_time = end_time self . asset_id = asset_id self . use_qa = use_qa # dictionary mapping of band names used to harmonized optical datasets to same names self . BANDREMAP = ee . Dictionary ( { \"landsat7\" : ee . List ([ \"SR_B1\" , \"SR_B2\" , \"SR_B3\" , \"SR_B4\" , \"SR_B5\" , \"SR_B7\" ]), \"landsat8\" : ee . List ([ \"SR_B2\" , \"SR_B3\" , \"SR_B4\" , \"SR_B5\" , \"SR_B6\" , \"SR_B7\" ]), \"viirs\" : ee . List ([ \"M2\" , \"M4\" , \"I1\" , \"I2\" , \"I3\" , \"M11\" ]), \"sen2\" : ee . List ([ \"B2\" , \"B3\" , \"B4\" , \"B8\" , \"B11\" , \"B12\" ]), \"modis\" : ee . List ( [ \"sur_refl_b03\" , \"sur_refl_b04\" , \"sur_refl_b01\" , \"sur_refl_b02\" , \"sur_refl_b06\" , \"sur_refl_b07\" , ] ), \"new\" : ee . List ([ \"blue\" , \"green\" , \"red\" , \"nir\" , \"swir1\" , \"swir2\" ]), } ) # get the image collection and filter by geographic region and date time imgcollection = ( ee . ImageCollection ( self . asset_id ) . filterBounds ( self . region ) . filterDate ( self . start_time , self . end_time ) ) # check if to apply arbitrary qa process on collection # qa function can be defined in custom objects extending dataset if self . use_qa : try : imgcollection = imgcollection . map ( self . qa ) except AttributeError : raise AttributeError ( \"qa() method is not defined...please define one or set `use_qa` to False\" ) self . collection = imgcollection def __repr__ ( self ): # format datetime information if isinstance ( self . start_time , datetime . datetime ): ststr = self . start_time . strftime ( \"%Y-%m- %d \" ) else : ststr = self . start_time if isinstance ( self . end_time , datetime . datetime ): etstr = self . end_time . strftime ( \"%Y-%m- %d \" ) else : etstr = self . end_time # create dict of dataset information objDict = { \"name\" : self . __class__ . __name__ , \"asset_id\" : self . asset_id , \"start_time\" : ststr , \"end_time\" : etstr , \"region\" : self . region . coordinates () . getInfo (), } # pretty format dict and return information strRepr = pformat ( objDict , depth = 3 ) return f \"HYDRAFloods Dataset: \\n { strRepr } \" @property def collection ( self ): \"\"\"image collection object property wrapped by dataset\"\"\" return self . _collection @collection . setter def collection ( self , value ): \"\"\"setter function for collection property\"\"\" self . _collection = value return @property def n_images ( self ): \"\"\"Number of images contained in the dataset\"\"\" return self . collection . size () . getInfo () @property def dates ( self ): \"\"\"Dates of imagery contained in the image collection\"\"\" eeDates = self . collection . aggregate_array ( \"system:time_start\" ) . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd HH:mm:ss.SSS\" ) ) return eeDates . getInfo () @staticmethod def from_imgcollection ( img_collection ): \"\"\"Static method to convert an ee.ImageCollection object to a hf.Dataset object. This method will take some time as it uses computed ee Objects from the image collection propeties to populate the Dataset object properties (passing info from server to client) args: img_collection (ee.ImageCollection): computed ee.ImageCollection object to create a hf.Dataset returns: hf.Dataset: dataset object with property information directly from the ee.ImageCollection \"\"\" # get region and date information region = ( img_collection . map ( geeutils . get_geoms ) . union ( maxError = 100 ) . geometry ( maxError = 100 ) ) # convert ee.Date info to string format dates = ( img_collection . aggregate_array ( \"system:time_start\" ) . sort () . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd HH:mm:ss.S\" )) ) # pull the date info to local strings start_time = dates . get ( 0 ) . getInfo () end_time = dates . get ( - 1 ) . getInfo () # get the collection id for `.asset_id` property collection_id = img_collection . get ( \"system:id\" ) . getInfo () if collection_id == \"None\" : collection_id = \"Custom ImageCollection\" # make a dummy dataset dummy_ds = Dataset ( region , start_time , end_time , asset_id = \"NOAA/VIIRS/001/VNP09GA\" , use_qa = False , ) # override the dummy dataset information with the correct data fr dummy_ds . asset_id = collection_id dummy_ds . collection = img_collection return dummy_ds def qa ( self , ): return def _inplace_wrapper ( self , collection , inplace ): \"\"\"Private helper function to replace the collection info for a class typically used when other class methods have inplace \"\"\" if inplace : self . collection = collection return else : outCls = self . copy () outCls . collection = collection return outCls def copy ( self ): \"\"\"returns a deep copy of the hydrafloods dataset class\"\"\" return copy . deepcopy ( self ) def apply_func ( self , func , inplace = False , * args , ** kwargs ): \"\"\"Wrapper method to apply a function to all of the image in the dataset. Makes a copy of the collection and reassigns the image collection property. Function must accept an ee.ImageCollection and return an ee.ImageCollection args: func (object): Function to map across image collection. Function must accept ee.Image as first argument inplace (bool, optional): define whether to return another dataset object or update inplace. default = False **kwargs: arbitrary keyword to pass to `func` returns: Dataset | None: copy of class with results from `func` as image within collection property \"\"\" # get a partial function to map over imagery with the keywords applied # expects that the first positional arg is an func = partial ( func , ** kwargs ) out_coll = self . collection . map ( func ) return self . _inplace_wrapper ( out_coll , inplace ) def apply ( self , func , inplace = False , * args , ** kwargs ): \"\"\"Alias for the `apply_func` method args: func (object): Function to map across image collection. Function must accept ee.Image as first argument inplace (bool, optional): define whether to return another dataset object or update inplace. default = False **kwargs: arbitrary keyword to pass to `func` returns: Dataset | None: copy of class with results from `func` as image within collection property \"\"\" return self . apply_func ( func , inplace , * args , * kwargs ) def filter ( self , filter , inplace = False ): \"\"\"Wrapper method for applying a filter to a datset collection. args: filter (ee.Filter): an `ee.Filter` object to apply to the dataset collection. returns: Dataset | None: returns the dataset with the filtered collection. \"\"\" filtered = self . collection . filter ( filter ) return self . _inplace_wrapper ( filtered , inplace ) def select ( self , * args , inplace = False ): \"\"\"Wrapper method for selecting bands from dataset collection args: *args: arbitrary arguments to pass to the `ee.ImageCollection.select()` method inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns the dataset with the collection with selected bands. \"\"\" selected = self . collection . select ( * args ) return self . _inplace_wrapper ( selected , inplace ) def clip_to_region ( self , inplace = False ): \"\"\"Clips all of the images to the geographic extent defined by region. Useful for setting geometries on unbounded imagery in collection (e.g. MODIS or VIIRS imagery) args: inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset with imagery clipped to self.region or none depending on inplace \"\"\" @decorators . keep_attrs def clip ( img ): \"\"\"Closure function to perform the clipping while carrying metadata\"\"\" return ee . Image ( img . clip ( self . region )) out_coll = self . collection . map ( clip ) return self . _inplace_wrapper ( out_coll , inplace ) def merge ( self , dataset , inplace = False ): \"\"\"Merge the collection of two datasets into one where self.collection will contain imagery from self and dataset arg. Results will be sorted by time args: dataset (Dataset): dataset object to merge inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection is merged imagery or none depending on inplace \"\"\" merged = self . collection . merge ( dataset . collection ) . sort ( \"system:time_start\" ) return self . _inplace_wrapper ( merged , inplace ) def join ( self , dataset , inplace = False ): \"\"\"Performs spatiotemporal join between self.collection and dataset.collection. Result will be a dataset where the collection is colocated imagery in space and time args: dataset (Dataset): dataset object to apply join with. Used as right in join operations inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection with joined imagery or none depending on inplace \"\"\" def _merge ( img ): \"\"\"Closure func to take results from the join and combine into one image with overlaping region\"\"\" join_coll = ee . ImageCollection . fromImages ( img . get ( key )) img_geom = img . geometry ( 100 ) join_geom = join_coll . map ( geeutils . get_geoms ) . union ( 100 ) . geometry ( 100 ) overlap = img_geom . intersection ( join_geom , 100 ) join_data = join_coll . mosaic () return img . addBands ( join_data ) . clip ( overlap ) key = str ( dataset . __class__ . __name__ ) # get a time and space filter filter = ee . Filter . And ( ee . Filter . maxDifference ( ** { \"difference\" : 1000 * 60 * 60 * 24 , # One day in milliseconds \"leftField\" : \"system:time_start\" , \"rightField\" : \"system:time_start\" , } ), ee . Filter . intersects ( ** { \"leftField\" : \".geo\" , \"rightField\" : \".geo\" , \"maxError\" : 100 } ), ) # apply join on collections and save all results joined = ee . ImageCollection ( ee . Join . saveAll ( key ) . apply ( primary = self . collection , secondary = dataset . collection , condition = filter ) ) # map over all filtered imagery, mosaic joined matches, and add bands to imagery joined = joined . map ( _merge ) return self . _inplace_wrapper ( joined , inplace ) def aggregate_time ( self , dates = None , period = 1 , period_unit = \"day\" , reducer = \"mean\" , rename = True , clip_to_area = False , inplace = False , ): \"\"\"Aggregates multiple images into one based on time periods and a user defined reducer. Useful for mosaicing images from same date or time period. Expects the images in this dataset to be homogenous (same band names and types) args: dates (list[str], optional): list of dates defined as beginning time period of aggregatation. default = None, all available uniques dates in collection will be used period (int, optional): number of days to advance from dates for aggregation. default = 1 period_unit (str, optional): time unit to advance period for aggregation. default = \"day\" reducer (str | ee.Reducer, optional): reducer to apply to images for aggregation, accepts string reducer name or ee.Reducer opbject, default = \"mean\" clip_to_area (bool): switch to clip imagery that has been merged to the overlaping region of imagery, default=False inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection with aggregated imagery or none depending on inplace \"\"\" def _aggregation ( d ): \"\"\"Closure function to map through days and reduce data within a given time period\"\"\" t1 = ee . Date ( d ) t2 = t1 . advance ( period , period_unit ) img = ( self . collection . filterDate ( t1 , t2 ) . reduce ( reducer ) . set ( \"system:time_start\" , t1 . millis ()) ) if rename : img = img . rename ( band_names ) geom = ( ee . FeatureCollection ( self . collection . filterDate ( t1 , t2 ) . map ( geeutils . get_geoms ) ) . union ( 100 ) . geometry ( 100 ) ) outimg = ee . Algorithms . If ( clip_to_area , img . clip ( geom ), img ) return outimg if dates is None : dates = ( self . collection . aggregate_array ( \"system:time_start\" ) . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd\" )) . distinct () ) else : dates = ee . List ( dates ) band_names = ee . Image ( self . collection . first ()) . bandNames () out_coll = ee . ImageCollection . fromImages ( dates . map ( _aggregation )) return self . _inplace_wrapper ( out_coll , inplace ) @decorators . keep_attrs def band_pass_adjustment ( self , img ): \"\"\"Method to apply linear band transformation to dataset image collection. Expects that dataset has properties `self.gain` and `self.bias` set args: img (ee.Image): image to apply regression on \"\"\" # linear regression coefficients for adjustment return ( img . multiply ( self . gain ) . add ( self . bias ) . set ( \"system:time_start\" , img . get ( \"system:time_start\" )) ) def pipe ( self , steps , inplace = False , keep_attrs = True ): \"\"\"Method to pipe imagery within dataset through multiple functions at once. Assumes the first argument into piped functions are and ee.Image args: steps (list | tuple): iterable of functions/steps to apply to imagery. list must be in the form of (func,func) or with a tuple of function/keyword ((func,kwargs),func) inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection with piped functions applied Example: ```python s1 = hf.Sentinel1(ee.Geometry.Point(105.03,11.72),\"2019-10-03\",\"2019-10-05\") water = s1.pipe( ( hf.gamma_map, #apply speckle filter (hf.egde_ostu,{'initial_threshold:-16}) # apply water mapping ) ) ``` \"\"\" def _piper ( funcs ): \"\"\"Closure function to nest list of functions\"\"\" if len ( funcs ) > 1 : one_shotter = funcs [ 0 ] for func in funcs [ 1 :]: one_shotter = pipe | one_shotter | func else : one_shotter = funcs [ 0 ] return one_shotter fs = [] # loop through the steps and create partial funcs is kwargs are provided for step in steps : try : func , kwargs = step except TypeError : func = step kwargs = None if kwargs is not None : pfunc = partial ( func , ** kwargs ) else : pfunc = func fs . append ( pfunc ) # get the piped function if keep_attrs : one_shot = decorators . keep_attrs ( _piper ( fs )) else : one_shot = _piper ( fs ) # apply pipe to each image out_coll = self . collection . map ( lambda img : one_shot ( img )) return self . _inplace_wrapper ( out_coll , inplace )","title":"Dataset"},{"location":"datasets/#hydrafloods.datasets.Dataset.collection","text":"image collection object property wrapped by dataset","title":"collection"},{"location":"datasets/#hydrafloods.datasets.Dataset.dates","text":"Dates of imagery contained in the image collection","title":"dates"},{"location":"datasets/#hydrafloods.datasets.Dataset.n_images","text":"Number of images contained in the dataset","title":"n_images"},{"location":"datasets/#hydrafloods.datasets.Dataset.__init__","text":"Initialize Dataset class Parameters: Name Type Description Default region ee.Geometry earth engine geometry object to filter image collection by required start_time str | datetime.datetime start time used to filter image collection required end_time str | datetime.datetime end time used to filter image collection required asset_id str asset id of earth engine collection required use_qa bool boolean to determine to use an internal function qa(). Used for definining custom dataset objects False Exceptions: Type Description AttributeError if qa() method is not defined and use_qa is True Source code in hydrafloods/datasets.py def __init__ ( self , region , start_time , end_time , asset_id , use_qa = False ): \"\"\"Initialize Dataset class args: region (ee.Geometry): earth engine geometry object to filter image collection by start_time (str | datetime.datetime): start time used to filter image collection end_time (str | datetime.datetime): end time used to filter image collection asset_id (str): asset id of earth engine collection use_qa (bool, optional): boolean to determine to use an internal function qa(). Used for definining custom dataset objects raises: AttributeError: if qa() method is not defined and use_qa is True \"\"\" # TODO: add exceptions to check datatypes self . region = region # dtype = ee.Geometry self . start_time = start_time self . end_time = end_time self . asset_id = asset_id self . use_qa = use_qa # dictionary mapping of band names used to harmonized optical datasets to same names self . BANDREMAP = ee . Dictionary ( { \"landsat7\" : ee . List ([ \"SR_B1\" , \"SR_B2\" , \"SR_B3\" , \"SR_B4\" , \"SR_B5\" , \"SR_B7\" ]), \"landsat8\" : ee . List ([ \"SR_B2\" , \"SR_B3\" , \"SR_B4\" , \"SR_B5\" , \"SR_B6\" , \"SR_B7\" ]), \"viirs\" : ee . List ([ \"M2\" , \"M4\" , \"I1\" , \"I2\" , \"I3\" , \"M11\" ]), \"sen2\" : ee . List ([ \"B2\" , \"B3\" , \"B4\" , \"B8\" , \"B11\" , \"B12\" ]), \"modis\" : ee . List ( [ \"sur_refl_b03\" , \"sur_refl_b04\" , \"sur_refl_b01\" , \"sur_refl_b02\" , \"sur_refl_b06\" , \"sur_refl_b07\" , ] ), \"new\" : ee . List ([ \"blue\" , \"green\" , \"red\" , \"nir\" , \"swir1\" , \"swir2\" ]), } ) # get the image collection and filter by geographic region and date time imgcollection = ( ee . ImageCollection ( self . asset_id ) . filterBounds ( self . region ) . filterDate ( self . start_time , self . end_time ) ) # check if to apply arbitrary qa process on collection # qa function can be defined in custom objects extending dataset if self . use_qa : try : imgcollection = imgcollection . map ( self . qa ) except AttributeError : raise AttributeError ( \"qa() method is not defined...please define one or set `use_qa` to False\" ) self . collection = imgcollection","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Dataset.aggregate_time","text":"Aggregates multiple images into one based on time periods and a user defined reducer. Useful for mosaicing images from same date or time period. Expects the images in this dataset to be homogenous (same band names and types) Parameters: Name Type Description Default dates list[str] list of dates defined as beginning time period of aggregatation. default = None, all available uniques dates in collection will be used None period int number of days to advance from dates for aggregation. default = 1 1 period_unit str time unit to advance period for aggregation. default = \"day\" 'day' reducer str | ee.Reducer reducer to apply to images for aggregation, accepts string reducer name or ee.Reducer opbject, default = \"mean\" 'mean' clip_to_area bool switch to clip imagery that has been merged to the overlaping region of imagery, default=False False inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset.collection with aggregated imagery or none depending on inplace Source code in hydrafloods/datasets.py def aggregate_time ( self , dates = None , period = 1 , period_unit = \"day\" , reducer = \"mean\" , rename = True , clip_to_area = False , inplace = False , ): \"\"\"Aggregates multiple images into one based on time periods and a user defined reducer. Useful for mosaicing images from same date or time period. Expects the images in this dataset to be homogenous (same band names and types) args: dates (list[str], optional): list of dates defined as beginning time period of aggregatation. default = None, all available uniques dates in collection will be used period (int, optional): number of days to advance from dates for aggregation. default = 1 period_unit (str, optional): time unit to advance period for aggregation. default = \"day\" reducer (str | ee.Reducer, optional): reducer to apply to images for aggregation, accepts string reducer name or ee.Reducer opbject, default = \"mean\" clip_to_area (bool): switch to clip imagery that has been merged to the overlaping region of imagery, default=False inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection with aggregated imagery or none depending on inplace \"\"\" def _aggregation ( d ): \"\"\"Closure function to map through days and reduce data within a given time period\"\"\" t1 = ee . Date ( d ) t2 = t1 . advance ( period , period_unit ) img = ( self . collection . filterDate ( t1 , t2 ) . reduce ( reducer ) . set ( \"system:time_start\" , t1 . millis ()) ) if rename : img = img . rename ( band_names ) geom = ( ee . FeatureCollection ( self . collection . filterDate ( t1 , t2 ) . map ( geeutils . get_geoms ) ) . union ( 100 ) . geometry ( 100 ) ) outimg = ee . Algorithms . If ( clip_to_area , img . clip ( geom ), img ) return outimg if dates is None : dates = ( self . collection . aggregate_array ( \"system:time_start\" ) . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd\" )) . distinct () ) else : dates = ee . List ( dates ) band_names = ee . Image ( self . collection . first ()) . bandNames () out_coll = ee . ImageCollection . fromImages ( dates . map ( _aggregation )) return self . _inplace_wrapper ( out_coll , inplace )","title":"aggregate_time()"},{"location":"datasets/#hydrafloods.datasets.Dataset.apply","text":"Alias for the apply_func method Parameters: Name Type Description Default func object Function to map across image collection. Function must accept ee.Image as first argument required inplace bool define whether to return another dataset object or update inplace. default = False False **kwargs arbitrary keyword to pass to func {} Returns: Type Description Dataset | None copy of class with results from func as image within collection property Source code in hydrafloods/datasets.py def apply ( self , func , inplace = False , * args , ** kwargs ): \"\"\"Alias for the `apply_func` method args: func (object): Function to map across image collection. Function must accept ee.Image as first argument inplace (bool, optional): define whether to return another dataset object or update inplace. default = False **kwargs: arbitrary keyword to pass to `func` returns: Dataset | None: copy of class with results from `func` as image within collection property \"\"\" return self . apply_func ( func , inplace , * args , * kwargs )","title":"apply()"},{"location":"datasets/#hydrafloods.datasets.Dataset.apply_func","text":"Wrapper method to apply a function to all of the image in the dataset. Makes a copy of the collection and reassigns the image collection property. Function must accept an ee.ImageCollection and return an ee.ImageCollection Parameters: Name Type Description Default func object Function to map across image collection. Function must accept ee.Image as first argument required inplace bool define whether to return another dataset object or update inplace. default = False False **kwargs arbitrary keyword to pass to func {} Returns: Type Description Dataset | None copy of class with results from func as image within collection property Source code in hydrafloods/datasets.py def apply_func ( self , func , inplace = False , * args , ** kwargs ): \"\"\"Wrapper method to apply a function to all of the image in the dataset. Makes a copy of the collection and reassigns the image collection property. Function must accept an ee.ImageCollection and return an ee.ImageCollection args: func (object): Function to map across image collection. Function must accept ee.Image as first argument inplace (bool, optional): define whether to return another dataset object or update inplace. default = False **kwargs: arbitrary keyword to pass to `func` returns: Dataset | None: copy of class with results from `func` as image within collection property \"\"\" # get a partial function to map over imagery with the keywords applied # expects that the first positional arg is an func = partial ( func , ** kwargs ) out_coll = self . collection . map ( func ) return self . _inplace_wrapper ( out_coll , inplace )","title":"apply_func()"},{"location":"datasets/#hydrafloods.datasets.Dataset.band_pass_adjustment","text":"Method to apply linear band transformation to dataset image collection. Expects that dataset has properties self.gain and self.bias set Parameters: Name Type Description Default img ee.Image image to apply regression on required Source code in hydrafloods/datasets.py @decorators . keep_attrs def band_pass_adjustment ( self , img ): \"\"\"Method to apply linear band transformation to dataset image collection. Expects that dataset has properties `self.gain` and `self.bias` set args: img (ee.Image): image to apply regression on \"\"\" # linear regression coefficients for adjustment return ( img . multiply ( self . gain ) . add ( self . bias ) . set ( \"system:time_start\" , img . get ( \"system:time_start\" )) )","title":"band_pass_adjustment()"},{"location":"datasets/#hydrafloods.datasets.Dataset.clip_to_region","text":"Clips all of the images to the geographic extent defined by region. Useful for setting geometries on unbounded imagery in collection (e.g. MODIS or VIIRS imagery) Parameters: Name Type Description Default inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset with imagery clipped to self.region or none depending on inplace Source code in hydrafloods/datasets.py def clip_to_region ( self , inplace = False ): \"\"\"Clips all of the images to the geographic extent defined by region. Useful for setting geometries on unbounded imagery in collection (e.g. MODIS or VIIRS imagery) args: inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset with imagery clipped to self.region or none depending on inplace \"\"\" @decorators . keep_attrs def clip ( img ): \"\"\"Closure function to perform the clipping while carrying metadata\"\"\" return ee . Image ( img . clip ( self . region )) out_coll = self . collection . map ( clip ) return self . _inplace_wrapper ( out_coll , inplace )","title":"clip_to_region()"},{"location":"datasets/#hydrafloods.datasets.Dataset.copy","text":"returns a deep copy of the hydrafloods dataset class Source code in hydrafloods/datasets.py def copy ( self ): \"\"\"returns a deep copy of the hydrafloods dataset class\"\"\" return copy . deepcopy ( self )","title":"copy()"},{"location":"datasets/#hydrafloods.datasets.Dataset.filter","text":"Wrapper method for applying a filter to a datset collection. Parameters: Name Type Description Default filter ee.Filter an ee.Filter object to apply to the dataset collection. required Returns: Type Description Dataset | None returns the dataset with the filtered collection. Source code in hydrafloods/datasets.py def filter ( self , filter , inplace = False ): \"\"\"Wrapper method for applying a filter to a datset collection. args: filter (ee.Filter): an `ee.Filter` object to apply to the dataset collection. returns: Dataset | None: returns the dataset with the filtered collection. \"\"\" filtered = self . collection . filter ( filter ) return self . _inplace_wrapper ( filtered , inplace )","title":"filter()"},{"location":"datasets/#hydrafloods.datasets.Dataset.from_imgcollection","text":"Static method to convert an ee.ImageCollection object to a hf.Dataset object. This method will take some time as it uses computed ee Objects from the image collection propeties to populate the Dataset object properties (passing info from server to client) Parameters: Name Type Description Default img_collection ee.ImageCollection computed ee.ImageCollection object to create a hf.Dataset required Returns: Type Description hf.Dataset dataset object with property information directly from the ee.ImageCollection Source code in hydrafloods/datasets.py @staticmethod def from_imgcollection ( img_collection ): \"\"\"Static method to convert an ee.ImageCollection object to a hf.Dataset object. This method will take some time as it uses computed ee Objects from the image collection propeties to populate the Dataset object properties (passing info from server to client) args: img_collection (ee.ImageCollection): computed ee.ImageCollection object to create a hf.Dataset returns: hf.Dataset: dataset object with property information directly from the ee.ImageCollection \"\"\" # get region and date information region = ( img_collection . map ( geeutils . get_geoms ) . union ( maxError = 100 ) . geometry ( maxError = 100 ) ) # convert ee.Date info to string format dates = ( img_collection . aggregate_array ( \"system:time_start\" ) . sort () . map ( lambda x : ee . Date ( x ) . format ( \"YYYY-MM-dd HH:mm:ss.S\" )) ) # pull the date info to local strings start_time = dates . get ( 0 ) . getInfo () end_time = dates . get ( - 1 ) . getInfo () # get the collection id for `.asset_id` property collection_id = img_collection . get ( \"system:id\" ) . getInfo () if collection_id == \"None\" : collection_id = \"Custom ImageCollection\" # make a dummy dataset dummy_ds = Dataset ( region , start_time , end_time , asset_id = \"NOAA/VIIRS/001/VNP09GA\" , use_qa = False , ) # override the dummy dataset information with the correct data fr dummy_ds . asset_id = collection_id dummy_ds . collection = img_collection return dummy_ds","title":"from_imgcollection()"},{"location":"datasets/#hydrafloods.datasets.Dataset.join","text":"Performs spatiotemporal join between self.collection and dataset.collection. Result will be a dataset where the collection is colocated imagery in space and time Parameters: Name Type Description Default dataset Dataset dataset object to apply join with. Used as right in join operations required inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset where collection with joined imagery or none depending on inplace Source code in hydrafloods/datasets.py def join ( self , dataset , inplace = False ): \"\"\"Performs spatiotemporal join between self.collection and dataset.collection. Result will be a dataset where the collection is colocated imagery in space and time args: dataset (Dataset): dataset object to apply join with. Used as right in join operations inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection with joined imagery or none depending on inplace \"\"\" def _merge ( img ): \"\"\"Closure func to take results from the join and combine into one image with overlaping region\"\"\" join_coll = ee . ImageCollection . fromImages ( img . get ( key )) img_geom = img . geometry ( 100 ) join_geom = join_coll . map ( geeutils . get_geoms ) . union ( 100 ) . geometry ( 100 ) overlap = img_geom . intersection ( join_geom , 100 ) join_data = join_coll . mosaic () return img . addBands ( join_data ) . clip ( overlap ) key = str ( dataset . __class__ . __name__ ) # get a time and space filter filter = ee . Filter . And ( ee . Filter . maxDifference ( ** { \"difference\" : 1000 * 60 * 60 * 24 , # One day in milliseconds \"leftField\" : \"system:time_start\" , \"rightField\" : \"system:time_start\" , } ), ee . Filter . intersects ( ** { \"leftField\" : \".geo\" , \"rightField\" : \".geo\" , \"maxError\" : 100 } ), ) # apply join on collections and save all results joined = ee . ImageCollection ( ee . Join . saveAll ( key ) . apply ( primary = self . collection , secondary = dataset . collection , condition = filter ) ) # map over all filtered imagery, mosaic joined matches, and add bands to imagery joined = joined . map ( _merge ) return self . _inplace_wrapper ( joined , inplace )","title":"join()"},{"location":"datasets/#hydrafloods.datasets.Dataset.merge","text":"Merge the collection of two datasets into one where self.collection will contain imagery from self and dataset arg. Results will be sorted by time Parameters: Name Type Description Default dataset Dataset dataset object to merge required inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset where collection is merged imagery or none depending on inplace Source code in hydrafloods/datasets.py def merge ( self , dataset , inplace = False ): \"\"\"Merge the collection of two datasets into one where self.collection will contain imagery from self and dataset arg. Results will be sorted by time args: dataset (Dataset): dataset object to merge inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset where collection is merged imagery or none depending on inplace \"\"\" merged = self . collection . merge ( dataset . collection ) . sort ( \"system:time_start\" ) return self . _inplace_wrapper ( merged , inplace )","title":"merge()"},{"location":"datasets/#hydrafloods.datasets.Dataset.pipe","text":"Method to pipe imagery within dataset through multiple functions at once. Assumes the first argument into piped functions are and ee.Image Parameters: Name Type Description Default steps list | tuple iterable of functions/steps to apply to imagery. list must be in the form of (func,func) or with a tuple of function/keyword ((func,kwargs),func) required inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset.collection with piped functions applied Examples: s1 = hf . Sentinel1 ( ee . Geometry . Point ( 105.03 , 11.72 ), \"2019-10-03\" , \"2019-10-05\" ) water = s1 . pipe ( ( hf . gamma_map , #apply speckle filter ( hf . egde_ostu ,{ 'initial_threshold:-16}) # apply water mapping ) ) Source code in hydrafloods/datasets.py def pipe ( self , steps , inplace = False , keep_attrs = True ): \"\"\"Method to pipe imagery within dataset through multiple functions at once. Assumes the first argument into piped functions are and ee.Image args: steps (list | tuple): iterable of functions/steps to apply to imagery. list must be in the form of (func,func) or with a tuple of function/keyword ((func,kwargs),func) inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection with piped functions applied Example: ```python s1 = hf.Sentinel1(ee.Geometry.Point(105.03,11.72),\"2019-10-03\",\"2019-10-05\") water = s1.pipe( ( hf.gamma_map, #apply speckle filter (hf.egde_ostu,{'initial_threshold:-16}) # apply water mapping ) ) ``` \"\"\" def _piper ( funcs ): \"\"\"Closure function to nest list of functions\"\"\" if len ( funcs ) > 1 : one_shotter = funcs [ 0 ] for func in funcs [ 1 :]: one_shotter = pipe | one_shotter | func else : one_shotter = funcs [ 0 ] return one_shotter fs = [] # loop through the steps and create partial funcs is kwargs are provided for step in steps : try : func , kwargs = step except TypeError : func = step kwargs = None if kwargs is not None : pfunc = partial ( func , ** kwargs ) else : pfunc = func fs . append ( pfunc ) # get the piped function if keep_attrs : one_shot = decorators . keep_attrs ( _piper ( fs )) else : one_shot = _piper ( fs ) # apply pipe to each image out_coll = self . collection . map ( lambda img : one_shot ( img )) return self . _inplace_wrapper ( out_coll , inplace )","title":"pipe()"},{"location":"datasets/#hydrafloods.datasets.Dataset.select","text":"Wrapper method for selecting bands from dataset collection Parameters: Name Type Description Default *args arbitrary arguments to pass to the ee.ImageCollection.select() method () inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns the dataset with the collection with selected bands. Source code in hydrafloods/datasets.py def select ( self , * args , inplace = False ): \"\"\"Wrapper method for selecting bands from dataset collection args: *args: arbitrary arguments to pass to the `ee.ImageCollection.select()` method inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns the dataset with the collection with selected bands. \"\"\" selected = self . collection . select ( * args ) return self . _inplace_wrapper ( selected , inplace )","title":"select()"},{"location":"datasets/#hydrafloods.datasets.Sentinel1","text":"Class extending dataset for the Sentinel 1 collection This Sentinel 1 dataset is in backscatter units Source code in hydrafloods/datasets.py class Sentinel1 ( Dataset ): \"\"\"Class extending dataset for the Sentinel 1 collection This Sentinel 1 dataset is in backscatter units \"\"\" def __init__ ( self , * args , asset_id = \"COPERNICUS/S1_GRD\" , use_qa = True , ** kwargs ): \"\"\"Initialize Sentinel1 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel 1 earth engine collection. default=\"COPERNICUS/S1_GRD\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel1 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . filter ( ee . Filter . listContains ( \"transmitterReceiverPolarisation\" , \"VH\" ) ) return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel1 backscatter based on view angle Angle threshold values taken from https://doi.org/10.3390/rs13101954 \"\"\" angle = img . select ( \"angle\" ) angle_mask = angle . lt ( 45.23993 ) . And ( angle . gt ( 30.63993 )) return img . updateMask ( angle_mask ) def add_orbit_band ( self , inplace = False ): \"\"\"Method to add orbit band from S1 image metadata Useful for determining if pixels are from ascending or descending orbits args: inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection where imagery has the added bands \"\"\" def _add_features ( img ): \"\"\"Closure function to add features as bands to the images\"\"\" bounds = img . geometry ( 100 ) orbit = ee . String ( img . get ( \"orbitProperties_pass\" )) orbit_band = ee . Algorithms . If ( orbit . compareTo ( \"DESCENDING\" ), ee . Image ( 1 ), ee . Image ( 0 ) ) extraFeatures = ee . Image ( orbit_band ) . rename ( \"orbit\" ) return img . addBands ( extraFeatures . clip ( bounds )) return self . apply_func ( _add_features , inplace = inplace ) def to_db ( self , inplace = False ): \"\"\"Convience method to convert units from power to db\"\"\" out_coll = self . collection . map ( geeutils . power_to_db ) if inplace : self . collection = out_coll return else : outCls = self . copy () outCls . collection = out_coll return outCls def to_power ( self , inplace = False ): \"\"\"Convience method to convert units from db to power\"\"\" out_coll = self . collection . map ( geeutils . db_to_power ) if inplace : self . collection = out_coll return else : outCls = self . copy () outCls . collection = out_coll return outCls","title":"Sentinel1"},{"location":"datasets/#hydrafloods.datasets.Sentinel1.__init__","text":"Initialize Sentinel1 Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Sentinel 1 earth engine collection. default=\"COPERNICUS/S1_GRD\" 'COPERNICUS/S1_GRD' use_qa bool boolean to determine to use a private self.qa() function. default=True True **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"COPERNICUS/S1_GRD\" , use_qa = True , ** kwargs ): \"\"\"Initialize Sentinel1 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel 1 earth engine collection. default=\"COPERNICUS/S1_GRD\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel1 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . filter ( ee . Filter . listContains ( \"transmitterReceiverPolarisation\" , \"VH\" ) ) return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Sentinel1.add_orbit_band","text":"Method to add orbit band from S1 image metadata Useful for determining if pixels are from ascending or descending orbits Parameters: Name Type Description Default inplace bool define whether to return another dataset object or update inplace. default = False False Returns: Type Description Dataset | None returns dataset.collection where imagery has the added bands Source code in hydrafloods/datasets.py def add_orbit_band ( self , inplace = False ): \"\"\"Method to add orbit band from S1 image metadata Useful for determining if pixels are from ascending or descending orbits args: inplace (bool, optional): define whether to return another dataset object or update inplace. default = False returns: Dataset | None: returns dataset.collection where imagery has the added bands \"\"\" def _add_features ( img ): \"\"\"Closure function to add features as bands to the images\"\"\" bounds = img . geometry ( 100 ) orbit = ee . String ( img . get ( \"orbitProperties_pass\" )) orbit_band = ee . Algorithms . If ( orbit . compareTo ( \"DESCENDING\" ), ee . Image ( 1 ), ee . Image ( 0 ) ) extraFeatures = ee . Image ( orbit_band ) . rename ( \"orbit\" ) return img . addBands ( extraFeatures . clip ( bounds )) return self . apply_func ( _add_features , inplace = inplace )","title":"add_orbit_band()"},{"location":"datasets/#hydrafloods.datasets.Sentinel1.qa","text":"Custom QA masking method for Sentinel1 backscatter based on view angle Angle threshold values taken from https://doi.org/10.3390/rs13101954 Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel1 backscatter based on view angle Angle threshold values taken from https://doi.org/10.3390/rs13101954 \"\"\" angle = img . select ( \"angle\" ) angle_mask = angle . lt ( 45.23993 ) . And ( angle . gt ( 30.63993 )) return img . updateMask ( angle_mask )","title":"qa()"},{"location":"datasets/#hydrafloods.datasets.Sentinel1.to_db","text":"Convience method to convert units from power to db Source code in hydrafloods/datasets.py def to_db ( self , inplace = False ): \"\"\"Convience method to convert units from power to db\"\"\" out_coll = self . collection . map ( geeutils . power_to_db ) if inplace : self . collection = out_coll return else : outCls = self . copy () outCls . collection = out_coll return outCls","title":"to_db()"},{"location":"datasets/#hydrafloods.datasets.Sentinel1.to_power","text":"Convience method to convert units from db to power Source code in hydrafloods/datasets.py def to_power ( self , inplace = False ): \"\"\"Convience method to convert units from db to power\"\"\" out_coll = self . collection . map ( geeutils . db_to_power ) if inplace : self . collection = out_coll return else : outCls = self . copy () outCls . collection = out_coll return outCls","title":"to_power()"},{"location":"datasets/#hydrafloods.datasets.Sentinel2","text":"Source code in hydrafloods/datasets.py class Sentinel2 ( Dataset ): def __init__ ( self , * args , asset_id = \"COPERNICUS/S2_SR\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize Sentinel2 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel2 earth engine collection. default=\"COPERNICUS/S2_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel2 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"sen2\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken HLS project https://hls.gsfc.nasa.gov/algorithms/bandpass-adjustment/ # slope coefficients self . gain = ee . Image . constant ( [ 0.9778 , 1.0053 , 0.9765 , 0.9983 , 0.9987 , 1.003 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ - 0.00411 , - 0.00093 , 0.00094 , - 0.0001 , - 0.0015 , - 0.0012 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel2 surface reflectance dataset\"\"\" CLD_PRB_THRESH = 40 NIR_DRK_THRESH = 0.175 * 1e4 CLD_PRJ_DIST = 3 BUFFER = 100 CRS = img . select ( 0 ) . projection () # Get s2cloudless image, subset the probability band. cld_prb = ee . Image ( ee . ImageCollection ( \"COPERNICUS/S2_CLOUD_PROBABILITY\" ) . filter ( ee . Filter . eq ( \"system:index\" , img . get ( \"system:index\" ))) . first () ) . select ( \"probability\" ) # Condition s2cloudless by the probability threshold value. is_cloud = cld_prb . gt ( CLD_PRB_THRESH ) # Identify water pixels from the SCL band, invert. not_water = img . select ( \"SCL\" ) . neq ( 6 ) # Identify dark NIR pixels that are not water (potential cloud shadow pixels). dark_pixels = img . select ( \"B8\" ) . lt ( NIR_DRK_THRESH ) . multiply ( not_water ) # Determine the direction to project cloud shadow from clouds (assumes UTM projection). shadow_azimuth = ee . Number ( 90 ) . subtract ( ee . Number ( img . get ( \"MEAN_SOLAR_AZIMUTH_ANGLE\" )) ) # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input. cld_proj = ( is_cloud . directionalDistanceTransform ( shadow_azimuth , CLD_PRJ_DIST * 10 ) . reproject ( ** { \"crs\" : CRS , \"scale\" : 120 }) . select ( \"distance\" ) . mask () ) # Identify the intersection of dark pixels with cloud shadow projection. is_shadow = cld_proj . multiply ( dark_pixels ) # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0. is_cld_shdw = is_cloud . add ( is_shadow ) . gt ( 0 ) # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input. # 20 m scale is for speed, and assumes clouds don't require 10 m precision. is_cld_shdw = ( is_cld_shdw . focal_min ( 2 ) . focal_max ( BUFFER * 2 / 20 ) . reproject ( ** { \"crs\" : CRS , \"scale\" : 60 }) . rename ( \"cloudmask\" ) ) # Subset reflectance bands and update their masks, return the result. return geeutils . rescale ( img ) . select ( \"B.*\" ) . updateMask ( is_cld_shdw . Not ())","title":"Sentinel2"},{"location":"datasets/#hydrafloods.datasets.Sentinel2.__init__","text":"Initialize Sentinel2 Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Sentinel2 earth engine collection. default=\"COPERNICUS/S2_SR\" 'COPERNICUS/S2_SR' use_qa bool boolean to determine to use a private self.qa() function. default=True True apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False rescale bool boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False required **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"COPERNICUS/S2_SR\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize Sentinel2 Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Sentinel2 earth engine collection. default=\"COPERNICUS/S2_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Sentinel2 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"sen2\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken HLS project https://hls.gsfc.nasa.gov/algorithms/bandpass-adjustment/ # slope coefficients self . gain = ee . Image . constant ( [ 0.9778 , 1.0053 , 0.9765 , 0.9983 , 0.9987 , 1.003 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ - 0.00411 , - 0.00093 , 0.00094 , - 0.0001 , - 0.0015 , - 0.0012 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Sentinel2.qa","text":"Custom QA masking method for Sentinel2 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Sentinel2 surface reflectance dataset\"\"\" CLD_PRB_THRESH = 40 NIR_DRK_THRESH = 0.175 * 1e4 CLD_PRJ_DIST = 3 BUFFER = 100 CRS = img . select ( 0 ) . projection () # Get s2cloudless image, subset the probability band. cld_prb = ee . Image ( ee . ImageCollection ( \"COPERNICUS/S2_CLOUD_PROBABILITY\" ) . filter ( ee . Filter . eq ( \"system:index\" , img . get ( \"system:index\" ))) . first () ) . select ( \"probability\" ) # Condition s2cloudless by the probability threshold value. is_cloud = cld_prb . gt ( CLD_PRB_THRESH ) # Identify water pixels from the SCL band, invert. not_water = img . select ( \"SCL\" ) . neq ( 6 ) # Identify dark NIR pixels that are not water (potential cloud shadow pixels). dark_pixels = img . select ( \"B8\" ) . lt ( NIR_DRK_THRESH ) . multiply ( not_water ) # Determine the direction to project cloud shadow from clouds (assumes UTM projection). shadow_azimuth = ee . Number ( 90 ) . subtract ( ee . Number ( img . get ( \"MEAN_SOLAR_AZIMUTH_ANGLE\" )) ) # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input. cld_proj = ( is_cloud . directionalDistanceTransform ( shadow_azimuth , CLD_PRJ_DIST * 10 ) . reproject ( ** { \"crs\" : CRS , \"scale\" : 120 }) . select ( \"distance\" ) . mask () ) # Identify the intersection of dark pixels with cloud shadow projection. is_shadow = cld_proj . multiply ( dark_pixels ) # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0. is_cld_shdw = is_cloud . add ( is_shadow ) . gt ( 0 ) # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input. # 20 m scale is for speed, and assumes clouds don't require 10 m precision. is_cld_shdw = ( is_cld_shdw . focal_min ( 2 ) . focal_max ( BUFFER * 2 / 20 ) . reproject ( ** { \"crs\" : CRS , \"scale\" : 60 }) . rename ( \"cloudmask\" ) ) # Subset reflectance bands and update their masks, return the result. return geeutils . rescale ( img ) . select ( \"B.*\" ) . updateMask ( is_cld_shdw . Not ())","title":"qa()"},{"location":"datasets/#hydrafloods.datasets.Landsat8","text":"Source code in hydrafloods/datasets.py class Landsat8 ( Dataset ): def __init__ ( self , * args , asset_id = \"LANDSAT/LC08/C02/T1_L2\" , use_qa = True , ** kwargs , ): \"\"\"Initialize Landsat8 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat earth engine collection. default=\"LANDSAT/LC08/C01/T1_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat8 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"landsat8\" ), self . BANDREMAP . get ( \"new\" ) ) return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Landsat8 surface reflectance dataset\"\"\" qa_band = img . select ( \"QA_PIXEL\" ) qa_flag = int ( '111111' , 2 ) sat_mask = img . select ( 'QA_RADSAT' ) . eq ( 0 ); mask = qa_band . bitwiseAnd ( qa_flag ) . eq ( 0 ) . And ( sat_mask ) return geeutils . rescale ( img , scale = 0.0000275 , offset = - 0.2 ) . updateMask ( mask )","title":"Landsat8"},{"location":"datasets/#hydrafloods.datasets.Landsat8.__init__","text":"Initialize Landsat8 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Landsat earth engine collection. default=\"LANDSAT/LC08/C01/T1_SR\" 'LANDSAT/LC08/C02/T1_L2' use_qa bool boolean to determine to use a private self.qa() function. default=True True rescale bool boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False required **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"LANDSAT/LC08/C02/T1_L2\" , use_qa = True , ** kwargs , ): \"\"\"Initialize Landsat8 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat earth engine collection. default=\"LANDSAT/LC08/C01/T1_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat8 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"landsat8\" ), self . BANDREMAP . get ( \"new\" ) ) return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Landsat8.qa","text":"Custom QA masking method for Landsat8 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Landsat8 surface reflectance dataset\"\"\" qa_band = img . select ( \"QA_PIXEL\" ) qa_flag = int ( '111111' , 2 ) sat_mask = img . select ( 'QA_RADSAT' ) . eq ( 0 ); mask = qa_band . bitwiseAnd ( qa_flag ) . eq ( 0 ) . And ( sat_mask ) return geeutils . rescale ( img , scale = 0.0000275 , offset = - 0.2 ) . updateMask ( mask )","title":"qa()"},{"location":"datasets/#hydrafloods.datasets.Landsat7","text":"Source code in hydrafloods/datasets.py class Landsat7 ( Dataset ): def __init__ ( self , * args , asset_id = \"LANDSAT/LE07/C02/T1_L2\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize Landsat7 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat7 earth engine collection. default=\"LANDSAT/LE07/C01/T1_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat7 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"landsat7\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken from Roy et al., 2016 http://dx.doi.org/10.1016/j.rse.2015.12.024 # slope coefficients self . gain = ee . Image . constant ( [ 0.8474 , 0.8483 , 0.9047 , 0.8462 , 0.8937 , 0.9071 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.0003 , 0.0088 , 0.0061 , 0.0412 , 0.0254 , 0.0172 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Landsat7 surface reflectance dataset\"\"\" qa_band = img . select ( \"QA_PIXEL\" ) qa_flag = int ( '111111' , 2 ) sat_mask = img . select ( 'QA_RADSAT' ) . eq ( 0 ); mask = qa_band . bitwiseAnd ( qa_flag ) . eq ( 0 ) . And ( sat_mask ) return geeutils . rescale ( img , scale = 0.0000275 , offset = - 0.2 ) . updateMask ( mask )","title":"Landsat7"},{"location":"datasets/#hydrafloods.datasets.Landsat7.__init__","text":"Initialize Landsat7 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the Landsat7 earth engine collection. default=\"LANDSAT/LE07/C01/T1_SR\" 'LANDSAT/LE07/C02/T1_L2' use_qa bool boolean to determine to use a private self.qa() function. default=True True apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False rescale bool boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False required **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"LANDSAT/LE07/C02/T1_L2\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize Landsat7 Dataset class Can theoretically be useds with any Landsat surface reflectance collection (e.g. LANDSAT/LT05/C01/T1_SR) args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the Landsat7 earth engine collection. default=\"LANDSAT/LE07/C01/T1_SR\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Landsat7 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) coll = self . collection . select ( self . BANDREMAP . get ( \"landsat7\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken from Roy et al., 2016 http://dx.doi.org/10.1016/j.rse.2015.12.024 # slope coefficients self . gain = ee . Image . constant ( [ 0.8474 , 0.8483 , 0.9047 , 0.8462 , 0.8937 , 0.9071 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.0003 , 0.0088 , 0.0061 , 0.0412 , 0.0254 , 0.0172 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Landsat7.qa","text":"Custom QA masking method for Landsat7 surface reflectance dataset Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Landsat7 surface reflectance dataset\"\"\" qa_band = img . select ( \"QA_PIXEL\" ) qa_flag = int ( '111111' , 2 ) sat_mask = img . select ( 'QA_RADSAT' ) . eq ( 0 ); mask = qa_band . bitwiseAnd ( qa_flag ) . eq ( 0 ) . And ( sat_mask ) return geeutils . rescale ( img , scale = 0.0000275 , offset = - 0.2 ) . updateMask ( mask )","title":"qa()"},{"location":"datasets/#hydrafloods.datasets.Viirs","text":"Source code in hydrafloods/datasets.py class Viirs ( Dataset ): def __init__ ( self , * args , asset_id = \"NOAA/VIIRS/001/VNP09GA\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize VIIRS Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the VIIRS earth engine collection. default=\"NOAA/VIIRS/001/VNP09GA\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Viirs , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) # get the bands and rename to common optical names coll = self . collection . select ( self . BANDREMAP . get ( \"viirs\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken calculated from https://code.earthengine.google.com/876f53861690e483fb3e3439a3571f27 # slope coefficients self . gain = ee . Image . constant ( [ 0.68328 , 0.66604 , 0.78901 , 0.95324 , 0.98593 , 0.88941 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.016728 , 0.030814 , 0.023199 , 0.036571 , 0.026923 , 0.021615 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for VIIRS VNP09GA dataset\"\"\" cloudMask = geeutils . extract_bits ( img . select ( \"QF1\" ), 2 , end = 3 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 3 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 5 , new_name = \"snow_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) env_mask = cloudMask . And ( shadowMask ) . And ( sensorZenith ) # internal pixel quality masks pixal_quality_3 = img . select ( \"QF3\" ) pixal_quality_4 = img . select ( \"QF4\" ) m2_qual = geeutils . extract_bits ( pixal_quality_3 , 1 , new_name = \"m2_quality\" ) . eq ( 0 ) m4_qual = geeutils . extract_bits ( pixal_quality_3 , 3 , new_name = \"m4_quality\" ) . eq ( 0 ) m11_qual = geeutils . extract_bits ( pixal_quality_4 , 0 , new_name = \"m11_quality\" ) . eq ( 0 ) i1_qual = geeutils . extract_bits ( pixal_quality_4 , 1 , new_name = \"i1_quality\" ) . eq ( 0 ) i2_qual = geeutils . extract_bits ( pixal_quality_4 , 2 , new_name = \"i2_quality\" ) . eq ( 0 ) i3_qual = geeutils . extract_bits ( pixal_quality_4 , 3 , new_name = \"i3_quality\" ) . eq ( 0 ) qual_mask = m2_qual . And ( m4_qual ) . And ( m11_qual ) . And ( i1_qual ) . And ( i2_qual ) . And ( i3_qual ) mask = env_mask . And ( qual_mask ) return geeutils . rescale ( img ) . updateMask ( mask )","title":"Viirs"},{"location":"datasets/#hydrafloods.datasets.Viirs.__init__","text":"Initialize VIIRS Dataset class Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the VIIRS earth engine collection. default=\"NOAA/VIIRS/001/VNP09GA\" 'NOAA/VIIRS/001/VNP09GA' use_qa bool boolean to determine to use a private self.qa() function. default=True True apply_band_adjustment bool boolean switch to apply linear band pass equation to convert values to Landsat8. default=False False rescale bool boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False required **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"NOAA/VIIRS/001/VNP09GA\" , use_qa = True , apply_band_adjustment = False , ** kwargs , ): \"\"\"Initialize VIIRS Dataset class args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the VIIRS earth engine collection. default=\"NOAA/VIIRS/001/VNP09GA\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True apply_band_adjustment (bool, optional): boolean switch to apply linear band pass equation to convert values to Landsat8. default=False rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Viirs , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) # get the bands and rename to common optical names coll = self . collection . select ( self . BANDREMAP . get ( \"viirs\" ), self . BANDREMAP . get ( \"new\" ) ) if apply_band_adjustment : # band bass adjustment coefficients taken calculated from https://code.earthengine.google.com/876f53861690e483fb3e3439a3571f27 # slope coefficients self . gain = ee . Image . constant ( [ 0.68328 , 0.66604 , 0.78901 , 0.95324 , 0.98593 , 0.88941 ] ) # y-intercept coefficients self . bias = ee . Image . constant ( [ 0.016728 , 0.030814 , 0.023199 , 0.036571 , 0.026923 , 0.021615 ] ) . multiply ( 10000 ) coll = coll . map ( self . band_pass_adjustment ) self . collection = coll return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Viirs.qa","text":"Custom QA masking method for VIIRS VNP09GA dataset Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for VIIRS VNP09GA dataset\"\"\" cloudMask = geeutils . extract_bits ( img . select ( \"QF1\" ), 2 , end = 3 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 3 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( img . select ( \"QF2\" ), 5 , new_name = \"snow_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) env_mask = cloudMask . And ( shadowMask ) . And ( sensorZenith ) # internal pixel quality masks pixal_quality_3 = img . select ( \"QF3\" ) pixal_quality_4 = img . select ( \"QF4\" ) m2_qual = geeutils . extract_bits ( pixal_quality_3 , 1 , new_name = \"m2_quality\" ) . eq ( 0 ) m4_qual = geeutils . extract_bits ( pixal_quality_3 , 3 , new_name = \"m4_quality\" ) . eq ( 0 ) m11_qual = geeutils . extract_bits ( pixal_quality_4 , 0 , new_name = \"m11_quality\" ) . eq ( 0 ) i1_qual = geeutils . extract_bits ( pixal_quality_4 , 1 , new_name = \"i1_quality\" ) . eq ( 0 ) i2_qual = geeutils . extract_bits ( pixal_quality_4 , 2 , new_name = \"i2_quality\" ) . eq ( 0 ) i3_qual = geeutils . extract_bits ( pixal_quality_4 , 3 , new_name = \"i3_quality\" ) . eq ( 0 ) qual_mask = m2_qual . And ( m4_qual ) . And ( m11_qual ) . And ( i1_qual ) . And ( i2_qual ) . And ( i3_qual ) mask = env_mask . And ( qual_mask ) return geeutils . rescale ( img ) . updateMask ( mask )","title":"qa()"},{"location":"datasets/#hydrafloods.datasets.Modis","text":"Source code in hydrafloods/datasets.py class Modis ( Dataset ): def __init__ ( self , * args , asset_id = \"MODIS/006/MOD09GA\" , use_qa = True , ** kwargs ): \"\"\"Initialize MODIS Dataset class Can be used with MOD09GA and MYD09GA args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the MODIS earth engine collection. default=\"MODIS/006/MOD09GA\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Modis , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"modis\" ), self . BANDREMAP . get ( \"new\" ) ) return @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for MODIS MXD09GA dataset\"\"\" # internal env masks qa = img . select ( \"state_1km\" ) cloudMask = geeutils . extract_bits ( qa , 10 , end = 11 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( qa , 2 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( qa , 12 , new_name = \"snow_qa\" ) . Not () cloudAdjMask = geeutils . extract_bits ( qa , 13 , new_name = \"cloud_adjacency_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) env_mask = cloudMask . And ( shadowMask ) . And ( snowMask ) . And ( sensorZenith ) . And ( cloudAdjMask ) # internal pixel quality masks pixal_quality = img . select ( \"QC_500m\" ) b1_qual = geeutils . extract_bits ( pixal_quality , 2 , end = 5 , new_name = \"b1_quality\" ) . eq ( 0 ) b2_qual = geeutils . extract_bits ( pixal_quality , 6 , end = 9 , new_name = \"b1_quality\" ) . eq ( 0 ) b3_qual = geeutils . extract_bits ( pixal_quality , 10 , end = 13 , new_name = \"b1_quality\" ) . eq ( 0 ) b4_qual = geeutils . extract_bits ( pixal_quality , 14 , end = 17 , new_name = \"b1_quality\" ) . eq ( 0 ) b6_qual = geeutils . extract_bits ( pixal_quality , 22 , end = 25 , new_name = \"b1_quality\" ) . eq ( 0 ) b7_qual = geeutils . extract_bits ( pixal_quality , 26 , end = 29 , new_name = \"b1_quality\" ) . eq ( 0 ) qual_mask = b1_qual . And ( b2_qual ) . And ( b3_qual ) . And ( b4_qual ) . And ( b6_qual ) . And ( b7_qual ) mask = env_mask . And ( qual_mask ) return geeutils . rescale ( img ) . updateMask ( mask )","title":"Modis"},{"location":"datasets/#hydrafloods.datasets.Modis.__init__","text":"Initialize MODIS Dataset class Can be used with MOD09GA and MYD09GA Parameters: Name Type Description Default *args positional arguments to pass to Dataset (i.e. region , start_time , end_time ) () asset_id str asset id of the MODIS earth engine collection. default=\"MODIS/006/MOD09GA\" 'MODIS/006/MOD09GA' use_qa bool boolean to determine to use a private self.qa() function. default=True True rescale bool boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False required **kwargs optional addtional arbitrary keywords to pass to Dataset {} Source code in hydrafloods/datasets.py def __init__ ( self , * args , asset_id = \"MODIS/006/MOD09GA\" , use_qa = True , ** kwargs ): \"\"\"Initialize MODIS Dataset class Can be used with MOD09GA and MYD09GA args: *args: positional arguments to pass to `Dataset` (i.e. `region`, `start_time`, `end_time`) asset_id (str): asset id of the MODIS earth engine collection. default=\"MODIS/006/MOD09GA\" use_qa (bool, optional): boolean to determine to use a private `self.qa()` function. default=True rescale (bool, optional): boolean switch to convert units from scaled int (0-10000) to float (0-1). If false values will be scaled int. default = False **kwargs (optional): addtional arbitrary keywords to pass to `Dataset` \"\"\" super ( Modis , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) self . collection = self . collection . select ( self . BANDREMAP . get ( \"modis\" ), self . BANDREMAP . get ( \"new\" ) ) return","title":"__init__()"},{"location":"datasets/#hydrafloods.datasets.Modis.qa","text":"Custom QA masking method for MODIS MXD09GA dataset Source code in hydrafloods/datasets.py @decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for MODIS MXD09GA dataset\"\"\" # internal env masks qa = img . select ( \"state_1km\" ) cloudMask = geeutils . extract_bits ( qa , 10 , end = 11 , new_name = \"cloud_qa\" ) . lt ( 1 ) shadowMask = geeutils . extract_bits ( qa , 2 , new_name = \"shadow_qa\" ) . Not () snowMask = geeutils . extract_bits ( qa , 12 , new_name = \"snow_qa\" ) . Not () cloudAdjMask = geeutils . extract_bits ( qa , 13 , new_name = \"cloud_adjacency_qa\" ) . Not () sensorZenith = img . select ( \"SensorZenith\" ) . abs () . lt ( 6000 ) env_mask = cloudMask . And ( shadowMask ) . And ( snowMask ) . And ( sensorZenith ) . And ( cloudAdjMask ) # internal pixel quality masks pixal_quality = img . select ( \"QC_500m\" ) b1_qual = geeutils . extract_bits ( pixal_quality , 2 , end = 5 , new_name = \"b1_quality\" ) . eq ( 0 ) b2_qual = geeutils . extract_bits ( pixal_quality , 6 , end = 9 , new_name = \"b1_quality\" ) . eq ( 0 ) b3_qual = geeutils . extract_bits ( pixal_quality , 10 , end = 13 , new_name = \"b1_quality\" ) . eq ( 0 ) b4_qual = geeutils . extract_bits ( pixal_quality , 14 , end = 17 , new_name = \"b1_quality\" ) . eq ( 0 ) b6_qual = geeutils . extract_bits ( pixal_quality , 22 , end = 25 , new_name = \"b1_quality\" ) . eq ( 0 ) b7_qual = geeutils . extract_bits ( pixal_quality , 26 , end = 29 , new_name = \"b1_quality\" ) . eq ( 0 ) qual_mask = b1_qual . And ( b2_qual ) . And ( b3_qual ) . And ( b4_qual ) . And ( b6_qual ) . And ( b7_qual ) mask = env_mask . And ( qual_mask ) return geeutils . rescale ( img ) . updateMask ( mask )","title":"qa()"},{"location":"decorators/","text":"hydrafloods.decorators keep_attrs ( func ) Decorator function to set the properties of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object Parameters: Name Type Description Default func object function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata required Examples: @decorators . carry_metadata def ndvi ( img ): return img . normalizedDifference ([ b1 , b2 ]) Returned image(s) will have all of the same metadata properties as the input including system:time_start Source code in hydrafloods/decorators.py def keep_attrs ( func ): \"\"\"Decorator function to set the properties of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object args: func (object): function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata Example: ```python @decorators.carry_metadata def ndvi(img): return img.normalizedDifference([b1,b2]) ``` Returned image(s) will have all of the same metadata properties as the input including `system:time_start` \"\"\" @functools . wraps ( func ) def wrapper ( * args , ** kwargs ): # expects an element within args is img # will set the metadata to first ee.Image instance # this assumption is true for 99% of functions used for ee.ImageCollection.map() result = ee . Image ( func ( * args , ** kwargs )) img = [ i for i in args if isinstance ( i , ee . Image )][ 0 ] return ee . Image ( result . copyProperties ( img ) . set ( \"system:time_start\" , img . get ( \"system:time_start\" ) ) ) return wrapper keep_names ( func ) Decorator function to set the band names of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object Parameters: Name Type Description Default func object function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata required Examples: @decorators . keep_names def my_computation ( img ): const = ee . Image . constant ( 2 ) return const . multiply ( img ) Returned image(s) will have the same band names as the input. This should only be used if the input and output images will have the same number of bands! Source code in hydrafloods/decorators.py def keep_names ( func ): \"\"\"Decorator function to set the band names of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object args: func (object): function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata Example: ```python @decorators.keep_names def my_computation(img): const = ee.Image.constant(2) return const.multiply(img) ``` Returned image(s) will have the same band names as the input. This should only be used if the input and output images will have the same number of bands! \"\"\" @functools . wraps ( func ) def wrapper ( * args , ** kwargs ): # expects an element within args is img # will set the metadata to first ee.Image instance # this assumption is true for 99% of functions used for ee.ImageCollection.map() result = ee . Image ( func ( * args , ** kwargs )) img = [ i for i in args if isinstance ( i , ee . Image )][ 0 ] return result . rename ( img . bandNames ()) return wrapper","title":"decorators module"},{"location":"decorators/#hydrafloods.decorators","text":"","title":"decorators"},{"location":"decorators/#hydrafloods.decorators.keep_attrs","text":"Decorator function to set the properties of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object Parameters: Name Type Description Default func object function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata required Examples: @decorators . carry_metadata def ndvi ( img ): return img . normalizedDifference ([ b1 , b2 ]) Returned image(s) will have all of the same metadata properties as the input including system:time_start Source code in hydrafloods/decorators.py def keep_attrs ( func ): \"\"\"Decorator function to set the properties of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object args: func (object): function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata Example: ```python @decorators.carry_metadata def ndvi(img): return img.normalizedDifference([b1,b2]) ``` Returned image(s) will have all of the same metadata properties as the input including `system:time_start` \"\"\" @functools . wraps ( func ) def wrapper ( * args , ** kwargs ): # expects an element within args is img # will set the metadata to first ee.Image instance # this assumption is true for 99% of functions used for ee.ImageCollection.map() result = ee . Image ( func ( * args , ** kwargs )) img = [ i for i in args if isinstance ( i , ee . Image )][ 0 ] return ee . Image ( result . copyProperties ( img ) . set ( \"system:time_start\" , img . get ( \"system:time_start\" ) ) ) return wrapper","title":"keep_attrs()"},{"location":"decorators/#hydrafloods.decorators.keep_names","text":"Decorator function to set the band names of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object Parameters: Name Type Description Default func object function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata required Examples: @decorators . keep_names def my_computation ( img ): const = ee . Image . constant ( 2 ) return const . multiply ( img ) Returned image(s) will have the same band names as the input. This should only be used if the input and output images will have the same number of bands! Source code in hydrafloods/decorators.py def keep_names ( func ): \"\"\"Decorator function to set the band names of an image from computations to that of the input Function to decorate should take an ee.Image object and return an ee.Image object args: func (object): function object to wrap. Expects that an element within args is of type ee.Image and will use first ee.Image to carry metadata Example: ```python @decorators.keep_names def my_computation(img): const = ee.Image.constant(2) return const.multiply(img) ``` Returned image(s) will have the same band names as the input. This should only be used if the input and output images will have the same number of bands! \"\"\" @functools . wraps ( func ) def wrapper ( * args , ** kwargs ): # expects an element within args is img # will set the metadata to first ee.Image instance # this assumption is true for 99% of functions used for ee.ImageCollection.map() result = ee . Image ( func ( * args , ** kwargs )) img = [ i for i in args if isinstance ( i , ee . Image )][ 0 ] return result . rename ( img . bandNames ()) return wrapper","title":"keep_names()"},{"location":"depths/","text":"hydrafloods.depths downscale_wfraction ( fraction , dem ) Algorithm to downscale water fraction maps using DEM data Converts fractional water data to higher resolution binary water data Paper: https://doi.org/10.1016/j.rse.2013.03.015 Parameters: Name Type Description Default fraction ee.Image earth engine image object representing the fractional water extent within each pixel. required dem ee.Image earth engine image object representing elevation required Returns: Type Description ee.Image downscaled binary image of water Source code in hydrafloods/depths.py def downscale_wfraction ( fraction , dem ): \"\"\"Algorithm to downscale water fraction maps using DEM data Converts fractional water data to higher resolution binary water data Paper: https://doi.org/10.1016/j.rse.2013.03.015 args: fraction (ee.Image): earth engine image object representing the fractional water extent within each pixel. dem (ee.Image): earth engine image object representing elevation returns: ee.Image: downscaled binary image of water \"\"\" resolution = fraction . projection () . nominalScale () water_present = fraction . gt ( 0.0 ) h_min = dem . updateMask ( water_present ) . focal_min ( resolution , \"square\" , \"meters\" ) h_max = dem . updateMask ( water_present ) . focal_max ( resolution , \"square\" , \"meters\" ) water_high = h_min . add ( h_max . subtract ( h_min ) . multiply ( fraction )) return dem . gte ( h_min ) . And ( dem . lt ( water_high )) fwdet ( water_img , dem , band = None , outlier_test = False , force_projection = False ) Implementation of the Flood Water Depth Estimation Tool Used to calculate water depth given a water map and elevation data Original paper: https://doi.org/10.5194/nhess-19-2053-2019 Earth Engine paper: https://doi.org/10.1109/LGRS.2020.3031190 Parameters: Name Type Description Default water_img ee.Image earth engine image object representing the water extent. Assumes values of 1 equal water. required dem ee.Image earth engine image object representing elevation required band str | None band name to use for algorithm, if set to None will use first band in image. default = None None outlier_test bool flag used to find and filter outlier dem values around water boundaries. default = False False force_projection bool flag used to force the output image projection to that of the input dem. default = False False Returns: Type Description ee.Image image of water depth in meters Source code in hydrafloods/depths.py def fwdet ( water_img , dem , band = None , outlier_test = False , force_projection = False ): \"\"\"Implementation of the Flood Water Depth Estimation Tool Used to calculate water depth given a water map and elevation data Original paper: https://doi.org/10.5194/nhess-19-2053-2019 Earth Engine paper: https://doi.org/10.1109/LGRS.2020.3031190 args: water_img (ee.Image): earth engine image object representing the water extent. Assumes values of 1 equal water. dem (ee.Image): earth engine image object representing elevation band (str | None): band name to use for algorithm, if set to `None` will use first band in image. default = None outlier_test (bool): flag used to find and filter outlier dem values around water boundaries. default = False force_projection (bool): flag used to force the output image projection to that of the input dem. default = False returns: ee.Image: image of water depth in meters \"\"\" proj = dem . projection () res = proj . nominalScale () . multiply ( 1.5 ) # select band to use for algorithm if band is None : water_img = water_img . select ([ 0 ]) . selfMask () else : water_img = water_img . select ( ee . String ( band )) . selfMask () if outlier_test : filled = filtering . modified_median_zscore ( dem ) expand = water_img . focal_max ( kernel = ee . Kernel . square ( radius = res , units = \"meters\" ) ) dem_mask = dem . updateMask ( water_img . gt ( 0 )) boundary = dem_mask . add ( expand ) filled = filtering . modified_median_zscore ( boundary , filled ) else : filled = dem # cumulative cost model mod = filled . updateMask ( water_img . mask () . eq ( 0 )) source = mod . mask () val = 10000 push = 5000 cost0 = ee . Image ( val ) . where ( source , 0 ) . cumulativeCost ( source , push ) cost1 = ee . Image ( val ) . where ( source , 1 ) . cumulativeCost ( source , push ) cost2 = mod . unmask ( val ) . cumulativeCost ( source , push ) costFill = cost2 . subtract ( cost0 ) . divide ( cost1 . subtract ( cost0 )) costSurface = mod . unmask ( 0 ) . add ( costFill ) # Kernel for low-pass filter boxcar = ee . Kernel . square ( radius = 3 , units = \"pixels\" , normalize = True ) # Floodwater depth calculation and smoothing using a low-pass filter depths = ( costSurface . subtract ( filled ) . convolve ( boxcar ) . updateMask ( water_img . mask ()) ) . rename ( \"depth\" ) # force min values to be 0 depths = depths . max ( ee . Image . constant ( 0 )) # force the output project to be that of the input dem if force_projection is true if force_projection : depths = depths . reproject ( proj ) return depths fwdet_experimental ( water_img , dem , iter = 10 , band = None , pixel_edge = 0 , boundary_definition = 'mean' , smooth_depths = True , force_projection = False ) Experimantal changes to the implementation of the Flood Water Depth Estimation Tool Used to calculate water depth given a water map and elevation data Difference from original FwDET implementation include ... Parameters: Name Type Description Default water_img ee.Image earth engine image object representing the water extent. required dem ee.Image earth engine image object representing elevation required iter int|ee.Number keyword to set number of iterations to fill up every pixel. The algorithm will calculate minimum iterations needed and use the max between the two. default = 10 10 band str | None,optional band name to use for algorithm, if set to None will use first band in image. default = None None pixel_edge int value that represents the boundary/edge of water. Note: must be client-side int object. default = 0 0 boundary_definition str method for defining the elevation at water edges. Options are 'mean' or 'nearest' Note: 'nearest' is the FwDET original method, 'mean' is an updated method. default=mean 'mean' smooth_depths bool flag to control if the resulting water depths should be smoothed or not, uses a 3x3 pixel mean. default=True True force_projection bool flag used to force the output image projection to that of the input dem. default = False False Returns: Type Description ee.Image image of water depth in meters Source code in hydrafloods/depths.py def fwdet_experimental ( water_img , dem , iter = 10 , band = None , pixel_edge = 0 , boundary_definition = \"mean\" , smooth_depths = True , force_projection = False , ): \"\"\"Experimantal changes to the implementation of the Flood Water Depth Estimation Tool Used to calculate water depth given a water map and elevation data Difference from original FwDET implementation include ... args: water_img (ee.Image): earth engine image object representing the water extent. dem (ee.Image): earth engine image object representing elevation iter (int|ee.Number, optional): keyword to set number of iterations to fill up every pixel. The algorithm will calculate minimum iterations needed and use the max between the two. default = 10 band (str | None,optional): band name to use for algorithm, if set to `None` will use first band in image. default = None pixel_edge (int): value that represents the boundary/edge of water. Note: must be client-side int object. default = 0 boundary_definition (str): method for defining the elevation at water edges. Options are 'mean' or 'nearest' Note: 'nearest' is the FwDET original method, 'mean' is an updated method. default=mean smooth_depths (bool): flag to control if the resulting water depths should be smoothed or not, uses a 3x3 pixel mean. default=True force_projection (bool): flag used to force the output image projection to that of the input dem. default = False returns: ee.Image: image of water depth in meters \"\"\" proj = dem . projection () res = water_img . projection () . nominalScale () . multiply ( 1.5 ) # select band to use for algorithm if band is None : water_img = water_img . select ([ 0 ]) else : water_img = water_img . select ( ee . String ( band )) # detect water edge watermap_edge = ( water_img . selfMask () . unmask ( - 999 ) . focal_min ( res , \"square\" , \"meters\" ) . eq ( - 999 ) ) watermap_edge = watermap_edge . updateMask ( water_img . unmask ( 0 )) watermap_edge = watermap_edge . selfMask () # watermap_edge = watermap_edge.reproject(water_img.projection()); # detect watermap extent outer edge (not to be used in algorithm) if pixel_edge > 0 : outer_edge = ( water_img . mask () . unmask ( 0 ) . gte ( 0 ) . unmask ( 0 , False ) . gt ( 0 ) . focal_min ( res . multiply ( ee . Number ( pixel_edge ) . add ( 1 )), \"square\" , \"meters\" ) . eq ( 0 ) ) outer_edge = outer_edge . updateMask ( outer_edge ) # outer_edge = outer_edge.reproject(water_img.projection()) # update watermap edge watermap_edge = watermap_edge . updateMask ( outer_edge . unmask ( 0 ) . eq ( 0 )) # watermap_edge = watermap_edge.reproject(water_img.projection()); else : outer_edge = water_img . mask () . unmask ( 0 ) . lt ( 0 ) DEM = dem # being super lazy here by setting a variable vs renaming things... # get elevation at edge # DEM_watered_edge = watermap_edge.multiply(DEM); # simply using boundary cell elevations DEM_masked = DEM . updateMask ( water_img . unmask ( 0 ) . eq ( 0 ) . add ( watermap_edge . unmask ( 0 )) . eq ( 1 ) ) DEM_watered_edge = watermap_edge . multiply ( DEM_masked . focal_mean ( res , \"square\" , \"meters\" ) ) DEM_watered_edge = DEM_watered_edge # .reproject(water_img.projection()) # calculate (approximation of) minimum needed iterations to fill up every pixel req_iter = ( water_img . eq ( 0 ) . add ( watermap_edge ) . fastDistanceTransform ( 50 , \"pixels\" , \"squared_euclidean\" ) . sqrt () . round () . updateMask ( water_img ) . updateMask ( outer_edge . unmask ( 0 ) . eq ( 0 )) . reproject ( water_img . projection ()) ) req_iter = req_iter . reduceRegion ( reducer = ee . Reducer . max (), geometry = water_img . geometry () . bounds ( 1e3 ), scale = res , maxPixels = 1e12 , ) . get ( \"distance\" ) # set iterations to be used iter = ee . Number ( req_iter ) . max ( iter ) # construct list to iterate over (list contents unused, just for iterations) iter_list = ee . List . sequence ( 0 , iter ) # use look up which algorithm to use for defining the boundary elevation values boundary_algos = { \"mean\" : _mbce , \"nearest\" : _nbce } f_boundary = partial ( boundary_algos [ boundary_definition ], mask = water_img , resolution = res ) # apply boundary condition algo, starting with edge values and filling it up further with each iteration DEM_watered_fill = ee . Image ( iter_list . iterate ( f_boundary , DEM_watered_edge )) DEM_watered = DEM_watered_fill . reproject ( water_img . projection ()) # derive water depths depths = DEM_watered . subtract ( DEM ) . max ( 0 ) # smooth water depths # Cohen et al. (2018) use a 3x3 pixel mean (but FwDET-GEE seems to use a boxcar kernel?) if smooth_depths : depths = depths . reduceNeighborhood ( reducer = ee . Reducer . mean (), kernel = ee . Kernel . square ( res , units = \"meters\" ), optimization = \"boxcar\" , # optimization for mean. ) # force the output project to be that of the input dem if force_projection is true if force_projection : depths = depths . reproject ( proj ) return depths . rename ( \"depth\" ) . set ( \"depth_iter\" , iter )","title":"depths module"},{"location":"depths/#hydrafloods.depths","text":"","title":"depths"},{"location":"depths/#hydrafloods.depths.downscale_wfraction","text":"Algorithm to downscale water fraction maps using DEM data Converts fractional water data to higher resolution binary water data Paper: https://doi.org/10.1016/j.rse.2013.03.015 Parameters: Name Type Description Default fraction ee.Image earth engine image object representing the fractional water extent within each pixel. required dem ee.Image earth engine image object representing elevation required Returns: Type Description ee.Image downscaled binary image of water Source code in hydrafloods/depths.py def downscale_wfraction ( fraction , dem ): \"\"\"Algorithm to downscale water fraction maps using DEM data Converts fractional water data to higher resolution binary water data Paper: https://doi.org/10.1016/j.rse.2013.03.015 args: fraction (ee.Image): earth engine image object representing the fractional water extent within each pixel. dem (ee.Image): earth engine image object representing elevation returns: ee.Image: downscaled binary image of water \"\"\" resolution = fraction . projection () . nominalScale () water_present = fraction . gt ( 0.0 ) h_min = dem . updateMask ( water_present ) . focal_min ( resolution , \"square\" , \"meters\" ) h_max = dem . updateMask ( water_present ) . focal_max ( resolution , \"square\" , \"meters\" ) water_high = h_min . add ( h_max . subtract ( h_min ) . multiply ( fraction )) return dem . gte ( h_min ) . And ( dem . lt ( water_high ))","title":"downscale_wfraction()"},{"location":"depths/#hydrafloods.depths.fwdet","text":"Implementation of the Flood Water Depth Estimation Tool Used to calculate water depth given a water map and elevation data Original paper: https://doi.org/10.5194/nhess-19-2053-2019 Earth Engine paper: https://doi.org/10.1109/LGRS.2020.3031190 Parameters: Name Type Description Default water_img ee.Image earth engine image object representing the water extent. Assumes values of 1 equal water. required dem ee.Image earth engine image object representing elevation required band str | None band name to use for algorithm, if set to None will use first band in image. default = None None outlier_test bool flag used to find and filter outlier dem values around water boundaries. default = False False force_projection bool flag used to force the output image projection to that of the input dem. default = False False Returns: Type Description ee.Image image of water depth in meters Source code in hydrafloods/depths.py def fwdet ( water_img , dem , band = None , outlier_test = False , force_projection = False ): \"\"\"Implementation of the Flood Water Depth Estimation Tool Used to calculate water depth given a water map and elevation data Original paper: https://doi.org/10.5194/nhess-19-2053-2019 Earth Engine paper: https://doi.org/10.1109/LGRS.2020.3031190 args: water_img (ee.Image): earth engine image object representing the water extent. Assumes values of 1 equal water. dem (ee.Image): earth engine image object representing elevation band (str | None): band name to use for algorithm, if set to `None` will use first band in image. default = None outlier_test (bool): flag used to find and filter outlier dem values around water boundaries. default = False force_projection (bool): flag used to force the output image projection to that of the input dem. default = False returns: ee.Image: image of water depth in meters \"\"\" proj = dem . projection () res = proj . nominalScale () . multiply ( 1.5 ) # select band to use for algorithm if band is None : water_img = water_img . select ([ 0 ]) . selfMask () else : water_img = water_img . select ( ee . String ( band )) . selfMask () if outlier_test : filled = filtering . modified_median_zscore ( dem ) expand = water_img . focal_max ( kernel = ee . Kernel . square ( radius = res , units = \"meters\" ) ) dem_mask = dem . updateMask ( water_img . gt ( 0 )) boundary = dem_mask . add ( expand ) filled = filtering . modified_median_zscore ( boundary , filled ) else : filled = dem # cumulative cost model mod = filled . updateMask ( water_img . mask () . eq ( 0 )) source = mod . mask () val = 10000 push = 5000 cost0 = ee . Image ( val ) . where ( source , 0 ) . cumulativeCost ( source , push ) cost1 = ee . Image ( val ) . where ( source , 1 ) . cumulativeCost ( source , push ) cost2 = mod . unmask ( val ) . cumulativeCost ( source , push ) costFill = cost2 . subtract ( cost0 ) . divide ( cost1 . subtract ( cost0 )) costSurface = mod . unmask ( 0 ) . add ( costFill ) # Kernel for low-pass filter boxcar = ee . Kernel . square ( radius = 3 , units = \"pixels\" , normalize = True ) # Floodwater depth calculation and smoothing using a low-pass filter depths = ( costSurface . subtract ( filled ) . convolve ( boxcar ) . updateMask ( water_img . mask ()) ) . rename ( \"depth\" ) # force min values to be 0 depths = depths . max ( ee . Image . constant ( 0 )) # force the output project to be that of the input dem if force_projection is true if force_projection : depths = depths . reproject ( proj ) return depths","title":"fwdet()"},{"location":"depths/#hydrafloods.depths.fwdet_experimental","text":"Experimantal changes to the implementation of the Flood Water Depth Estimation Tool Used to calculate water depth given a water map and elevation data Difference from original FwDET implementation include ... Parameters: Name Type Description Default water_img ee.Image earth engine image object representing the water extent. required dem ee.Image earth engine image object representing elevation required iter int|ee.Number keyword to set number of iterations to fill up every pixel. The algorithm will calculate minimum iterations needed and use the max between the two. default = 10 10 band str | None,optional band name to use for algorithm, if set to None will use first band in image. default = None None pixel_edge int value that represents the boundary/edge of water. Note: must be client-side int object. default = 0 0 boundary_definition str method for defining the elevation at water edges. Options are 'mean' or 'nearest' Note: 'nearest' is the FwDET original method, 'mean' is an updated method. default=mean 'mean' smooth_depths bool flag to control if the resulting water depths should be smoothed or not, uses a 3x3 pixel mean. default=True True force_projection bool flag used to force the output image projection to that of the input dem. default = False False Returns: Type Description ee.Image image of water depth in meters Source code in hydrafloods/depths.py def fwdet_experimental ( water_img , dem , iter = 10 , band = None , pixel_edge = 0 , boundary_definition = \"mean\" , smooth_depths = True , force_projection = False , ): \"\"\"Experimantal changes to the implementation of the Flood Water Depth Estimation Tool Used to calculate water depth given a water map and elevation data Difference from original FwDET implementation include ... args: water_img (ee.Image): earth engine image object representing the water extent. dem (ee.Image): earth engine image object representing elevation iter (int|ee.Number, optional): keyword to set number of iterations to fill up every pixel. The algorithm will calculate minimum iterations needed and use the max between the two. default = 10 band (str | None,optional): band name to use for algorithm, if set to `None` will use first band in image. default = None pixel_edge (int): value that represents the boundary/edge of water. Note: must be client-side int object. default = 0 boundary_definition (str): method for defining the elevation at water edges. Options are 'mean' or 'nearest' Note: 'nearest' is the FwDET original method, 'mean' is an updated method. default=mean smooth_depths (bool): flag to control if the resulting water depths should be smoothed or not, uses a 3x3 pixel mean. default=True force_projection (bool): flag used to force the output image projection to that of the input dem. default = False returns: ee.Image: image of water depth in meters \"\"\" proj = dem . projection () res = water_img . projection () . nominalScale () . multiply ( 1.5 ) # select band to use for algorithm if band is None : water_img = water_img . select ([ 0 ]) else : water_img = water_img . select ( ee . String ( band )) # detect water edge watermap_edge = ( water_img . selfMask () . unmask ( - 999 ) . focal_min ( res , \"square\" , \"meters\" ) . eq ( - 999 ) ) watermap_edge = watermap_edge . updateMask ( water_img . unmask ( 0 )) watermap_edge = watermap_edge . selfMask () # watermap_edge = watermap_edge.reproject(water_img.projection()); # detect watermap extent outer edge (not to be used in algorithm) if pixel_edge > 0 : outer_edge = ( water_img . mask () . unmask ( 0 ) . gte ( 0 ) . unmask ( 0 , False ) . gt ( 0 ) . focal_min ( res . multiply ( ee . Number ( pixel_edge ) . add ( 1 )), \"square\" , \"meters\" ) . eq ( 0 ) ) outer_edge = outer_edge . updateMask ( outer_edge ) # outer_edge = outer_edge.reproject(water_img.projection()) # update watermap edge watermap_edge = watermap_edge . updateMask ( outer_edge . unmask ( 0 ) . eq ( 0 )) # watermap_edge = watermap_edge.reproject(water_img.projection()); else : outer_edge = water_img . mask () . unmask ( 0 ) . lt ( 0 ) DEM = dem # being super lazy here by setting a variable vs renaming things... # get elevation at edge # DEM_watered_edge = watermap_edge.multiply(DEM); # simply using boundary cell elevations DEM_masked = DEM . updateMask ( water_img . unmask ( 0 ) . eq ( 0 ) . add ( watermap_edge . unmask ( 0 )) . eq ( 1 ) ) DEM_watered_edge = watermap_edge . multiply ( DEM_masked . focal_mean ( res , \"square\" , \"meters\" ) ) DEM_watered_edge = DEM_watered_edge # .reproject(water_img.projection()) # calculate (approximation of) minimum needed iterations to fill up every pixel req_iter = ( water_img . eq ( 0 ) . add ( watermap_edge ) . fastDistanceTransform ( 50 , \"pixels\" , \"squared_euclidean\" ) . sqrt () . round () . updateMask ( water_img ) . updateMask ( outer_edge . unmask ( 0 ) . eq ( 0 )) . reproject ( water_img . projection ()) ) req_iter = req_iter . reduceRegion ( reducer = ee . Reducer . max (), geometry = water_img . geometry () . bounds ( 1e3 ), scale = res , maxPixels = 1e12 , ) . get ( \"distance\" ) # set iterations to be used iter = ee . Number ( req_iter ) . max ( iter ) # construct list to iterate over (list contents unused, just for iterations) iter_list = ee . List . sequence ( 0 , iter ) # use look up which algorithm to use for defining the boundary elevation values boundary_algos = { \"mean\" : _mbce , \"nearest\" : _nbce } f_boundary = partial ( boundary_algos [ boundary_definition ], mask = water_img , resolution = res ) # apply boundary condition algo, starting with edge values and filling it up further with each iteration DEM_watered_fill = ee . Image ( iter_list . iterate ( f_boundary , DEM_watered_edge )) DEM_watered = DEM_watered_fill . reproject ( water_img . projection ()) # derive water depths depths = DEM_watered . subtract ( DEM ) . max ( 0 ) # smooth water depths # Cohen et al. (2018) use a 3x3 pixel mean (but FwDET-GEE seems to use a boxcar kernel?) if smooth_depths : depths = depths . reduceNeighborhood ( reducer = ee . Reducer . mean (), kernel = ee . Kernel . square ( res , units = \"meters\" ), optimization = \"boxcar\" , # optimization for mean. ) # force the output project to be that of the input dem if force_projection is true if force_projection : depths = depths . reproject ( proj ) return depths . rename ( \"depth\" ) . set ( \"depth_iter\" , iter )","title":"fwdet_experimental()"},{"location":"dswfp/","text":"hydrafloods.workflows.dswfp export_daily_surface_water ( region , target_date , harmonic_image = None , harmonic_collection = None , feature_names = None , label = None , look_back = 30 , lag = 4 , n_cycles = 2 , include_confidence = False , include_flood = False , fusion_samples = None , output_asset_path = None , output_bucket_path = None , initial_threshold = 0.1 , thresh_no_data = None , tile = False , tile_size = 1.0 , tile_buffer = 100000 , output_scale = 30 ) Last and repeated step of the daily surface water fusion process. This procedure uses the results from export_fusion_samples and export_surface_water_harmonics to build a random forest model to predict a water index from SAR imagery and predict water using the harmonic model. This process will correct the harmonic estimate using observed data and export the resulting imagery. Parameters: Name Type Description Default region ee.Geometry geographic region to look for coincident data and sample from required target_date str | datetime.datetime date to estimate surface water extent for required harmonic_image str Earth Engine Image asset id of the harmonic model weights exported by export_surface_water_harmonics . If left as None then harmonic_collection must be defined. default = None None harmonic_collection str Earth Engine ImageCollection asset id of the harmonic model weights from tile export_surface_water_harmonics . If left as None then harmonic_image must be defined. default = None None feature_names list[str], names of feature columns used to calculate label from None label str name of feature column to predict using feature_names None look_back int,optional number of days used to estimate short-term trend in water. default = 30 30 lag int number of days after target_date to begin look_back . default=4 4 n_cycles int number of interannual cycles to model. default = 2 2 include_confidence bool boolean keyword to specify if a confidence band will be exported with surface water image. If True then confidence will be calculated. default = False False include_flood bool boolean keyword to specify if a flood band will be exported with surface water image. If True then flood will be calculated based on JRC permanent water data. default = False False export_fusion bool boolean keyword to specify if the fusion image used to calculate water should be exported as a seperated task. If True then run fusion export task. default = False required fusion_samples str Earth Engine FeatureCollection asset id of samples to get a data fusion model from. Should be the asset output from export_fusion_samples None output_asset_path str Earth Engine asset id to save estimate water and fusion results to as image. If tile==True, then output_asset_path much be a precreated ImageCollection asset. If left as None then output_bucket_path must be specified. default = None None output_bucket_path str GCP cloud bucket path to save estimate water and fusion results to cloud optimized geotiffs. If tile==True, then multiple file will be created. If left as None then output_asset_path must be specified. default = None None initial_threshold float initial threshold value used in edge_otsu thresholding algorithm to segment water from fusion image. default = 0.1 0.1 tile bool boolean keyword to tile exports. If false will try to calculate harmonic weights as image. If true, it will tile area and recusively call to export smaller areas. If true then expects that output_asset_path is an ImageCollection. default = False False tile_size float resolution in decimal degrees to create tiles over region for smaller exports. Only used if tile==True. default = 1.0 1.0 tile_buffer float,optional buffer size in meters to buffer tiles to calculate threshold. This is used to ensure running tiled exports produces consistent results at tile seams. default = 100000 100000 output_scale float output resolution of harmonic weight image. default = 30 30 Exceptions: Type Description ValueError if fusion_samples is None ValueError if both harmonic_image and harmonic_collection is None ValueError if both 'output_asset_path' and 'output_bucket_path' is None Source code in hydrafloods/workflows/dswfp.py def export_daily_surface_water ( region , target_date , harmonic_image = None , harmonic_collection = None , feature_names = None , label = None , look_back = 30 , lag = 4 , n_cycles = 2 , include_confidence = False , include_flood = False , fusion_samples = None , output_asset_path = None , output_bucket_path = None , initial_threshold = 0.1 , thresh_no_data = None , tile = False , tile_size = 1.0 , tile_buffer = 100000 , output_scale = 30 , ): \"\"\"Last and repeated step of the daily surface water fusion process. This procedure uses the results from `export_fusion_samples` and `export_surface_water_harmonics` to build a random forest model to predict a water index from SAR imagery and predict water using the harmonic model. This process will correct the harmonic estimate using observed data and export the resulting imagery. args: region (ee.Geometry): geographic region to look for coincident data and sample from target_date (str | datetime.datetime): date to estimate surface water extent for harmonic_image (str, optional): Earth Engine Image asset id of the harmonic model weights exported by `export_surface_water_harmonics`. If left as None then `harmonic_collection` must be defined. default = None harmonic_collection (str, optional): Earth Engine ImageCollection asset id of the harmonic model weights from tile `export_surface_water_harmonics`. If left as None then `harmonic_image` must be defined. default = None feature_names (list[str],): names of feature columns used to calculate `label` from label (str): name of feature column to predict using `feature_names` look_back (int,optional): number of days used to estimate short-term trend in water. default = 30 lag (int, optional): number of days after `target_date` to begin `look_back`. default=4 n_cycles (int, optional): number of interannual cycles to model. default = 2 include_confidence (bool, optional): boolean keyword to specify if a confidence band will be exported with surface water image. If True then confidence will be calculated. default = False include_flood (bool, optional): boolean keyword to specify if a flood band will be exported with surface water image. If True then flood will be calculated based on JRC permanent water data. default = False export_fusion (bool, optional): boolean keyword to specify if the fusion image used to calculate water should be exported as a seperated task. If True then run fusion export task. default = False fusion_samples (str): Earth Engine FeatureCollection asset id of samples to get a data fusion model from. Should be the asset output from `export_fusion_samples` output_asset_path (str): Earth Engine asset id to save estimate water and fusion results to as image. If tile==True, then output_asset_path much be a precreated ImageCollection asset. If left as None then `output_bucket_path` must be specified. default = None output_bucket_path (str): GCP cloud bucket path to save estimate water and fusion results to cloud optimized geotiffs. If tile==True, then multiple file will be created. If left as None then `output_asset_path` must be specified. default = None initial_threshold (float, optional): initial threshold value used in `edge_otsu` thresholding algorithm to segment water from fusion image. default = 0.1 tile (bool, optional): boolean keyword to tile exports. If false will try to calculate harmonic weights as image. If true, it will tile area and recusively call to export smaller areas. If true then expects that `output_asset_path` is an ImageCollection. default = False tile_size (float, optional): resolution in decimal degrees to create tiles over region for smaller exports. Only used if tile==True. default = 1.0 tile_buffer (float,optional): buffer size in meters to buffer tiles to calculate threshold. This is used to ensure running tiled exports produces consistent results at tile seams. default = 100000 output_scale (float, optional): output resolution of harmonic weight image. default = 30 raises: ValueError: if `fusion_samples` is None ValueError: if both`harmonic_image` and `harmonic_collection` is None ValueError: if both 'output_asset_path' and 'output_bucket_path' is None \"\"\" def get_residuals ( i ): \"\"\"Closure function to calculate residuals of harmonic water estimate compared to observed data. \"\"\" i = ee . Number ( i ) t_diff = ( ee . Number ( i ) . multiply ( - 1 ) . subtract ( lag ) ) # calc how many days to adjust ini date new_date = target_date . advance ( t_diff , \"day\" ) # calculate new date corr_img = ( ds . collection . select ( label ) . filterDate ( new_date , new_date . advance ( 1 , \"day\" )) . median () ) time_img = timeseries . get_dummy_img ( new_date ) harmon_pred = ( timeseries . add_harmonic_coefs ( time_img ) . multiply ( harmonic_coefs ) . reduce ( \"sum\" ) ) harmon_diff = harmon_pred . subtract ( corr_img ) . rename ( \"residual\" ) return harmon_diff . set ( \"system:time_start\" , new_date . millis ()) def calc_confidence ( i ): \"\"\"Closure function to calculate confidence in water estimate using monte carlo methods and simulating errors in long- and short-term water dynamics \"\"\" i = ee . Number ( i ) # uniform sampling of std dev at 95% confidence interval long_term_seed = i . add ( 500 ) short_term_seed = i . add ( 1000 ) long_term_random = ee . Image . random ( long_term_seed ) . multiply ( 3.92 ) . subtract ( 1.96 ) short_term_random = ( ee . Image . random ( short_term_seed ) . multiply ( 3.92 ) . subtract ( 1.96 ) ) lin_sim = lin_pred . add ( short_term_random . multiply ( linCi )) har_sim = har_pred . add ( long_term_random . multiply ( harCi )) sim_pred = har_sim . subtract ( lin_sim ) # random_water = thresholding.bmax_otsu(random_combination,invert=True) # naive estimate of water (>0) return sim_pred . gt ( ci_threshold ) . uint8 () if tile : if tile : land_area = ( ee . FeatureCollection ( \"USDOS/LSIB_SIMPLE/2017\" ) . filterBounds ( region ) . geometry ( 100 ) . buffer ( 2500 , maxError = 100 ) ) grid = geeutils . tile_region ( region , intersect_geom = land_area , grid_size = tile_size ) n = grid . size () . getInfo () grid_list = grid . toList ( n ) for i in range ( n ): if output_asset_path is not None : output_asset_tile = output_asset_path + f \"daily_tile { i : 05d } \" else : output_asset_tile = None if output_bucket_path is not None : output_bucket_tile = output_bucket_path + f \"_tile { i : 05d } \" else : output_bucket_tile = None grid_tile = ee . Feature ( grid_list . get ( i )) . geometry () export_daily_surface_water ( region = grid_tile , target_date = target_date , harmonic_image = harmonic_image , harmonic_collection = harmonic_collection , feature_names = feature_names , label = label , look_back = look_back , lag = lag , n_cycles = n_cycles , include_confidence = include_confidence , include_flood = include_flood , fusion_samples = fusion_samples , output_asset_path = output_asset_tile , output_bucket_path = output_bucket_tile , initial_threshold = initial_threshold , thresh_no_data = thresh_no_data , tile = False , tile_buffer = tile_buffer , output_scale = output_scale , ) else : if not isinstance ( target_date , ee . Date ): target_date = ee . Date ( target_date ) end_time = target_date . advance ( - ( lag - 1 ), \"day\" ) start_time = end_time . advance ( - look_back , \"day\" ) if fusion_samples is not None : fusion_model , scaling_dict = ml . random_forest_ee ( 30 , fusion_samples , feature_names , label , scaling = None , mode = \"regression\" , ) else : raise ValueError ( \"'fusion_samples' needs to be defined to run fusion process\" ) now = datetime . datetime . now () time_id = now . strftime ( \"%Y%m %d %H%M %s \" ) time_str = now . strftime ( \"%Y-%m- %d %H:%M: %s \" ) if harmonic_image is not None : harmonic_coefs = ee . Image ( harmonic_image ) harmonic_coefs = harmonic_coefs . multiply ( ee . Image ( ee . Number ( harmonic_coefs . get ( \"scale_factor\" ))) ) elif harmonic_collection is not None : harmonic_collection = ee . ImageCollection ( harmonic_collection ) first = ee . Image ( harmonic_collection . first ()) harmonic_coefs = ee . Image ( harmonic_collection . mosaic ()) . multiply ( ee . Image ( ee . Number ( first . get ( \"scale_factor\" ))) ) else : raise ValueError ( \"Either 'harmonic_image' or 'harmonic_collection' needs to be defined to run fusion process\" ) if include_confidence : harmonic_err = harmonic_coefs . select ( \".*(x|y|n)$\" ) harmonic_coefs = harmonic_coefs . select ( \"^(c|t|s).*\" ) else : harmonic_coefs = harmonic_coefs . select ( \"^(c|t|s).*\" ) prod_region = region . buffer ( tile_buffer , 100 ) ds = _fuse_dataset ( region , start_time , end_time , fusion_model , scaling_dict , feature_names , target_band = label , use_viirs = True , ) dummy_target = timeseries . get_dummy_img ( target_date ) weights = ee . ImageCollection . fromImages ( ee . List . sequence ( 0 , look_back - 1 ) . map ( get_residuals ) ) . sort ( \"system:time_start\" ) weights_lr = timeseries . fit_linear_trend ( weights , dependent = \"residual\" , output_err = include_confidence ) weights_coefs = weights_lr . select ( \"^(c|t).*\" ) lin_pred = ( dummy_target . multiply ( weights_coefs ) . reduce ( \"sum\" ) . rename ( \"residual_est\" ) ) har_pred = ( timeseries . add_harmonic_coefs ( dummy_target , n_cycles = n_cycles ) . multiply ( harmonic_coefs ) . reduce ( \"sum\" ) ) fused_pred = ( har_pred . subtract ( lin_pred )) . rename ( \"fused_product\" ) ci_threshold = thresholding . edge_otsu ( fused_pred , initial_threshold = initial_threshold , thresh_no_data = thresh_no_data , edge_buffer = 300 , region = prod_region , invert = True , scale = 150 , return_threshold = True , ) permanent_water = ( ee . ImageCollection ( \"JRC/GSW1_2/YearlyHistory\" ) . filterDate ( \"1985-01-01\" , end_time ) . limit ( 5 , \"system:time_start\" , False ) . map ( lambda x : x . select ( \"waterClass\" ) . eq ( 3 )) . sum () . unmask ( 0 ) . gt ( 0 ) ) water = fused_pred . gt ( ci_threshold ) . Or ( permanent_water ) . rename ( \"water\" ) . uint8 () if include_flood : flood = water . select ( \"water\" ) . And ( permanent_water . Not ()) . rename ( \"flood\" ) water = water . addBands ( flood ) if include_confidence : weights_err = weights_lr . select ( \".*(x|y|n)$\" ) linCi = weights_err . expression ( \"mse * (1 + (1/n) + ((t-xmean)**2/xr))**(1/2)\" , { \"mse\" : weights_err . select ( \"residual_y\" ), \"n\" : weights_err . select ( \"n\" ), \"xmean\" : weights_err . select ( \"mean_x\" ), \"xr\" : weights_err . select ( \"residual_x\" ), \"t\" : dummy_target . select ( \"time\" ), }, ) harCi = harmonic_err . expression ( \"mse * (1 + (1/n) + ((t-xmean)**2/xr))**(1/2)\" , { \"mse\" : harmonic_err . select ( \"residual_y\" ), \"n\" : harmonic_err . select ( \"n\" ), \"xmean\" : harmonic_err . select ( \"mean_x\" ), \"xr\" : harmonic_err . select ( \"residual_x\" ), \"t\" : dummy_target . select ( \"time\" ), }, ) confidence = ( ee . ImageCollection . fromImages ( ee . List . sequence ( 0 , 99 ) . map ( calc_confidence ) ) . reduce ( ee . Reducer . mean (), 16 ) . multiply ( 100 ) . uint8 () . rename ( \"confidence\" ) ) out_water = water . addBands ( confidence ) else : out_water = water if output_asset_path is not None : # create metadata dict metadata = ee . Dictionary ( { \"hf_version\" : hf . __version__ , \"system:time_start\" : target_date . millis (), \"system:time_end\" : target_date . advance ( 86399 , \"seconds\" ) . millis (), \"execution_time\" : time_str , \"lag\" : lag , \"look_back\" : look_back , } ) geeutils . export_image ( out_water . set ( metadata . combine ({ \"product\" : \"water\" })), region , output_asset_path + \"_water\" , description = f \"hydrafloods_water_ee_export_ { time_id } \" , scale = output_scale , crs = \"EPSG:4326\" , ) elif output_bucket_path is not None : export_region = region . bounds ( maxError = 100 ) . getInfo ()[ \"coordinates\" ] bucket_path , ext = os . path . splitext ( output_bucket_path ) fcomponents = bucket_path . split ( \"/\" ) bucket = fcomponents [ 2 ] fpath = fcomponents [ 3 : - 1 ] # TODO: remove extension from string formulation f_water = \"/\" . join ( fpath + [ fcomponents [ - 1 ] + \"_water\" + ext ]) f_fusion = \"/\" . join ( fpath + [ fcomponents [ - 1 ] + \"_fusion\" + ext ]) water_task = ee . batch . Export . image . toCloudStorage ( image = out_water , description = f \"hydrafloods_water_gcp_export_ { time_id } \" , bucket = bucket , fileNamePrefix = f_water , region = export_region , scale = output_scale , crs = \"EPSG:4326\" , maxPixels = 1e13 , fileFormat = \"GeoTIFF\" , formatOptions = { \"cloudOptimized\" : True }, ) water_task . start () else : raise ValueError ( \"Either 'output_asset_path' or 'output_bucket_path' needs to be defined to run fusion export process\" ) return export_fusion_samples ( region , start_time , end_time , output_asset_path , stratify_samples = True , sample_scale = 30 , n_samples = 25 , seed = 0 ) First step of the daily surface water fusion process. This procedure samples values from coincident optical and SAR data so that we can use ML for data fusion. This will calculate MNDWI, NWI, AEWInsh, and AEWIsh optical water indices and a few indices from SAR imagery (VV/VH, NDPI, NVVI, NVHI) to predict a water index. Parameters: Name Type Description Default region ee.Geometry geographic region to look for coincident data and sample from required start_time str | datetime.datetime start time used to look for coincident data required end_time str | datetime.datetime end time used to look for coincident data required output_asset_path str Earth Engine asset id to save sampled values too required stratify_samples bool boolean keyword to specify for sampling data stratified by a combination of the MODIS land cover and JRC surface water occurrence. If False, then a random sampling wil be used. default = False True sample_scale float resolution in meters to sample data at 30 n_samples int number of samples to collect per coincident image pair. If stratified_samples == True, this value be be samples per class. default = 25 25 seed int,optional random number generator seed, used for setting random sampling. default = 0 0 Source code in hydrafloods/workflows/dswfp.py def export_fusion_samples ( region , start_time , end_time , output_asset_path , stratify_samples = True , sample_scale = 30 , n_samples = 25 , seed = 0 , ): \"\"\"First step of the daily surface water fusion process. This procedure samples values from coincident optical and SAR data so that we can use ML for data fusion. This will calculate MNDWI, NWI, AEWInsh, and AEWIsh optical water indices and a few indices from SAR imagery (VV/VH, NDPI, NVVI, NVHI) to predict a water index. args: region (ee.Geometry): geographic region to look for coincident data and sample from start_time (str | datetime.datetime): start time used to look for coincident data end_time (str | datetime.datetime): end time used to look for coincident data output_asset_path (str): Earth Engine asset id to save sampled values too stratify_samples (bool, optional): boolean keyword to specify for sampling data stratified by a combination of the MODIS land cover and JRC surface water occurrence. If False, then a random sampling wil be used. default = False sample_scale (float, optional): resolution in meters to sample data at n_samples (int, optional): number of samples to collect per coincident image pair. If stratified_samples == True, this value be be samples per class. default = 25 seed (int,optional): random number generator seed, used for setting random sampling. default = 0 \"\"\" dem = ee . Image ( \"NASA/NASADEM_HGT/001\" ) . select ( \"elevation\" ) optical_water_indices = [ \"mndwi\" , \"nwi\" , \"aewish\" , \"aewinsh\" ] ds_kwargs = dict ( region = region , start_time = start_time , end_time = end_time , rescale = True ) dsa_kwargs = { ** ds_kwargs , ** { \"apply_band_adjustment\" : True }} lc8 = datasets . Landsat8 ( ** ds_kwargs ) le7 = datasets . Landsat7 ( ** dsa_kwargs ) s2 = datasets . Sentinel2 ( ** dsa_kwargs ) _ = ds_kwargs . pop ( \"rescale\" ) s1a = datasets . Sentinel1Asc ( ** ds_kwargs ) s1d = datasets . Sentinel1Desc ( ** ds_kwargs ) years = ( s1a . collection . aggregate_array ( \"system:time_start\" ) . map ( lambda x : ee . Date ( x ) . get ( \"year\" )) . distinct () ) sar_proc = ( ( corrections . slope_correction , dict ( elevation = dem , buffer = 50 , ), ), hf . gamma_map , ( geeutils . add_indices , dict ( indices = [ \"vv_vh_ratio\" , \"ndpi\" , \"nvvi\" , \"nvhi\" ])), ) s1a . pipe ( sar_proc , inplace = True ) s1d . pipe ( sar_proc , inplace = True ) s1a_anomalies = _calc_sar_anomalies ( years , s1a ) s1d_anomalies = _calc_sar_anomalies ( years , s1d ) s1a . collection = s1a_anomalies s1d . collection = s1d_anomalies s1 = s1a . merge ( s1d ) optical = lc8 . merge ( s2 ) . merge ( le7 ) optical = optical . apply_func ( geeutils . add_indices , indices = optical_water_indices ) ds = optical . join ( s1 ) sample_region = ( ds . collection . map ( geeutils . get_geoms ) . union ( maxError = 1000 ) . geometry ( maxError = 1000 ) ) . intersection ( region , maxError = 1000 ) img_list = ds . collection . toList ( ds . collection . size ()) output_features = ee . FeatureCollection ([]) aggregate_samples = 0 if stratify_samples : class_band = \"strata\" interval = 20 water_freq = ee . Image ( \"JRC/GSW1_2/GlobalSurfaceWater\" ) . select ( \"occurrence\" ) class_intervals = ee . List . sequence ( 0 , 80 , interval ) logging . info ( f \"Water intervals: { class_intervals . getInfo () } \" ) n_water_classes = class_intervals . size () water_classes = ee . List . sequence ( 1 , n_water_classes ) logging . info ( f \"Water Classes: { water_classes . getInfo () } \" ) water_img = ( ee . ImageCollection . fromImages ( class_intervals . map ( lambda x : water_freq . gte ( ee . Number ( x ))) ) . reduce ( ee . Reducer . sum ()) . uint8 () . rename ( class_band ) ) # class_band = \"landcover\" igbp_classes = ee . List ( [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 ] ) ipcc_classes = ee . List ([ 1 , 1 , 1 , 1 , 1 , 2 , 2 , 2 , 2 , 2 , 6 , 3 , 5 , 3 , 4 , 4 , 6 ]) lc_img = ( ee . ImageCollection ( \"MODIS/006/MCD12Q1\" ) . limit ( 1 , \"system:time_start\" , True ) . first () . remap ( igbp_classes , ipcc_classes ) . rename ( class_band ) ) . add ( water_classes . size ()) lc_classes = ( ipcc_classes . distinct () . map ( lambda x : ee . Number ( x ) . add ( water_classes . size ())) . sort () ) logging . info ( f \"LC Classes: { lc_classes . getInfo () } \" ) final_strata_img = water_img . unmask ( lc_img ) . rename ( class_band ) half = ee . Number ( n_samples ) . multiply ( n_water_classes . subtract ( 1 )) n_lc = half . divide ( lc_classes . size ()) . round () all_classes = ( water_classes . slice ( 1 ) . cat ( lc_classes ) . map ( lambda x : ee . Number ( x ) . subtract ( 1 )) ) n_water_samples = ee . List . repeat ( n_samples , n_water_classes ) n_lc_samples = ee . List . repeat ( n_lc , lc_classes . size ()) logging . info ( f \"n Water Samples { n_water_samples . getInfo () } \" ) logging . info ( f \"n LC Samples { n_lc_samples . getInfo () } \" ) base_samples = water_img . select ( class_band ) . stratifiedSample ( region = sample_region , numPoints = n_samples , classBand = class_band , scale = sample_scale , seed = seed , classValues = water_classes , classPoints = n_water_samples , tileScale = 16 , geometries = True , ) else : base_samples = ee . FeatureCollection . randomPoints ( sample_region , n_samples , seed ) def sample_img ( img ): geom = img . geometry () date = img . date () week = date . get ( \"week\" ) year = date . get ( \"year\" ) new_seed = week . add ( year ) . add ( seed ) lc_samples = lc_img . select ( class_band ) . stratifiedSample ( region = sample_region , numPoints = n_samples , classBand = class_band , scale = sample_scale , seed = new_seed , classValues = lc_classes , classPoints = n_lc_samples , tileScale = 16 , geometries = True , ) samples = ( base_samples . merge ( lc_samples ) . filterBounds ( geom ) . randomColumn ( \"random\" , seed ) ) features = img . sampleRegions ( samples , scale = sample_scale , tileScale = 16 , geometries = True ) features = features . map ( lambda x : ee . Feature ( x ) . set ( \"timestamp\" , date . millis ())) return features sample_features = ds . collection . map ( sample_img ) . flatten () output_features = ee . FeatureCollection ( sample_features . aggregate_array ( class_band ) . distinct () . map ( lambda x : sample_features . filter ( ee . Filter . eq ( class_band , x )) . randomColumn () ) ) . flatten () now = datetime . datetime . now () time_id = now . strftime ( \"%Y%m %d %H%M %s \" ) task = ee . batch . Export . table . toAsset ( collection = output_features , assetId = output_asset_path , description = f \"hydrafloods_fusion_samples_export_ { time_id } \" , ) task . start () logging . info ( f \"Started export task for { output_asset_path } \" ) return export_surface_water_harmonics ( region , start_time , end_time , output_asset_path , n_cycles = 2 , feature_names = None , label = None , fusion_samples = None , tile = False , tile_size = 1.0 , output_scale = 30 ) Second step of the daily surface water fusion process. This procedure uses samples from export_fusion_samples to build a random forest model to predict a water index from SAR imagery. This a time series of optical-SAR fused data is used to calculate a harmonic model for long-term surface water trend and is exported to an Earth Engine asset. Parameters: Name Type Description Default region ee.Geometry geographic region to look for coincident data and sample from required start_time str | datetime.datetime start time used to look for coincident data required end_time str | datetime.datetime end time used to look for coincident data required output_asset_path str Earth Engine asset id to save harmonic model weights to as image. If tile==True, then output_asset_path much be a precreated ImageCollection asset required n_cycles int number of interannual cycles to model. default = 2 2 feature_names list[str], names of feature columns used to calculate label from None label str name of feature column to predict using feature_names None fusion_samples str Earth Engine FeatureCollection asset id of samples to get a data fusion model from. Should be the asset output from export_fusion_samples None tile bool boolean keyword to tile exports. If false will try to calculate harmonic weights as image. If true, it will tile area and recusively call to export smaller areas. If true then expects that output_asset_path is an ImageCollection. default = False False tile_size float resolution in decimal degrees to create tiles over region for smaller exports. Only used if tile==True. default = 1.0 1.0 output_scale float output resolution of harmonic weight image. default = 30 30 Source code in hydrafloods/workflows/dswfp.py def export_surface_water_harmonics ( region , start_time , end_time , output_asset_path , n_cycles = 2 , feature_names = None , label = None , fusion_samples = None , tile = False , tile_size = 1.0 , output_scale = 30 , ): \"\"\"Second step of the daily surface water fusion process. This procedure uses samples from `export_fusion_samples` to build a random forest model to predict a water index from SAR imagery. This a time series of optical-SAR fused data is used to calculate a harmonic model for long-term surface water trend and is exported to an Earth Engine asset. args: region (ee.Geometry): geographic region to look for coincident data and sample from start_time (str | datetime.datetime): start time used to look for coincident data end_time (str | datetime.datetime): end time used to look for coincident data output_asset_path (str): Earth Engine asset id to save harmonic model weights to as image. If tile==True, then output_asset_path much be a precreated ImageCollection asset n_cycles (int, optional): number of interannual cycles to model. default = 2 feature_names (list[str],): names of feature columns used to calculate `label` from label (str): name of feature column to predict using `feature_names` fusion_samples (str): Earth Engine FeatureCollection asset id of samples to get a data fusion model from. Should be the asset output from `export_fusion_samples` tile (bool, optional): boolean keyword to tile exports. If false will try to calculate harmonic weights as image. If true, it will tile area and recusively call to export smaller areas. If true then expects that `output_asset_path` is an ImageCollection. default = False tile_size (float, optional): resolution in decimal degrees to create tiles over region for smaller exports. Only used if tile==True. default = 1.0 output_scale (float, optional): output resolution of harmonic weight image. default = 30 \"\"\" if tile : land_area = ( ee . FeatureCollection ( \"USDOS/LSIB_SIMPLE/2017\" ) . filterBounds ( region ) . geometry ( 1000 ) . buffer ( 2500 , maxError = 1000 ) ) grid = geeutils . tile_region ( region , intersect_geom = land_area , grid_size = tile_size ) n = grid . size () . getInfo () grid_list = grid . toList ( n ) for i in range ( n ): grid_tile = ee . Feature ( grid_list . get ( i )) . geometry () if output_asset_path is not None : output_tile_path = output_asset_path + f \"harmonics_t { i : 05d } \" export_surface_water_harmonics ( region = grid_tile , start_time = start_time , end_time = end_time , n_cycles = n_cycles , feature_names = feature_names , label = label , fusion_samples = fusion_samples , output_asset_path = output_tile_path , tile = False , tile_size = tile_size , output_scale = output_scale , ) else : if fusion_samples is not None : fusion_model , scaling_dict = ml . random_forest_ee ( 30 , fusion_samples , feature_names , label , scaling = None , mode = \"regression\" , ) else : raise ValueError ( \"Either 'fusion_samples' or 'fusion_model_path' needs to be defined to run fusion process\" ) ds = _fuse_dataset ( region , start_time , end_time , fusion_model , scaling_dict , feature_names , target_band = label , ) now = datetime . datetime . now () time_id = now . strftime ( \"%Y%m %d %H%M %s \" ) time_str = now . strftime ( \"%Y-%m- %d %H:%M: %s \" ) scale_factor = 0.0001 # create metadata dict metadata = ee . Dictionary ( { \"hf_version\" : hf . __version__ , \"scale_factor\" : scale_factor , \"fit_time_start\" : start_time , \"fit_time_end\" : end_time , \"execution_time\" : time_str , } ) harmonic_coefs = timeseries . fit_harmonic_trend ( ds , dependent = label , n_cycles = n_cycles , output_err = True ) harmonic_coefs = harmonic_coefs . divide ( scale_factor ) . int32 () . set ( metadata ) if output_asset_path is not None : geeutils . export_image ( harmonic_coefs , region , output_asset_path , description = f \"hydrafloods_harmonic_coefficient_export_ { time_id } \" , scale = output_scale , crs = \"EPSG:4326\" , ) else : raise ValueError ( \"'output_asset_path' needs to be defined to run fusion export process\" ) return merge_gcp_tiled_results ( bucket_path , pattern , region , retries =- 1 , clean_up = False , cloud_project = None , file_dims = None , output_scale = 30 ) Helper function to merge tiled surface water estimates from export_daily_surface_water into on cloud optimized geotiff on Google Cloud Platform Parameters: Name Type Description Default bucket_path str GCP cloud bucket path to read tiled cloud optimized geotiffs. Will also export merged file to this path. required pattern str regex string to search for specific files. Useful for selecting files from a specific bucket subdirectory or date in filename required region ee.Geometry geographic region to export merged data over. region must align with region from the tiled export required retries int number of retries to search for tiled data. Useful is runtime is unknown and the merge function is run at a set time each day. If less than or equal to zero, no retries will be used. default = -1 -1 clean_up bool boolean keyword to delete tile geotiffs after merge is complete. Only use if you are sure the merging is/will be successful. default = False False cloud_project str name of GCP cloud project name that the cloud storage bucket is part of. If nothing is provided, it will try to use default system GCP credentials. default = None None file_dims int | list[int] the dimensions in pixels of each image file, if the image is too large to fit in a single file. May specify a single number to indicate a square shape, or a list of two dimensions to indicate (width,height). Note that the image will still be clipped to the overall image dimensions. Must be a multiple of shardSize (256). If none, then Earth Engine will automatically estimate dimensions. default = None None output_scale float output resolution of harmonic weight image. default = 30 30 Source code in hydrafloods/workflows/dswfp.py def merge_gcp_tiled_results ( bucket_path , pattern , region , retries =- 1 , clean_up = False , cloud_project = None , file_dims = None , output_scale = 30 , ): \"\"\"Helper function to merge tiled surface water estimates from `export_daily_surface_water` into on cloud optimized geotiff on Google Cloud Platform args: bucket_path (str): GCP cloud bucket path to read tiled cloud optimized geotiffs. Will also export merged file to this path. pattern (str): regex string to search for specific files. Useful for selecting files from a specific bucket subdirectory or date in filename region (ee.Geometry): geographic region to export merged data over. region must align with region from the tiled export retries (int, optional): number of retries to search for tiled data. Useful is runtime is unknown and the merge function is run at a set time each day. If less than or equal to zero, no retries will be used. default = -1 clean_up (bool, optional): boolean keyword to delete tile geotiffs after merge is complete. Only use if you are sure the merging is/will be successful. default = False cloud_project (str, optional): name of GCP cloud project name that the cloud storage bucket is part of. If nothing is provided, it will try to use default system GCP credentials. default = None file_dims (int | list[int], optional): the dimensions in pixels of each image file, if the image is too large to fit in a single file. May specify a single number to indicate a square shape, or a list of two dimensions to indicate (width,height). Note that the image will still be clipped to the overall image dimensions. Must be a multiple of shardSize (256). If none, then Earth Engine will automatically estimate dimensions. default = None output_scale (float, optional): output resolution of harmonic weight image. default = 30 \"\"\" land_area = ( ee . FeatureCollection ( \"USDOS/LSIB_SIMPLE/2017\" ) . filterBounds ( region ) . geometry ( 100 ) . buffer ( 2500 , maxError = 100 ) ) grid = geeutils . tile_region ( region , intersect_geom = land_area , grid_size = 1.0 ) expected_n = grid . size () . getInfo () fcomponents = bucket_path . split ( \"/\" ) bucket = fcomponents [ 2 ] fpath = pattern . replace ( \"*\" , \"\" ) files = utils . list_gcs_objs ( bucket , pattern = pattern , project = cloud_project ) if len ( files ) == expected_n : images = [ ee . Image . loadGeoTIFF ( file ) for file in files ] merged = ee . ImageCollection . fromImages ( images ) . mosaic () export_region = region . bounds ( maxError = 100 ) . getInfo ()[ \"coordinates\" ] # bucket_path, ext = os.path.splitext(output_bucket_path) now = datetime . datetime . now () time_id = now . strftime ( \"%Y%m %d %H%M %s \" ) task = ee . batch . Export . image . toCloudStorage ( image = merged , description = f \"hydrafloods_merge_gcp_export_ { time_id } \" , bucket = bucket , fileNamePrefix = fpath , region = export_region , scale = output_scale , crs = \"EPSG:4326\" , fileDimensions = file_dims , maxPixels = 1e13 , fileFormat = \"GeoTIFF\" , formatOptions = { \"cloudOptimized\" : True }, ) task . start () if clean_up : gcsfs . GCSFileSystem . rm ( files ) elif retries > 0 : time . sleep ( 60 * 10 ) merge_gcp_tiled_results ( bucket_path , pattern , region , retries = ( retries - 1 )) else : raise RuntimeError ( f \"could not find all expected tiles to merge...found { len ( files ) } tiles but expected { expected_n } \" ) return","title":"workflows.dswfp module"},{"location":"dswfp/#hydrafloods.workflows.dswfp","text":"","title":"dswfp"},{"location":"dswfp/#hydrafloods.workflows.dswfp.export_daily_surface_water","text":"Last and repeated step of the daily surface water fusion process. This procedure uses the results from export_fusion_samples and export_surface_water_harmonics to build a random forest model to predict a water index from SAR imagery and predict water using the harmonic model. This process will correct the harmonic estimate using observed data and export the resulting imagery. Parameters: Name Type Description Default region ee.Geometry geographic region to look for coincident data and sample from required target_date str | datetime.datetime date to estimate surface water extent for required harmonic_image str Earth Engine Image asset id of the harmonic model weights exported by export_surface_water_harmonics . If left as None then harmonic_collection must be defined. default = None None harmonic_collection str Earth Engine ImageCollection asset id of the harmonic model weights from tile export_surface_water_harmonics . If left as None then harmonic_image must be defined. default = None None feature_names list[str], names of feature columns used to calculate label from None label str name of feature column to predict using feature_names None look_back int,optional number of days used to estimate short-term trend in water. default = 30 30 lag int number of days after target_date to begin look_back . default=4 4 n_cycles int number of interannual cycles to model. default = 2 2 include_confidence bool boolean keyword to specify if a confidence band will be exported with surface water image. If True then confidence will be calculated. default = False False include_flood bool boolean keyword to specify if a flood band will be exported with surface water image. If True then flood will be calculated based on JRC permanent water data. default = False False export_fusion bool boolean keyword to specify if the fusion image used to calculate water should be exported as a seperated task. If True then run fusion export task. default = False required fusion_samples str Earth Engine FeatureCollection asset id of samples to get a data fusion model from. Should be the asset output from export_fusion_samples None output_asset_path str Earth Engine asset id to save estimate water and fusion results to as image. If tile==True, then output_asset_path much be a precreated ImageCollection asset. If left as None then output_bucket_path must be specified. default = None None output_bucket_path str GCP cloud bucket path to save estimate water and fusion results to cloud optimized geotiffs. If tile==True, then multiple file will be created. If left as None then output_asset_path must be specified. default = None None initial_threshold float initial threshold value used in edge_otsu thresholding algorithm to segment water from fusion image. default = 0.1 0.1 tile bool boolean keyword to tile exports. If false will try to calculate harmonic weights as image. If true, it will tile area and recusively call to export smaller areas. If true then expects that output_asset_path is an ImageCollection. default = False False tile_size float resolution in decimal degrees to create tiles over region for smaller exports. Only used if tile==True. default = 1.0 1.0 tile_buffer float,optional buffer size in meters to buffer tiles to calculate threshold. This is used to ensure running tiled exports produces consistent results at tile seams. default = 100000 100000 output_scale float output resolution of harmonic weight image. default = 30 30 Exceptions: Type Description ValueError if fusion_samples is None ValueError if both harmonic_image and harmonic_collection is None ValueError if both 'output_asset_path' and 'output_bucket_path' is None Source code in hydrafloods/workflows/dswfp.py def export_daily_surface_water ( region , target_date , harmonic_image = None , harmonic_collection = None , feature_names = None , label = None , look_back = 30 , lag = 4 , n_cycles = 2 , include_confidence = False , include_flood = False , fusion_samples = None , output_asset_path = None , output_bucket_path = None , initial_threshold = 0.1 , thresh_no_data = None , tile = False , tile_size = 1.0 , tile_buffer = 100000 , output_scale = 30 , ): \"\"\"Last and repeated step of the daily surface water fusion process. This procedure uses the results from `export_fusion_samples` and `export_surface_water_harmonics` to build a random forest model to predict a water index from SAR imagery and predict water using the harmonic model. This process will correct the harmonic estimate using observed data and export the resulting imagery. args: region (ee.Geometry): geographic region to look for coincident data and sample from target_date (str | datetime.datetime): date to estimate surface water extent for harmonic_image (str, optional): Earth Engine Image asset id of the harmonic model weights exported by `export_surface_water_harmonics`. If left as None then `harmonic_collection` must be defined. default = None harmonic_collection (str, optional): Earth Engine ImageCollection asset id of the harmonic model weights from tile `export_surface_water_harmonics`. If left as None then `harmonic_image` must be defined. default = None feature_names (list[str],): names of feature columns used to calculate `label` from label (str): name of feature column to predict using `feature_names` look_back (int,optional): number of days used to estimate short-term trend in water. default = 30 lag (int, optional): number of days after `target_date` to begin `look_back`. default=4 n_cycles (int, optional): number of interannual cycles to model. default = 2 include_confidence (bool, optional): boolean keyword to specify if a confidence band will be exported with surface water image. If True then confidence will be calculated. default = False include_flood (bool, optional): boolean keyword to specify if a flood band will be exported with surface water image. If True then flood will be calculated based on JRC permanent water data. default = False export_fusion (bool, optional): boolean keyword to specify if the fusion image used to calculate water should be exported as a seperated task. If True then run fusion export task. default = False fusion_samples (str): Earth Engine FeatureCollection asset id of samples to get a data fusion model from. Should be the asset output from `export_fusion_samples` output_asset_path (str): Earth Engine asset id to save estimate water and fusion results to as image. If tile==True, then output_asset_path much be a precreated ImageCollection asset. If left as None then `output_bucket_path` must be specified. default = None output_bucket_path (str): GCP cloud bucket path to save estimate water and fusion results to cloud optimized geotiffs. If tile==True, then multiple file will be created. If left as None then `output_asset_path` must be specified. default = None initial_threshold (float, optional): initial threshold value used in `edge_otsu` thresholding algorithm to segment water from fusion image. default = 0.1 tile (bool, optional): boolean keyword to tile exports. If false will try to calculate harmonic weights as image. If true, it will tile area and recusively call to export smaller areas. If true then expects that `output_asset_path` is an ImageCollection. default = False tile_size (float, optional): resolution in decimal degrees to create tiles over region for smaller exports. Only used if tile==True. default = 1.0 tile_buffer (float,optional): buffer size in meters to buffer tiles to calculate threshold. This is used to ensure running tiled exports produces consistent results at tile seams. default = 100000 output_scale (float, optional): output resolution of harmonic weight image. default = 30 raises: ValueError: if `fusion_samples` is None ValueError: if both`harmonic_image` and `harmonic_collection` is None ValueError: if both 'output_asset_path' and 'output_bucket_path' is None \"\"\" def get_residuals ( i ): \"\"\"Closure function to calculate residuals of harmonic water estimate compared to observed data. \"\"\" i = ee . Number ( i ) t_diff = ( ee . Number ( i ) . multiply ( - 1 ) . subtract ( lag ) ) # calc how many days to adjust ini date new_date = target_date . advance ( t_diff , \"day\" ) # calculate new date corr_img = ( ds . collection . select ( label ) . filterDate ( new_date , new_date . advance ( 1 , \"day\" )) . median () ) time_img = timeseries . get_dummy_img ( new_date ) harmon_pred = ( timeseries . add_harmonic_coefs ( time_img ) . multiply ( harmonic_coefs ) . reduce ( \"sum\" ) ) harmon_diff = harmon_pred . subtract ( corr_img ) . rename ( \"residual\" ) return harmon_diff . set ( \"system:time_start\" , new_date . millis ()) def calc_confidence ( i ): \"\"\"Closure function to calculate confidence in water estimate using monte carlo methods and simulating errors in long- and short-term water dynamics \"\"\" i = ee . Number ( i ) # uniform sampling of std dev at 95% confidence interval long_term_seed = i . add ( 500 ) short_term_seed = i . add ( 1000 ) long_term_random = ee . Image . random ( long_term_seed ) . multiply ( 3.92 ) . subtract ( 1.96 ) short_term_random = ( ee . Image . random ( short_term_seed ) . multiply ( 3.92 ) . subtract ( 1.96 ) ) lin_sim = lin_pred . add ( short_term_random . multiply ( linCi )) har_sim = har_pred . add ( long_term_random . multiply ( harCi )) sim_pred = har_sim . subtract ( lin_sim ) # random_water = thresholding.bmax_otsu(random_combination,invert=True) # naive estimate of water (>0) return sim_pred . gt ( ci_threshold ) . uint8 () if tile : if tile : land_area = ( ee . FeatureCollection ( \"USDOS/LSIB_SIMPLE/2017\" ) . filterBounds ( region ) . geometry ( 100 ) . buffer ( 2500 , maxError = 100 ) ) grid = geeutils . tile_region ( region , intersect_geom = land_area , grid_size = tile_size ) n = grid . size () . getInfo () grid_list = grid . toList ( n ) for i in range ( n ): if output_asset_path is not None : output_asset_tile = output_asset_path + f \"daily_tile { i : 05d } \" else : output_asset_tile = None if output_bucket_path is not None : output_bucket_tile = output_bucket_path + f \"_tile { i : 05d } \" else : output_bucket_tile = None grid_tile = ee . Feature ( grid_list . get ( i )) . geometry () export_daily_surface_water ( region = grid_tile , target_date = target_date , harmonic_image = harmonic_image , harmonic_collection = harmonic_collection , feature_names = feature_names , label = label , look_back = look_back , lag = lag , n_cycles = n_cycles , include_confidence = include_confidence , include_flood = include_flood , fusion_samples = fusion_samples , output_asset_path = output_asset_tile , output_bucket_path = output_bucket_tile , initial_threshold = initial_threshold , thresh_no_data = thresh_no_data , tile = False , tile_buffer = tile_buffer , output_scale = output_scale , ) else : if not isinstance ( target_date , ee . Date ): target_date = ee . Date ( target_date ) end_time = target_date . advance ( - ( lag - 1 ), \"day\" ) start_time = end_time . advance ( - look_back , \"day\" ) if fusion_samples is not None : fusion_model , scaling_dict = ml . random_forest_ee ( 30 , fusion_samples , feature_names , label , scaling = None , mode = \"regression\" , ) else : raise ValueError ( \"'fusion_samples' needs to be defined to run fusion process\" ) now = datetime . datetime . now () time_id = now . strftime ( \"%Y%m %d %H%M %s \" ) time_str = now . strftime ( \"%Y-%m- %d %H:%M: %s \" ) if harmonic_image is not None : harmonic_coefs = ee . Image ( harmonic_image ) harmonic_coefs = harmonic_coefs . multiply ( ee . Image ( ee . Number ( harmonic_coefs . get ( \"scale_factor\" ))) ) elif harmonic_collection is not None : harmonic_collection = ee . ImageCollection ( harmonic_collection ) first = ee . Image ( harmonic_collection . first ()) harmonic_coefs = ee . Image ( harmonic_collection . mosaic ()) . multiply ( ee . Image ( ee . Number ( first . get ( \"scale_factor\" ))) ) else : raise ValueError ( \"Either 'harmonic_image' or 'harmonic_collection' needs to be defined to run fusion process\" ) if include_confidence : harmonic_err = harmonic_coefs . select ( \".*(x|y|n)$\" ) harmonic_coefs = harmonic_coefs . select ( \"^(c|t|s).*\" ) else : harmonic_coefs = harmonic_coefs . select ( \"^(c|t|s).*\" ) prod_region = region . buffer ( tile_buffer , 100 ) ds = _fuse_dataset ( region , start_time , end_time , fusion_model , scaling_dict , feature_names , target_band = label , use_viirs = True , ) dummy_target = timeseries . get_dummy_img ( target_date ) weights = ee . ImageCollection . fromImages ( ee . List . sequence ( 0 , look_back - 1 ) . map ( get_residuals ) ) . sort ( \"system:time_start\" ) weights_lr = timeseries . fit_linear_trend ( weights , dependent = \"residual\" , output_err = include_confidence ) weights_coefs = weights_lr . select ( \"^(c|t).*\" ) lin_pred = ( dummy_target . multiply ( weights_coefs ) . reduce ( \"sum\" ) . rename ( \"residual_est\" ) ) har_pred = ( timeseries . add_harmonic_coefs ( dummy_target , n_cycles = n_cycles ) . multiply ( harmonic_coefs ) . reduce ( \"sum\" ) ) fused_pred = ( har_pred . subtract ( lin_pred )) . rename ( \"fused_product\" ) ci_threshold = thresholding . edge_otsu ( fused_pred , initial_threshold = initial_threshold , thresh_no_data = thresh_no_data , edge_buffer = 300 , region = prod_region , invert = True , scale = 150 , return_threshold = True , ) permanent_water = ( ee . ImageCollection ( \"JRC/GSW1_2/YearlyHistory\" ) . filterDate ( \"1985-01-01\" , end_time ) . limit ( 5 , \"system:time_start\" , False ) . map ( lambda x : x . select ( \"waterClass\" ) . eq ( 3 )) . sum () . unmask ( 0 ) . gt ( 0 ) ) water = fused_pred . gt ( ci_threshold ) . Or ( permanent_water ) . rename ( \"water\" ) . uint8 () if include_flood : flood = water . select ( \"water\" ) . And ( permanent_water . Not ()) . rename ( \"flood\" ) water = water . addBands ( flood ) if include_confidence : weights_err = weights_lr . select ( \".*(x|y|n)$\" ) linCi = weights_err . expression ( \"mse * (1 + (1/n) + ((t-xmean)**2/xr))**(1/2)\" , { \"mse\" : weights_err . select ( \"residual_y\" ), \"n\" : weights_err . select ( \"n\" ), \"xmean\" : weights_err . select ( \"mean_x\" ), \"xr\" : weights_err . select ( \"residual_x\" ), \"t\" : dummy_target . select ( \"time\" ), }, ) harCi = harmonic_err . expression ( \"mse * (1 + (1/n) + ((t-xmean)**2/xr))**(1/2)\" , { \"mse\" : harmonic_err . select ( \"residual_y\" ), \"n\" : harmonic_err . select ( \"n\" ), \"xmean\" : harmonic_err . select ( \"mean_x\" ), \"xr\" : harmonic_err . select ( \"residual_x\" ), \"t\" : dummy_target . select ( \"time\" ), }, ) confidence = ( ee . ImageCollection . fromImages ( ee . List . sequence ( 0 , 99 ) . map ( calc_confidence ) ) . reduce ( ee . Reducer . mean (), 16 ) . multiply ( 100 ) . uint8 () . rename ( \"confidence\" ) ) out_water = water . addBands ( confidence ) else : out_water = water if output_asset_path is not None : # create metadata dict metadata = ee . Dictionary ( { \"hf_version\" : hf . __version__ , \"system:time_start\" : target_date . millis (), \"system:time_end\" : target_date . advance ( 86399 , \"seconds\" ) . millis (), \"execution_time\" : time_str , \"lag\" : lag , \"look_back\" : look_back , } ) geeutils . export_image ( out_water . set ( metadata . combine ({ \"product\" : \"water\" })), region , output_asset_path + \"_water\" , description = f \"hydrafloods_water_ee_export_ { time_id } \" , scale = output_scale , crs = \"EPSG:4326\" , ) elif output_bucket_path is not None : export_region = region . bounds ( maxError = 100 ) . getInfo ()[ \"coordinates\" ] bucket_path , ext = os . path . splitext ( output_bucket_path ) fcomponents = bucket_path . split ( \"/\" ) bucket = fcomponents [ 2 ] fpath = fcomponents [ 3 : - 1 ] # TODO: remove extension from string formulation f_water = \"/\" . join ( fpath + [ fcomponents [ - 1 ] + \"_water\" + ext ]) f_fusion = \"/\" . join ( fpath + [ fcomponents [ - 1 ] + \"_fusion\" + ext ]) water_task = ee . batch . Export . image . toCloudStorage ( image = out_water , description = f \"hydrafloods_water_gcp_export_ { time_id } \" , bucket = bucket , fileNamePrefix = f_water , region = export_region , scale = output_scale , crs = \"EPSG:4326\" , maxPixels = 1e13 , fileFormat = \"GeoTIFF\" , formatOptions = { \"cloudOptimized\" : True }, ) water_task . start () else : raise ValueError ( \"Either 'output_asset_path' or 'output_bucket_path' needs to be defined to run fusion export process\" ) return","title":"export_daily_surface_water()"},{"location":"dswfp/#hydrafloods.workflows.dswfp.export_fusion_samples","text":"First step of the daily surface water fusion process. This procedure samples values from coincident optical and SAR data so that we can use ML for data fusion. This will calculate MNDWI, NWI, AEWInsh, and AEWIsh optical water indices and a few indices from SAR imagery (VV/VH, NDPI, NVVI, NVHI) to predict a water index. Parameters: Name Type Description Default region ee.Geometry geographic region to look for coincident data and sample from required start_time str | datetime.datetime start time used to look for coincident data required end_time str | datetime.datetime end time used to look for coincident data required output_asset_path str Earth Engine asset id to save sampled values too required stratify_samples bool boolean keyword to specify for sampling data stratified by a combination of the MODIS land cover and JRC surface water occurrence. If False, then a random sampling wil be used. default = False True sample_scale float resolution in meters to sample data at 30 n_samples int number of samples to collect per coincident image pair. If stratified_samples == True, this value be be samples per class. default = 25 25 seed int,optional random number generator seed, used for setting random sampling. default = 0 0 Source code in hydrafloods/workflows/dswfp.py def export_fusion_samples ( region , start_time , end_time , output_asset_path , stratify_samples = True , sample_scale = 30 , n_samples = 25 , seed = 0 , ): \"\"\"First step of the daily surface water fusion process. This procedure samples values from coincident optical and SAR data so that we can use ML for data fusion. This will calculate MNDWI, NWI, AEWInsh, and AEWIsh optical water indices and a few indices from SAR imagery (VV/VH, NDPI, NVVI, NVHI) to predict a water index. args: region (ee.Geometry): geographic region to look for coincident data and sample from start_time (str | datetime.datetime): start time used to look for coincident data end_time (str | datetime.datetime): end time used to look for coincident data output_asset_path (str): Earth Engine asset id to save sampled values too stratify_samples (bool, optional): boolean keyword to specify for sampling data stratified by a combination of the MODIS land cover and JRC surface water occurrence. If False, then a random sampling wil be used. default = False sample_scale (float, optional): resolution in meters to sample data at n_samples (int, optional): number of samples to collect per coincident image pair. If stratified_samples == True, this value be be samples per class. default = 25 seed (int,optional): random number generator seed, used for setting random sampling. default = 0 \"\"\" dem = ee . Image ( \"NASA/NASADEM_HGT/001\" ) . select ( \"elevation\" ) optical_water_indices = [ \"mndwi\" , \"nwi\" , \"aewish\" , \"aewinsh\" ] ds_kwargs = dict ( region = region , start_time = start_time , end_time = end_time , rescale = True ) dsa_kwargs = { ** ds_kwargs , ** { \"apply_band_adjustment\" : True }} lc8 = datasets . Landsat8 ( ** ds_kwargs ) le7 = datasets . Landsat7 ( ** dsa_kwargs ) s2 = datasets . Sentinel2 ( ** dsa_kwargs ) _ = ds_kwargs . pop ( \"rescale\" ) s1a = datasets . Sentinel1Asc ( ** ds_kwargs ) s1d = datasets . Sentinel1Desc ( ** ds_kwargs ) years = ( s1a . collection . aggregate_array ( \"system:time_start\" ) . map ( lambda x : ee . Date ( x ) . get ( \"year\" )) . distinct () ) sar_proc = ( ( corrections . slope_correction , dict ( elevation = dem , buffer = 50 , ), ), hf . gamma_map , ( geeutils . add_indices , dict ( indices = [ \"vv_vh_ratio\" , \"ndpi\" , \"nvvi\" , \"nvhi\" ])), ) s1a . pipe ( sar_proc , inplace = True ) s1d . pipe ( sar_proc , inplace = True ) s1a_anomalies = _calc_sar_anomalies ( years , s1a ) s1d_anomalies = _calc_sar_anomalies ( years , s1d ) s1a . collection = s1a_anomalies s1d . collection = s1d_anomalies s1 = s1a . merge ( s1d ) optical = lc8 . merge ( s2 ) . merge ( le7 ) optical = optical . apply_func ( geeutils . add_indices , indices = optical_water_indices ) ds = optical . join ( s1 ) sample_region = ( ds . collection . map ( geeutils . get_geoms ) . union ( maxError = 1000 ) . geometry ( maxError = 1000 ) ) . intersection ( region , maxError = 1000 ) img_list = ds . collection . toList ( ds . collection . size ()) output_features = ee . FeatureCollection ([]) aggregate_samples = 0 if stratify_samples : class_band = \"strata\" interval = 20 water_freq = ee . Image ( \"JRC/GSW1_2/GlobalSurfaceWater\" ) . select ( \"occurrence\" ) class_intervals = ee . List . sequence ( 0 , 80 , interval ) logging . info ( f \"Water intervals: { class_intervals . getInfo () } \" ) n_water_classes = class_intervals . size () water_classes = ee . List . sequence ( 1 , n_water_classes ) logging . info ( f \"Water Classes: { water_classes . getInfo () } \" ) water_img = ( ee . ImageCollection . fromImages ( class_intervals . map ( lambda x : water_freq . gte ( ee . Number ( x ))) ) . reduce ( ee . Reducer . sum ()) . uint8 () . rename ( class_band ) ) # class_band = \"landcover\" igbp_classes = ee . List ( [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 , 11 , 12 , 13 , 14 , 15 , 16 , 17 ] ) ipcc_classes = ee . List ([ 1 , 1 , 1 , 1 , 1 , 2 , 2 , 2 , 2 , 2 , 6 , 3 , 5 , 3 , 4 , 4 , 6 ]) lc_img = ( ee . ImageCollection ( \"MODIS/006/MCD12Q1\" ) . limit ( 1 , \"system:time_start\" , True ) . first () . remap ( igbp_classes , ipcc_classes ) . rename ( class_band ) ) . add ( water_classes . size ()) lc_classes = ( ipcc_classes . distinct () . map ( lambda x : ee . Number ( x ) . add ( water_classes . size ())) . sort () ) logging . info ( f \"LC Classes: { lc_classes . getInfo () } \" ) final_strata_img = water_img . unmask ( lc_img ) . rename ( class_band ) half = ee . Number ( n_samples ) . multiply ( n_water_classes . subtract ( 1 )) n_lc = half . divide ( lc_classes . size ()) . round () all_classes = ( water_classes . slice ( 1 ) . cat ( lc_classes ) . map ( lambda x : ee . Number ( x ) . subtract ( 1 )) ) n_water_samples = ee . List . repeat ( n_samples , n_water_classes ) n_lc_samples = ee . List . repeat ( n_lc , lc_classes . size ()) logging . info ( f \"n Water Samples { n_water_samples . getInfo () } \" ) logging . info ( f \"n LC Samples { n_lc_samples . getInfo () } \" ) base_samples = water_img . select ( class_band ) . stratifiedSample ( region = sample_region , numPoints = n_samples , classBand = class_band , scale = sample_scale , seed = seed , classValues = water_classes , classPoints = n_water_samples , tileScale = 16 , geometries = True , ) else : base_samples = ee . FeatureCollection . randomPoints ( sample_region , n_samples , seed ) def sample_img ( img ): geom = img . geometry () date = img . date () week = date . get ( \"week\" ) year = date . get ( \"year\" ) new_seed = week . add ( year ) . add ( seed ) lc_samples = lc_img . select ( class_band ) . stratifiedSample ( region = sample_region , numPoints = n_samples , classBand = class_band , scale = sample_scale , seed = new_seed , classValues = lc_classes , classPoints = n_lc_samples , tileScale = 16 , geometries = True , ) samples = ( base_samples . merge ( lc_samples ) . filterBounds ( geom ) . randomColumn ( \"random\" , seed ) ) features = img . sampleRegions ( samples , scale = sample_scale , tileScale = 16 , geometries = True ) features = features . map ( lambda x : ee . Feature ( x ) . set ( \"timestamp\" , date . millis ())) return features sample_features = ds . collection . map ( sample_img ) . flatten () output_features = ee . FeatureCollection ( sample_features . aggregate_array ( class_band ) . distinct () . map ( lambda x : sample_features . filter ( ee . Filter . eq ( class_band , x )) . randomColumn () ) ) . flatten () now = datetime . datetime . now () time_id = now . strftime ( \"%Y%m %d %H%M %s \" ) task = ee . batch . Export . table . toAsset ( collection = output_features , assetId = output_asset_path , description = f \"hydrafloods_fusion_samples_export_ { time_id } \" , ) task . start () logging . info ( f \"Started export task for { output_asset_path } \" ) return","title":"export_fusion_samples()"},{"location":"dswfp/#hydrafloods.workflows.dswfp.export_surface_water_harmonics","text":"Second step of the daily surface water fusion process. This procedure uses samples from export_fusion_samples to build a random forest model to predict a water index from SAR imagery. This a time series of optical-SAR fused data is used to calculate a harmonic model for long-term surface water trend and is exported to an Earth Engine asset. Parameters: Name Type Description Default region ee.Geometry geographic region to look for coincident data and sample from required start_time str | datetime.datetime start time used to look for coincident data required end_time str | datetime.datetime end time used to look for coincident data required output_asset_path str Earth Engine asset id to save harmonic model weights to as image. If tile==True, then output_asset_path much be a precreated ImageCollection asset required n_cycles int number of interannual cycles to model. default = 2 2 feature_names list[str], names of feature columns used to calculate label from None label str name of feature column to predict using feature_names None fusion_samples str Earth Engine FeatureCollection asset id of samples to get a data fusion model from. Should be the asset output from export_fusion_samples None tile bool boolean keyword to tile exports. If false will try to calculate harmonic weights as image. If true, it will tile area and recusively call to export smaller areas. If true then expects that output_asset_path is an ImageCollection. default = False False tile_size float resolution in decimal degrees to create tiles over region for smaller exports. Only used if tile==True. default = 1.0 1.0 output_scale float output resolution of harmonic weight image. default = 30 30 Source code in hydrafloods/workflows/dswfp.py def export_surface_water_harmonics ( region , start_time , end_time , output_asset_path , n_cycles = 2 , feature_names = None , label = None , fusion_samples = None , tile = False , tile_size = 1.0 , output_scale = 30 , ): \"\"\"Second step of the daily surface water fusion process. This procedure uses samples from `export_fusion_samples` to build a random forest model to predict a water index from SAR imagery. This a time series of optical-SAR fused data is used to calculate a harmonic model for long-term surface water trend and is exported to an Earth Engine asset. args: region (ee.Geometry): geographic region to look for coincident data and sample from start_time (str | datetime.datetime): start time used to look for coincident data end_time (str | datetime.datetime): end time used to look for coincident data output_asset_path (str): Earth Engine asset id to save harmonic model weights to as image. If tile==True, then output_asset_path much be a precreated ImageCollection asset n_cycles (int, optional): number of interannual cycles to model. default = 2 feature_names (list[str],): names of feature columns used to calculate `label` from label (str): name of feature column to predict using `feature_names` fusion_samples (str): Earth Engine FeatureCollection asset id of samples to get a data fusion model from. Should be the asset output from `export_fusion_samples` tile (bool, optional): boolean keyword to tile exports. If false will try to calculate harmonic weights as image. If true, it will tile area and recusively call to export smaller areas. If true then expects that `output_asset_path` is an ImageCollection. default = False tile_size (float, optional): resolution in decimal degrees to create tiles over region for smaller exports. Only used if tile==True. default = 1.0 output_scale (float, optional): output resolution of harmonic weight image. default = 30 \"\"\" if tile : land_area = ( ee . FeatureCollection ( \"USDOS/LSIB_SIMPLE/2017\" ) . filterBounds ( region ) . geometry ( 1000 ) . buffer ( 2500 , maxError = 1000 ) ) grid = geeutils . tile_region ( region , intersect_geom = land_area , grid_size = tile_size ) n = grid . size () . getInfo () grid_list = grid . toList ( n ) for i in range ( n ): grid_tile = ee . Feature ( grid_list . get ( i )) . geometry () if output_asset_path is not None : output_tile_path = output_asset_path + f \"harmonics_t { i : 05d } \" export_surface_water_harmonics ( region = grid_tile , start_time = start_time , end_time = end_time , n_cycles = n_cycles , feature_names = feature_names , label = label , fusion_samples = fusion_samples , output_asset_path = output_tile_path , tile = False , tile_size = tile_size , output_scale = output_scale , ) else : if fusion_samples is not None : fusion_model , scaling_dict = ml . random_forest_ee ( 30 , fusion_samples , feature_names , label , scaling = None , mode = \"regression\" , ) else : raise ValueError ( \"Either 'fusion_samples' or 'fusion_model_path' needs to be defined to run fusion process\" ) ds = _fuse_dataset ( region , start_time , end_time , fusion_model , scaling_dict , feature_names , target_band = label , ) now = datetime . datetime . now () time_id = now . strftime ( \"%Y%m %d %H%M %s \" ) time_str = now . strftime ( \"%Y-%m- %d %H:%M: %s \" ) scale_factor = 0.0001 # create metadata dict metadata = ee . Dictionary ( { \"hf_version\" : hf . __version__ , \"scale_factor\" : scale_factor , \"fit_time_start\" : start_time , \"fit_time_end\" : end_time , \"execution_time\" : time_str , } ) harmonic_coefs = timeseries . fit_harmonic_trend ( ds , dependent = label , n_cycles = n_cycles , output_err = True ) harmonic_coefs = harmonic_coefs . divide ( scale_factor ) . int32 () . set ( metadata ) if output_asset_path is not None : geeutils . export_image ( harmonic_coefs , region , output_asset_path , description = f \"hydrafloods_harmonic_coefficient_export_ { time_id } \" , scale = output_scale , crs = \"EPSG:4326\" , ) else : raise ValueError ( \"'output_asset_path' needs to be defined to run fusion export process\" ) return","title":"export_surface_water_harmonics()"},{"location":"dswfp/#hydrafloods.workflows.dswfp.merge_gcp_tiled_results","text":"Helper function to merge tiled surface water estimates from export_daily_surface_water into on cloud optimized geotiff on Google Cloud Platform Parameters: Name Type Description Default bucket_path str GCP cloud bucket path to read tiled cloud optimized geotiffs. Will also export merged file to this path. required pattern str regex string to search for specific files. Useful for selecting files from a specific bucket subdirectory or date in filename required region ee.Geometry geographic region to export merged data over. region must align with region from the tiled export required retries int number of retries to search for tiled data. Useful is runtime is unknown and the merge function is run at a set time each day. If less than or equal to zero, no retries will be used. default = -1 -1 clean_up bool boolean keyword to delete tile geotiffs after merge is complete. Only use if you are sure the merging is/will be successful. default = False False cloud_project str name of GCP cloud project name that the cloud storage bucket is part of. If nothing is provided, it will try to use default system GCP credentials. default = None None file_dims int | list[int] the dimensions in pixels of each image file, if the image is too large to fit in a single file. May specify a single number to indicate a square shape, or a list of two dimensions to indicate (width,height). Note that the image will still be clipped to the overall image dimensions. Must be a multiple of shardSize (256). If none, then Earth Engine will automatically estimate dimensions. default = None None output_scale float output resolution of harmonic weight image. default = 30 30 Source code in hydrafloods/workflows/dswfp.py def merge_gcp_tiled_results ( bucket_path , pattern , region , retries =- 1 , clean_up = False , cloud_project = None , file_dims = None , output_scale = 30 , ): \"\"\"Helper function to merge tiled surface water estimates from `export_daily_surface_water` into on cloud optimized geotiff on Google Cloud Platform args: bucket_path (str): GCP cloud bucket path to read tiled cloud optimized geotiffs. Will also export merged file to this path. pattern (str): regex string to search for specific files. Useful for selecting files from a specific bucket subdirectory or date in filename region (ee.Geometry): geographic region to export merged data over. region must align with region from the tiled export retries (int, optional): number of retries to search for tiled data. Useful is runtime is unknown and the merge function is run at a set time each day. If less than or equal to zero, no retries will be used. default = -1 clean_up (bool, optional): boolean keyword to delete tile geotiffs after merge is complete. Only use if you are sure the merging is/will be successful. default = False cloud_project (str, optional): name of GCP cloud project name that the cloud storage bucket is part of. If nothing is provided, it will try to use default system GCP credentials. default = None file_dims (int | list[int], optional): the dimensions in pixels of each image file, if the image is too large to fit in a single file. May specify a single number to indicate a square shape, or a list of two dimensions to indicate (width,height). Note that the image will still be clipped to the overall image dimensions. Must be a multiple of shardSize (256). If none, then Earth Engine will automatically estimate dimensions. default = None output_scale (float, optional): output resolution of harmonic weight image. default = 30 \"\"\" land_area = ( ee . FeatureCollection ( \"USDOS/LSIB_SIMPLE/2017\" ) . filterBounds ( region ) . geometry ( 100 ) . buffer ( 2500 , maxError = 100 ) ) grid = geeutils . tile_region ( region , intersect_geom = land_area , grid_size = 1.0 ) expected_n = grid . size () . getInfo () fcomponents = bucket_path . split ( \"/\" ) bucket = fcomponents [ 2 ] fpath = pattern . replace ( \"*\" , \"\" ) files = utils . list_gcs_objs ( bucket , pattern = pattern , project = cloud_project ) if len ( files ) == expected_n : images = [ ee . Image . loadGeoTIFF ( file ) for file in files ] merged = ee . ImageCollection . fromImages ( images ) . mosaic () export_region = region . bounds ( maxError = 100 ) . getInfo ()[ \"coordinates\" ] # bucket_path, ext = os.path.splitext(output_bucket_path) now = datetime . datetime . now () time_id = now . strftime ( \"%Y%m %d %H%M %s \" ) task = ee . batch . Export . image . toCloudStorage ( image = merged , description = f \"hydrafloods_merge_gcp_export_ { time_id } \" , bucket = bucket , fileNamePrefix = fpath , region = export_region , scale = output_scale , crs = \"EPSG:4326\" , fileDimensions = file_dims , maxPixels = 1e13 , fileFormat = \"GeoTIFF\" , formatOptions = { \"cloudOptimized\" : True }, ) task . start () if clean_up : gcsfs . GCSFileSystem . rm ( files ) elif retries > 0 : time . sleep ( 60 * 10 ) merge_gcp_tiled_results ( bucket_path , pattern , region , retries = ( retries - 1 )) else : raise RuntimeError ( f \"could not find all expected tiles to merge...found { len ( files ) } tiles but expected { expected_n } \" ) return","title":"merge_gcp_tiled_results()"},{"location":"fetch/","text":"hydrafloods.fetch atms ( credentials , start_time = '2000-01-01' , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = './' ) Function to download Suomi-NPP ATMS passive microwave data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple | list Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path, optioanl Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def atms ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\" Function to download Suomi-NPP ATMS passive microwave data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple | list, optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optioanl): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" CONCEPTID = \"C1442068516-GES_DISC\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , ) fetching ( conceptid , start_time , region , credentials , out_directory , max_results = 500 , end_time = None ) Function to download data from NASA CMR by specifying a dataset, time and region. Uses CMR to handle spatio-temporal query and extracts data download urls Parameters: Name Type Description Default conceptid str String of dataset concept id to search for required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) required region tuple[float] | list[float] Bounding box of region to search as iterable in W,S,E,N order required credentials tuple | list EarthData username and password login credentials as iterable required out_directory str|pathlib.Path Local directory to downaload data to required max_results int Maximum number of items to search and download. default = 500 500 end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd). default = start_time + 1day None Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def fetching ( conceptid , start_time , region , credentials , out_directory , max_results = 500 , end_time = None , ): \"\"\" Function to download data from NASA CMR by specifying a dataset, time and region. Uses CMR to handle spatio-temporal query and extracts data download urls args: conceptid (str): String of dataset concept id to search for start_time (str): Date as string preferrably as ISO8601 format (YYYY-MM-dd) region (tuple[float] | list[float]): Bounding box of region to search as iterable in W,S,E,N order credentials (tuple | list): EarthData username and password login credentials as iterable out_directory (str|pathlib.Path): Local directory to downaload data to max_results (int, optional): Maximum number of items to search and download. default = 500 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd). default = start_time + 1day returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" if type ( start_time ) != datetime . datetime : start_time = scmr . utils . decode_date ( start_time ) if end_time is None : end_time = start_time + datetime . timedelta ( seconds = 86399 ) else : end_time = scmr . utils . decode_date ( end_time ) # construct query query = scmr . Query ( conceptid = conceptid , startTime = start_time , endTime = end_time , spatialExtent = region , maxResults = max_results , ) # fetch datasets from query query . granules . fetch ( credentials = credentials , directory = out_directory , limit = max_results , maxWorkers = 4 , ) # return a list of the granules for later processing return query . granules . getLocalPaths ( directory = out_directory ) modis ( credentials , start_time = '2000-01-01' , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = './' ) Function to download MODIS surface reflectance data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple[float] | list[float] Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def modis ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\"Function to download MODIS surface reflectance data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple[float] | list[float], optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optional): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" # check if date requested is within science-quality production time now = datetime . datetime . now () offset = now - scmr . utils . decode_date ( start_time ) if offset . days > 4 : # use science-quality collection CONCEPTID = \"C193529902-LPDAAC_ECS\" else : # use LANCE-NRT collection CONCEPTID = \"C1219249711-LANCEMODIS\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , ) viirs ( credentials , start_time = '2000-01-01' , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = './' ) Function to download Suomi-NPP VIIRS surface reflectance data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple | list Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path, optioanl Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def viirs ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\"Function to download Suomi-NPP VIIRS surface reflectance data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple | list, optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optioanl): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" # check if date requested is within science-quality production time now = datetime . datetime . now () offset = now - scmr . utils . decode_date ( start_time ) if offset . days > 4 : # use science-quality collection CONCEPTID = \"C1373412034-LPDAAC_ECS\" else : # use LANCE-NRT collection CONCEPTID = \"C1344293643-LANCEMODIS\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , )","title":"fetch module"},{"location":"fetch/#hydrafloods.fetch","text":"","title":"fetch"},{"location":"fetch/#hydrafloods.fetch.atms","text":"Function to download Suomi-NPP ATMS passive microwave data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple | list Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path, optioanl Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def atms ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\" Function to download Suomi-NPP ATMS passive microwave data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple | list, optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optioanl): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" CONCEPTID = \"C1442068516-GES_DISC\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , )","title":"atms()"},{"location":"fetch/#hydrafloods.fetch.fetching","text":"Function to download data from NASA CMR by specifying a dataset, time and region. Uses CMR to handle spatio-temporal query and extracts data download urls Parameters: Name Type Description Default conceptid str String of dataset concept id to search for required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) required region tuple[float] | list[float] Bounding box of region to search as iterable in W,S,E,N order required credentials tuple | list EarthData username and password login credentials as iterable required out_directory str|pathlib.Path Local directory to downaload data to required max_results int Maximum number of items to search and download. default = 500 500 end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd). default = start_time + 1day None Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def fetching ( conceptid , start_time , region , credentials , out_directory , max_results = 500 , end_time = None , ): \"\"\" Function to download data from NASA CMR by specifying a dataset, time and region. Uses CMR to handle spatio-temporal query and extracts data download urls args: conceptid (str): String of dataset concept id to search for start_time (str): Date as string preferrably as ISO8601 format (YYYY-MM-dd) region (tuple[float] | list[float]): Bounding box of region to search as iterable in W,S,E,N order credentials (tuple | list): EarthData username and password login credentials as iterable out_directory (str|pathlib.Path): Local directory to downaload data to max_results (int, optional): Maximum number of items to search and download. default = 500 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd). default = start_time + 1day returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" if type ( start_time ) != datetime . datetime : start_time = scmr . utils . decode_date ( start_time ) if end_time is None : end_time = start_time + datetime . timedelta ( seconds = 86399 ) else : end_time = scmr . utils . decode_date ( end_time ) # construct query query = scmr . Query ( conceptid = conceptid , startTime = start_time , endTime = end_time , spatialExtent = region , maxResults = max_results , ) # fetch datasets from query query . granules . fetch ( credentials = credentials , directory = out_directory , limit = max_results , maxWorkers = 4 , ) # return a list of the granules for later processing return query . granules . getLocalPaths ( directory = out_directory )","title":"fetching()"},{"location":"fetch/#hydrafloods.fetch.modis","text":"Function to download MODIS surface reflectance data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple[float] | list[float] Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def modis ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\"Function to download MODIS surface reflectance data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple[float] | list[float], optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optional): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" # check if date requested is within science-quality production time now = datetime . datetime . now () offset = now - scmr . utils . decode_date ( start_time ) if offset . days > 4 : # use science-quality collection CONCEPTID = \"C193529902-LPDAAC_ECS\" else : # use LANCE-NRT collection CONCEPTID = \"C1219249711-LANCEMODIS\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , )","title":"modis()"},{"location":"fetch/#hydrafloods.fetch.viirs","text":"Function to download Suomi-NPP VIIRS surface reflectance data for specified time and region, wraps fetching() Parameters: Name Type Description Default credentials tuple | list EarthData username and password login credentials as iterable required start_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 '2000-01-01' end_time str Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day None region tuple | list Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] [-180, 60, 180, 85] out_directory str | pathlib.Path, optioanl Local directory to downaload data to default = \"./\" './' Returns: Type Description list[pathlib.Path] List of local paths that data was downloaded to Source code in hydrafloods/fetch.py def viirs ( credentials , start_time = \"2000-01-01\" , end_time = None , region = [ - 180 , 60 , 180 , 85 ], out_directory = \"./\" , ): \"\"\"Function to download Suomi-NPP VIIRS surface reflectance data for specified time and region, wraps `fetching()` args: credentials (tuple | list): EarthData username and password login credentials as iterable start_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = 2000-01-01 end_time (str, optional): Date as string preferrably as ISO8601 format (YYYY-MM-dd) default = start_time + 1day region (tuple | list, optional): Bounding box of region to search as iterable in W,S,E,N order default = [-180,60,180,85] out_directory (str | pathlib.Path, optioanl): Local directory to downaload data to default = \"./\" returns: list[pathlib.Path]: List of local paths that data was downloaded to \"\"\" # check if date requested is within science-quality production time now = datetime . datetime . now () offset = now - scmr . utils . decode_date ( start_time ) if offset . days > 4 : # use science-quality collection CONCEPTID = \"C1373412034-LPDAAC_ECS\" else : # use LANCE-NRT collection CONCEPTID = \"C1344293643-LANCEMODIS\" return fetching ( conceptid = CONCEPTID , start_time = start_time , region = region , credentials = credentials , out_directory = out_directory , max_results = 500 , end_time = end_time , )","title":"viirs()"},{"location":"filtering/","text":"hydrafloods.filtering close_binary ( img , window = 3 , neighborhood = None ) Closing morphological filter. Closing is the erosion of the dialiation of values greater than 1. Parameters: Name Type Description Default img ee.Image binary image to apply closing filter on required window int | ee.Number distance in pixels to consider for closing process 3 neighborhood int | ee.Number size of the neighborhood to perform fast distance trasnform. Smaller values speed up operations however must be greater than window. If no neighborhood is provided, it will be double the window size. default = None None Returns: Type Description ee.Image the closed binary image Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def close_binary ( img , window = 3 , neighborhood = None ): \"\"\"Closing morphological filter. Closing is the erosion of the dialiation of values greater than 1. args: img (ee.Image): binary image to apply closing filter on window (int | ee.Number, optional): distance in pixels to consider for closing process neighborhood (int | ee.Number, optional): size of the neighborhood to perform fast distance trasnform. Smaller values speed up operations however must be greater than window. If no neighborhood is provided, it will be double the window size. default = None returns: ee.Image: the closed binary image \"\"\" if not isinstance ( window , ee . Number ): window = ee . Number ( window ) if neighborhood is None : neighborhood = window . multiply ( 2 ) dialation = img . fastDistanceTransform ( neighborhood ) . sqrt () . lt ( window ) closed = dialation . Not () . fastDistanceTransform ( neighborhood ) . sqrt () . gt ( window ) return closed . updateMask ( img . mask ()) gamma_map ( img , window = 7 , enl = 4.9 , keep_bands = [ 'angle' ]) Gamma Map speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/a9W0Nlrhoq0/m/tnGMC45jAgAJ. Parameters: Name Type Description Default img ee.Image Earth engine image object. Expects that imagery is a SAR image required window int moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 7 7 enl float equivalent number of looks (enl) per pixel from a SAR scan. See https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/resolutions/level-1-ground-range-detected. default = 4.9 4.9 keep_bands list[str] list of band names to drop during filtering and include in the result default = [\"angle\"] ['angle'] Returns: Type Description ee.Image filtered SAR image using the Gamma Map algorithm Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def gamma_map ( img , window = 7 , enl = 4.9 , keep_bands = [ \"angle\" ]): \"\"\"Gamma Map speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/a9W0Nlrhoq0/m/tnGMC45jAgAJ. args: img (ee.Image): Earth engine image object. Expects that imagery is a SAR image window (int, optional): moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 7 enl (float, optional): equivalent number of looks (enl) per pixel from a SAR scan. See https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/resolutions/level-1-ground-range-detected. default = 4.9 keep_bands (list[str], optional): list of band names to drop during filtering and include in the result default = [\"angle\"] returns: ee.Image: filtered SAR image using the Gamma Map algorithm \"\"\" band_names = img . bandNames () if keep_bands is not None : keep_img = img . select ( keep_bands ) proc_bands = band_names . removeAll ( keep_bands ) else : proc_bands = band_names img = img . select ( proc_bands ) # Square kernel, window should be odd (typically 3, 5 or 7) weights = ee . List . repeat ( ee . List . repeat ( 1 , window ), window ) midPt = ( window // 2 ) + 1 if ( window % 2 ) != 0 else window // 2 # ~~(window/2) does integer division in JavaScript kernel = ee . Kernel . fixed ( window , window , weights , midPt , midPt , False ) # Convert image from dB to natural values nat_img = geeutils . db_to_power ( img ) # Get mean and variance mean = nat_img . reduceNeighborhood ( ee . Reducer . mean (), kernel ) variance = nat_img . reduceNeighborhood ( ee . Reducer . variance (), kernel ) # \"Pure speckle\" threshold ci = variance . sqrt () . divide ( mean ) # square root of inverse of enl # If ci <= cu, the kernel lies in a \"pure speckle\" area -> return simple mean cu = 1.0 / math . sqrt ( enl ) # If cu < ci < cmax the kernel lies in the low textured speckle area -> return the filtered value cmax = math . sqrt ( 2.0 ) * cu alpha = ee . Image ( 1.0 + cu * cu ) . divide ( ci . multiply ( ci ) . subtract ( cu * cu )) b = alpha . subtract ( enl + 1.0 ) d = ( mean . multiply ( mean ) . multiply ( b ) . multiply ( b ) . add ( alpha . multiply ( mean ) . multiply ( nat_img ) . multiply ( 4.0 * enl )) ) f = b . multiply ( mean ) . add ( d . sqrt ()) . divide ( alpha . multiply ( 2.0 )) caster = ee . Dictionary . fromLists ( proc_bands , ee . List . repeat ( \"float\" , proc_bands . length ()) ) img1 = ( geeutils . power_to_db ( mean . updateMask ( ci . lte ( cu ))) . rename ( proc_bands ) . cast ( caster ) ) img2 = ( geeutils . power_to_db ( f . updateMask ( ci . gt ( cu )) . updateMask ( ci . lt ( cmax ))) . rename ( proc_bands ) . cast ( caster ) ) img3 = img . updateMask ( ci . gte ( cmax )) . rename ( proc_bands ) . cast ( caster ) # If ci > cmax do not filter at all (i.e. we don't do anything, other then masking) output = ( ee . ImageCollection ([ img1 , img2 , img3 ]) . reduce ( ee . Reducer . firstNonNull ()) . rename ( proc_bands ) . clip ( img . geometry ()) ) if keep_bands is not None : output = output . addBands ( keep_img ) # Compose a 3 band image with the mean filtered \"pure speckle\", the \"low textured\" filtered and the unfiltered portions return output lee_sigma ( img , window = 9 , sigma = 0.9 , looks = 4 , tk = 7 , keep_bands = [ 'angle' ]) Lee Sigma speckle filtering algorithm. Implemented from interpreting https://doi.org/10.1109/TGRS.2008.2002881 Parameters: Name Type Description Default img ee.Image Earth engine image object. Expects that imagery is a SAR image required window int moving window size to apply filter (i.e. a value of 9 == 9x9 window). default = 9 9 sigma float sigma lookup value from table 1 in paper. default = 0.9 0.9 looks int look intensity value from table 1 in paper. default = 4 4 tk int threshold value to determine values in window as point targets. default = 7 7 keep_bands list[str] list of band names to drop during filtering and include in the result default = [\"angle\"] ['angle'] Returns: Type Description ee.Image filtered SAR image using the Lee Sigma algorithm Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def lee_sigma ( img , window = 9 , sigma = 0.9 , looks = 4 , tk = 7 , keep_bands = [ \"angle\" ]): \"\"\"Lee Sigma speckle filtering algorithm. Implemented from interpreting https://doi.org/10.1109/TGRS.2008.2002881 args: img (ee.Image): Earth engine image object. Expects that imagery is a SAR image window (int, optional): moving window size to apply filter (i.e. a value of 9 == 9x9 window). default = 9 sigma (float, optional): sigma lookup value from table 1 in paper. default = 0.9 looks (int, optional): look intensity value from table 1 in paper. default = 4 tk (int, optional): threshold value to determine values in window as point targets. default = 7 keep_bands (list[str], optional): list of band names to drop during filtering and include in the result default = [\"angle\"] returns: ee.Image: filtered SAR image using the Lee Sigma algorithm \"\"\" band_names = img . bandNames () if keep_bands is not None : keep_img = img . select ( keep_bands ) proc_bands = band_names . removeAll ( keep_bands ) else : proc_bands = band_names img = img . select ( proc_bands ) midPt = ( window // 2 ) + 1 if ( window % 2 ) != 0 else window // 2 kernelWeights = ee . List . repeat ( ee . List . repeat ( 1 , window ), window ) kernel = ee . Kernel . fixed ( window , window , kernelWeights , midPt , midPt ) targetWeights = ee . List . repeat ( ee . List . repeat ( 1 , 3 ), 3 ) targetkernel = ee . Kernel . fixed ( 3 , 3 , targetWeights , 1 , 1 ) # Lookup table for range and eta values for intensity sigmaLookup = ee . Dictionary ( { 1 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.436 , \"A2\" : 1.92 , \"\u03b7\" : 0.4057 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.343 , \"A2\" : 2.21 , \"\u03b7\" : 0.4954 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.254 , \"A2\" : 2.582 , \"\u03b7\" : 0.5911 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.168 , \"A2\" : 3.094 , \"\u03b7\" : 0.6966 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.084 , \"A2\" : 3.941 , \"\u03b7\" : 0.8191 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.043 , \"A2\" : 4.840 , \"\u03b7\" : 0.8599 }), } ), 2 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.582 , \"A2\" : 1.584 , \"\u03b7\" : 0.2763 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.501 , \"A2\" : 1.755 , \"\u03b7\" : 0.3388 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.418 , \"A2\" : 1.972 , \"\u03b7\" : 0.4062 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.327 , \"A2\" : 2.260 , \"\u03b7\" : 0.4819 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.221 , \"A2\" : 2.744 , \"\u03b7\" : 0.5699 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.152 , \"A2\" : 3.206 , \"\u03b7\" : 0.6254 }), } ), 3 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.652 , \"A2\" : 1.458 , \"\u03b7\" : 0.2222 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.580 , \"A2\" : 1.586 , \"\u03b7\" : 0.2736 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.505 , \"A2\" : 1.751 , \"\u03b7\" : 0.3280 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.419 , \"A2\" : 1.865 , \"\u03b7\" : 0.3892 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.313 , \"A2\" : 2.320 , \"\u03b7\" : 0.4624 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.238 , \"A2\" : 2.656 , \"\u03b7\" : 0.5084 }), } ), 4 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.694 , \"A2\" : 1.385 , \"\u03b7\" : 0.1921 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.630 , \"A2\" : 1.495 , \"\u03b7\" : 0.2348 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.560 , \"A2\" : 1.627 , \"\u03b7\" : 0.2825 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.480 , \"A2\" : 1.804 , \"\u03b7\" : 0.3354 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.378 , \"A2\" : 2.094 , \"\u03b7\" : 0.3991 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.302 , \"A2\" : 2.360 , \"\u03b7\" : 0.4391 }), } ), } ) # extract data from lookup looksDict = ee . Dictionary ( sigmaLookup . get ( ee . String ( str ( looks )))) sigmaImage = ee . Dictionary ( looksDict . get ( ee . String ( str ( sigma )))) . toImage () a1 = sigmaImage . select ( \"A1\" ) a2 = sigmaImage . select ( \"A2\" ) aRange = a2 . subtract ( a1 ) eta = sigmaImage . select ( \"\u03b7\" ) . pow ( 2 ) img = geeutils . db_to_power ( img ) # MMSE estimator mmseMask = img . gte ( a1 ) . Or ( img . lte ( a2 )) mmseIn = img . updateMask ( mmseMask ) oneImg = ee . Image ( 1 ) z = mmseIn . reduceNeighborhood ( ee . Reducer . mean (), kernel , None , True ) varz = mmseIn . reduceNeighborhood ( ee . Reducer . variance (), kernel ) varx = ( varz . subtract ( z . abs () . pow ( 2 ) . multiply ( eta ))) . divide ( oneImg . add ( eta )) b = varx . divide ( varz ) mmse = oneImg . subtract ( b ) . multiply ( z . abs ()) . add ( b . multiply ( mmseIn )) # workflow z99 = ee . Dictionary ( img . reduceRegion ( reducer = ee . Reducer . percentile ([ 99 ], None , 255 , 0.001 , 1e6 ), geometry = img . geometry (), scale = 10 , bestEffort = True , ) ) . toImage () overThresh = img . gte ( z99 ) K = overThresh . reduceNeighborhood ( ee . Reducer . sum (), targetkernel , None , True ) retainPixel = K . gte ( tk ) xHat = geeutils . power_to_db ( img . updateMask ( retainPixel ) . unmask ( mmse )) output = ee . Image ( xHat ) . rename ( proc_bands ) if keep_bands is not None : output = output . addBands ( keep_img ) return output modified_median_zscore ( img , fill_img = None ) Outlier detection and filling on complete DEM using the modified z-score and a median filter Method from Iglewicz, B. and Hoaglin, D.C., 1993. How to detect and handle outliers (Vol. 16). Asq Press. Parameters: Name Type Description Default img ee.Image Earth engine image object to apply filter on required fill_img ee.Image Earth engine image object to fill values resulting from filter. If None provided, the fill operation will be on the input image. Default = None None Returns: Type Description ee.Image filtered image Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def modified_median_zscore ( img , fill_img = None ): \"\"\"Outlier detection and filling on complete DEM using the modified z-score and a median filter Method from Iglewicz, B. and Hoaglin, D.C., 1993. How to detect and handle outliers (Vol. 16). Asq Press. args: img (ee.Image): Earth engine image object to apply filter on fill_img (ee.Image): Earth engine image object to fill values resulting from filter. If None provided, the fill operation will be on the input image. Default = None returns: ee.Image: filtered image \"\"\" kernel = ee . Kernel . fixed ( 3 , 3 , [[ 1 , 1 , 1 ], [ 1 , 1 , 1 ], [ 1 , 1 , 1 ]]) kernel_weighted = ee . Kernel . fixed ( 3 , 3 , [[ 1 , 1 , 1 ], [ 1 , 0 , 1 ], [ 1 , 1 , 1 ]]) median = img . focal_median ( kernel = kernel ) median_weighted = img . focal_median ( kernel = kernel_weighted ) diff = img . subtract ( median ) mzscore = diff . multiply ( 0.6745 ) . divide ( diff . abs () . focal_median ( kernel = kernel )) if fill_img : filled = fill_img . where ( mzscore . gt ( 3.5 ), median_weighted ) else : filled = img . where ( mzscore . gt ( 3.5 ), median_weighted ) return filled open_binary ( img , window = 3 , neighborhood = None ) Opening morphological filter. Opening is the dilation of the erosion of values greater than 1. Parameters: Name Type Description Default img ee.Image binary image to apply opening filter on required window int | ee.Number distance in pixels to consider for opening process 3 neighborhood int | ee.Number size of the neighborhood to perform fast distance trasnform. Smaller values speed up operations however must be greater than window. If no nerighborhood is provided, it will be double the window size. default = None None Returns: Type Description ee.Image the opened binary image Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def open_binary ( img , window = 3 , neighborhood = None ): \"\"\"Opening morphological filter. Opening is the dilation of the erosion of values greater than 1. args: img (ee.Image): binary image to apply opening filter on window (int | ee.Number, optional): distance in pixels to consider for opening process neighborhood (int | ee.Number, optional): size of the neighborhood to perform fast distance trasnform. Smaller values speed up operations however must be greater than window. If no nerighborhood is provided, it will be double the window size. default = None returns: ee.Image: the opened binary image \"\"\" if not isinstance ( window , ee . Number ): window = ee . Number ( window ) if neighborhood is None : neighborhood = window . multiply ( 2 ) erosion = img . Not () . fastDistanceTransform ( neighborhood ) . sqrt () . gt ( window ) opened = erosion . fastDistanceTransform ( neighborhood ) . sqrt () . lt ( window ) return opened . updateMask ( img . mask ()) p_median ( img , window = 5 , keep_bands = [ 'angle' ]) P-Median filter for smoothing imagery. Calculates the average from the median along cross and diagnal pixels of a window Parameters: Name Type Description Default img ee.Image Earth engine image object to filter required window int moving window size to apply filter (i.e. a value of 5 == 5x5 window). default = 5 5 Returns: Type Description ee.Image filtered image Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def p_median ( img , window = 5 , keep_bands = [ \"angle\" ]): \"\"\"P-Median filter for smoothing imagery. Calculates the average from the median along cross and diagnal pixels of a window args: img (ee.Image): Earth engine image object to filter window (int, optional): moving window size to apply filter (i.e. a value of 5 == 5x5 window). default = 5 returns: ee.Image: filtered image \"\"\" def _band_filter ( bname ): selector = ee . List ([ bname ]) band_img = img . select ( selector ) hv_median = band_img . reduceNeighborhood ( ee . Reducer . median (), hv_kernel ) diag_median = band_img . reduceNeighborhood ( ee . Reducer . median (), diag_kernel ) return ee . Image ( ee . Image . cat ([ hv_median , diag_median ]) . reduce ( \"mean\" )) . rename ( selector ) if window % 2 == 0 : window += 1 center_idx = ( window - 1 ) // 2 hv = [ [ 1 if i == center_idx or j == center_idx else 0 for j in range ( window )] for i in range ( window ) ] diag = [ [ 1 if i == j or i == (( window - 1 ) - j ) else 0 for j in range ( window )] for i in range ( window ) ] # method based on ??? band_names = img . bandNames () hv_weights = ee . List ( hv ) diag_weights = ee . List ( diag ) hv_kernel = ee . Kernel . fixed ( window , window , hv_weights ) diag_kernel = ee . Kernel . fixed ( window , window , diag_weights ) reduced_bands = ee . ImageCollection . fromImages ( band_names . map ( _band_filter ) ) . toBands () return reduced_bands . rename ( band_names ) perona_malik ( img , n_iters = 10 , K = 3 , method = 1 ) Perona-Malik (anisotropic diffusion) convolution Developed by Gennadii Donchyts see https://groups.google.com/g/google-earth-engine-developers/c/umGlt5qIN1I/m/PD8lsJ7qBAAJ I(n+1, i, j) = I(n, i, j) + lambda * (cN * dN(I) + cS * dS(I) + cE * dE(I), cW * dW(I)) Parameters: Name Type Description Default img ee.Image Earth engine image object. Expects that imagery is a SAR image required n_iters int Number of interations to apply filter K (int,optional): moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 3 10 method int choose method 1 (default) or 2 1 Returns: Type Description ee.Image filtered SAR image using the perona malik algorithm Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def perona_malik ( img , n_iters = 10 , K = 3 , method = 1 ): \"\"\"Perona-Malik (anisotropic diffusion) convolution Developed by Gennadii Donchyts see https://groups.google.com/g/google-earth-engine-developers/c/umGlt5qIN1I/m/PD8lsJ7qBAAJ I(n+1, i, j) = I(n, i, j) + lambda * (cN * dN(I) + cS * dS(I) + cE * dE(I), cW * dW(I)) args: img (ee.Image): Earth engine image object. Expects that imagery is a SAR image n_iters (int, optional): Number of interations to apply filter K (int,optional): moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 3 method (int, optional): choose method 1 (default) or 2 returns: ee.Image: filtered SAR image using the perona malik algorithm \"\"\" def _method_1 ( dI_W , dI_E , dI_N , dI_S ): cW = dI_W . pow ( 2 ) . multiply ( k1 ) . exp () cE = dI_E . pow ( 2 ) . multiply ( k1 ) . exp () cN = dI_N . pow ( 2 ) . multiply ( k1 ) . exp () cS = dI_S . pow ( 2 ) . multiply ( k1 ) . exp () return cW , cE , cN , cS def _method_2 ( dI_W , dI_E , dI_N , dI_S ): cW = one . divide ( one . add ( dI_W . pow ( 2 ) . divide ( k2 ))) cE = one . divide ( one . add ( dI_E . pow ( 2 ) . divide ( k2 ))) cN = one . divide ( one . add ( dI_N . pow ( 2 ) . divide ( k2 ))) cS = one . divide ( one . add ( dI_S . pow ( 2 ) . divide ( k2 ))) return cW , cE , cN , cS # covnert db to natural units before applying filter power = geeutils . db_to_power ( img ) dxW = ee . Kernel . fixed ( 3 , 3 , [[ 0 , 0 , 0 ], [ 1 , - 1 , 0 ], [ 0 , 0 , 0 ]]) dxE = ee . Kernel . fixed ( 3 , 3 , [[ 0 , 0 , 0 ], [ 0 , - 1 , 1 ], [ 0 , 0 , 0 ]]) dyN = ee . Kernel . fixed ( 3 , 3 , [[ 0 , 1 , 0 ], [ 0 , - 1 , 0 ], [ 0 , 0 , 0 ]]) dyS = ee . Kernel . fixed ( 3 , 3 , [[ 0 , 0 , 0 ], [ 0 , - 1 , 0 ], [ 0 , 1 , 0 ]]) one = ee . Image . constant ( 1.0 ) l = ee . Image . constant ( 0.2 ) k = ee . Image . constant ( K ) k1 = ee . Image . constant ( - 1.0 / K ) k2 = k . pow ( 2 ) if method == 1 : _method = _method_1 elif method == 2 : _method = _method_2 else : raise NotImplementedError ( \"Could not determine algorithm to apply filter...options for `method` are 1 or 2\" ) for i in range ( n_iters ): dI_W = power . convolve ( dxW ) dI_E = power . convolve ( dxE ) dI_N = power . convolve ( dyN ) dI_S = power . convolve ( dyS ) cW , cE , cN , cS = _method ( dI_W , dI_E , dI_N , dI_S ) power = power . add ( l . multiply ( cN . multiply ( dI_N ) . add ( cS . multiply ( dI_S )) . add ( cE . multiply ( dI_E )) . add ( cW . multiply ( dI_W )) ) ) # covnert natural to db units after filter is done img = geeutils . power_to_db ( power ) return img refined_lee ( image , keep_bands = [ 'angle' ]) Refined Lee speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/ExepnAmP-hQ/m/7e5DnjXXAQAJ Parameters: Name Type Description Default image ee.Image Earth engine image object. Expects that imagery is a SAR image required Returns: Type Description ee.Image filtered SAR image using the Refined Lee algorithm Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def refined_lee ( image , keep_bands = [ \"angle\" ]): \"\"\"Refined Lee speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/ExepnAmP-hQ/m/7e5DnjXXAQAJ args: image (ee.Image): Earth engine image object. Expects that imagery is a SAR image returns: ee.Image: filtered SAR image using the Refined Lee algorithm \"\"\" # TODO: include keep bands...maybe one-shot filtering if using keep_bands??? def apply_filter ( b ): \"\"\"Closure function to apply the refined lee algorithm on individual bands\"\"\" b = ee . String ( b ) img = power . select ( b ) # img must be in natural units, i.e. not in dB! # Set up 3x3 kernels weights3 = ee . List . repeat ( ee . List . repeat ( 1 , 3 ), 3 ) kernel3 = ee . Kernel . fixed ( 3 , 3 , weights3 , 1 , 1 , False ) mean3 = img . reduceNeighborhood ( ee . Reducer . mean (), kernel3 ) variance3 = img . reduceNeighborhood ( ee . Reducer . variance (), kernel3 ) # Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions sample_weights = ee . List ( [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], ] ) sample_kernel = ee . Kernel . fixed ( 7 , 7 , sample_weights , 3 , 3 , False ) # Calculate mean and variance for the sampled windows and store as 9 bands sample_mean = mean3 . neighborhoodToBands ( sample_kernel ) sample_var = variance3 . neighborhoodToBands ( sample_kernel ) # Determine the 4 gradients for the sampled windows gradients = sample_mean . select ( 1 ) . subtract ( sample_mean . select ( 7 )) . abs () gradients = gradients . addBands ( sample_mean . select ( 6 ) . subtract ( sample_mean . select ( 2 )) . abs () ) gradients = gradients . addBands ( sample_mean . select ( 3 ) . subtract ( sample_mean . select ( 5 )) . abs () ) gradients = gradients . addBands ( sample_mean . select ( 0 ) . subtract ( sample_mean . select ( 8 )) . abs () ) # And find the maximum gradient amongst gradient bands max_gradient = gradients . reduce ( ee . Reducer . max ()) # Create a mask for band pixels that are the maximum gradient gradmask = gradients . eq ( max_gradient ) # duplicate gradmask bands: each gradient represents 2 directions gradmask = gradmask . addBands ( gradmask ) # Determine the 8 directions directions = ( sample_mean . select ( 1 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 7 ))) . multiply ( 1 ) ) directions = directions . addBands ( sample_mean . select ( 6 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 2 ))) . multiply ( 2 ) ) directions = directions . addBands ( sample_mean . select ( 3 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 5 ))) . multiply ( 3 ) ) directions = directions . addBands ( sample_mean . select ( 0 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 8 ))) . multiply ( 4 ) ) # The next 4 are the not() of the previous 4 directions = directions . addBands ( directions . select ( 0 ) . Not () . multiply ( 5 )) directions = directions . addBands ( directions . select ( 1 ) . Not () . multiply ( 6 )) directions = directions . addBands ( directions . select ( 2 ) . Not () . multiply ( 7 )) directions = directions . addBands ( directions . select ( 3 ) . Not () . multiply ( 8 )) # Mask all values that are not 1-8 directions = directions . updateMask ( gradmask ) # \"collapse\" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked) directions = directions . reduce ( ee . Reducer . sum ()) sample_stats = sample_var . divide ( sample_mean . multiply ( sample_mean )) # Calculate localNoiseVariance sigmaV = ( sample_stats . toArray () . arraySort () . arraySlice ( 0 , 0 , 5 ) . arrayReduce ( ee . Reducer . mean (), [ 0 ]) ) # Set up the 7*7 kernels for directional statistics rect_weights = ee . List . repeat ( ee . List . repeat ( 0 , 7 ), 3 ) . cat ( ee . List . repeat ( ee . List . repeat ( 1 , 7 ), 4 ) ) diag_weights = ee . List ( [ [ 1 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 0 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 1 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 1 , 1 ], ] ) rect_kernel = ee . Kernel . fixed ( 7 , 7 , rect_weights , 3 , 3 , False ) diag_kernel = ee . Kernel . fixed ( 7 , 7 , diag_weights , 3 , 3 , False ) # Create stacks for mean and variance using the original kernels. Mask with relevant direction. dir_mean = img . reduceNeighborhood ( ee . Reducer . mean (), rect_kernel ) . updateMask ( directions . eq ( 1 ) ) dir_var = img . reduceNeighborhood ( ee . Reducer . variance (), rect_kernel ) . updateMask ( directions . eq ( 1 ) ) dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), diag_kernel ) . updateMask ( directions . eq ( 2 ) ) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), diag_kernel ) . updateMask ( directions . eq ( 2 ) ) ) # and add the bands for rotated kernels for i in range ( 1 , 4 ): dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), rect_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 1 )) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), rect_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 1 )) ) dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), diag_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 2 )) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), diag_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 2 )) ) # \"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked) dir_mean = dir_mean . reduce ( ee . Reducer . sum ()) dir_var = dir_var . reduce ( ee . Reducer . sum ()) # A finally generate the filtered value varX = dir_var . subtract ( dir_mean . multiply ( dir_mean ) . multiply ( sigmaV )) . divide ( sigmaV . add ( 1.0 ) ) b = varX . divide ( dir_var ) # return multi-band image band from array return ( dir_mean . add ( b . multiply ( img . subtract ( dir_mean ))) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"sum\" ]]) . float () ) band_names = image . bandNames () if keep_bands is not None : keep_img = image . select ( keep_bands ) proc_bands = band_names . removeAll ( keep_bands ) else : proc_bands = band_names image = image . select ( proc_bands ) power = geeutils . db_to_power ( image ) result = ee . ImageCollection ( proc_bands . map ( apply_filter )) . toBands () output = geeutils . power_to_db ( ee . Image ( result )) . rename ( proc_bands ) if keep_bands is not None : output = output . addBands ( keep_img ) return output","title":"filtering module"},{"location":"filtering/#hydrafloods.filtering","text":"","title":"filtering"},{"location":"filtering/#hydrafloods.filtering.close_binary","text":"Closing morphological filter. Closing is the erosion of the dialiation of values greater than 1. Parameters: Name Type Description Default img ee.Image binary image to apply closing filter on required window int | ee.Number distance in pixels to consider for closing process 3 neighborhood int | ee.Number size of the neighborhood to perform fast distance trasnform. Smaller values speed up operations however must be greater than window. If no neighborhood is provided, it will be double the window size. default = None None Returns: Type Description ee.Image the closed binary image Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def close_binary ( img , window = 3 , neighborhood = None ): \"\"\"Closing morphological filter. Closing is the erosion of the dialiation of values greater than 1. args: img (ee.Image): binary image to apply closing filter on window (int | ee.Number, optional): distance in pixels to consider for closing process neighborhood (int | ee.Number, optional): size of the neighborhood to perform fast distance trasnform. Smaller values speed up operations however must be greater than window. If no neighborhood is provided, it will be double the window size. default = None returns: ee.Image: the closed binary image \"\"\" if not isinstance ( window , ee . Number ): window = ee . Number ( window ) if neighborhood is None : neighborhood = window . multiply ( 2 ) dialation = img . fastDistanceTransform ( neighborhood ) . sqrt () . lt ( window ) closed = dialation . Not () . fastDistanceTransform ( neighborhood ) . sqrt () . gt ( window ) return closed . updateMask ( img . mask ())","title":"close_binary()"},{"location":"filtering/#hydrafloods.filtering.gamma_map","text":"Gamma Map speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/a9W0Nlrhoq0/m/tnGMC45jAgAJ. Parameters: Name Type Description Default img ee.Image Earth engine image object. Expects that imagery is a SAR image required window int moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 7 7 enl float equivalent number of looks (enl) per pixel from a SAR scan. See https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/resolutions/level-1-ground-range-detected. default = 4.9 4.9 keep_bands list[str] list of band names to drop during filtering and include in the result default = [\"angle\"] ['angle'] Returns: Type Description ee.Image filtered SAR image using the Gamma Map algorithm Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def gamma_map ( img , window = 7 , enl = 4.9 , keep_bands = [ \"angle\" ]): \"\"\"Gamma Map speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/a9W0Nlrhoq0/m/tnGMC45jAgAJ. args: img (ee.Image): Earth engine image object. Expects that imagery is a SAR image window (int, optional): moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 7 enl (float, optional): equivalent number of looks (enl) per pixel from a SAR scan. See https://sentinel.esa.int/web/sentinel/user-guides/sentinel-1-sar/resolutions/level-1-ground-range-detected. default = 4.9 keep_bands (list[str], optional): list of band names to drop during filtering and include in the result default = [\"angle\"] returns: ee.Image: filtered SAR image using the Gamma Map algorithm \"\"\" band_names = img . bandNames () if keep_bands is not None : keep_img = img . select ( keep_bands ) proc_bands = band_names . removeAll ( keep_bands ) else : proc_bands = band_names img = img . select ( proc_bands ) # Square kernel, window should be odd (typically 3, 5 or 7) weights = ee . List . repeat ( ee . List . repeat ( 1 , window ), window ) midPt = ( window // 2 ) + 1 if ( window % 2 ) != 0 else window // 2 # ~~(window/2) does integer division in JavaScript kernel = ee . Kernel . fixed ( window , window , weights , midPt , midPt , False ) # Convert image from dB to natural values nat_img = geeutils . db_to_power ( img ) # Get mean and variance mean = nat_img . reduceNeighborhood ( ee . Reducer . mean (), kernel ) variance = nat_img . reduceNeighborhood ( ee . Reducer . variance (), kernel ) # \"Pure speckle\" threshold ci = variance . sqrt () . divide ( mean ) # square root of inverse of enl # If ci <= cu, the kernel lies in a \"pure speckle\" area -> return simple mean cu = 1.0 / math . sqrt ( enl ) # If cu < ci < cmax the kernel lies in the low textured speckle area -> return the filtered value cmax = math . sqrt ( 2.0 ) * cu alpha = ee . Image ( 1.0 + cu * cu ) . divide ( ci . multiply ( ci ) . subtract ( cu * cu )) b = alpha . subtract ( enl + 1.0 ) d = ( mean . multiply ( mean ) . multiply ( b ) . multiply ( b ) . add ( alpha . multiply ( mean ) . multiply ( nat_img ) . multiply ( 4.0 * enl )) ) f = b . multiply ( mean ) . add ( d . sqrt ()) . divide ( alpha . multiply ( 2.0 )) caster = ee . Dictionary . fromLists ( proc_bands , ee . List . repeat ( \"float\" , proc_bands . length ()) ) img1 = ( geeutils . power_to_db ( mean . updateMask ( ci . lte ( cu ))) . rename ( proc_bands ) . cast ( caster ) ) img2 = ( geeutils . power_to_db ( f . updateMask ( ci . gt ( cu )) . updateMask ( ci . lt ( cmax ))) . rename ( proc_bands ) . cast ( caster ) ) img3 = img . updateMask ( ci . gte ( cmax )) . rename ( proc_bands ) . cast ( caster ) # If ci > cmax do not filter at all (i.e. we don't do anything, other then masking) output = ( ee . ImageCollection ([ img1 , img2 , img3 ]) . reduce ( ee . Reducer . firstNonNull ()) . rename ( proc_bands ) . clip ( img . geometry ()) ) if keep_bands is not None : output = output . addBands ( keep_img ) # Compose a 3 band image with the mean filtered \"pure speckle\", the \"low textured\" filtered and the unfiltered portions return output","title":"gamma_map()"},{"location":"filtering/#hydrafloods.filtering.lee_sigma","text":"Lee Sigma speckle filtering algorithm. Implemented from interpreting https://doi.org/10.1109/TGRS.2008.2002881 Parameters: Name Type Description Default img ee.Image Earth engine image object. Expects that imagery is a SAR image required window int moving window size to apply filter (i.e. a value of 9 == 9x9 window). default = 9 9 sigma float sigma lookup value from table 1 in paper. default = 0.9 0.9 looks int look intensity value from table 1 in paper. default = 4 4 tk int threshold value to determine values in window as point targets. default = 7 7 keep_bands list[str] list of band names to drop during filtering and include in the result default = [\"angle\"] ['angle'] Returns: Type Description ee.Image filtered SAR image using the Lee Sigma algorithm Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def lee_sigma ( img , window = 9 , sigma = 0.9 , looks = 4 , tk = 7 , keep_bands = [ \"angle\" ]): \"\"\"Lee Sigma speckle filtering algorithm. Implemented from interpreting https://doi.org/10.1109/TGRS.2008.2002881 args: img (ee.Image): Earth engine image object. Expects that imagery is a SAR image window (int, optional): moving window size to apply filter (i.e. a value of 9 == 9x9 window). default = 9 sigma (float, optional): sigma lookup value from table 1 in paper. default = 0.9 looks (int, optional): look intensity value from table 1 in paper. default = 4 tk (int, optional): threshold value to determine values in window as point targets. default = 7 keep_bands (list[str], optional): list of band names to drop during filtering and include in the result default = [\"angle\"] returns: ee.Image: filtered SAR image using the Lee Sigma algorithm \"\"\" band_names = img . bandNames () if keep_bands is not None : keep_img = img . select ( keep_bands ) proc_bands = band_names . removeAll ( keep_bands ) else : proc_bands = band_names img = img . select ( proc_bands ) midPt = ( window // 2 ) + 1 if ( window % 2 ) != 0 else window // 2 kernelWeights = ee . List . repeat ( ee . List . repeat ( 1 , window ), window ) kernel = ee . Kernel . fixed ( window , window , kernelWeights , midPt , midPt ) targetWeights = ee . List . repeat ( ee . List . repeat ( 1 , 3 ), 3 ) targetkernel = ee . Kernel . fixed ( 3 , 3 , targetWeights , 1 , 1 ) # Lookup table for range and eta values for intensity sigmaLookup = ee . Dictionary ( { 1 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.436 , \"A2\" : 1.92 , \"\u03b7\" : 0.4057 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.343 , \"A2\" : 2.21 , \"\u03b7\" : 0.4954 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.254 , \"A2\" : 2.582 , \"\u03b7\" : 0.5911 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.168 , \"A2\" : 3.094 , \"\u03b7\" : 0.6966 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.084 , \"A2\" : 3.941 , \"\u03b7\" : 0.8191 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.043 , \"A2\" : 4.840 , \"\u03b7\" : 0.8599 }), } ), 2 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.582 , \"A2\" : 1.584 , \"\u03b7\" : 0.2763 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.501 , \"A2\" : 1.755 , \"\u03b7\" : 0.3388 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.418 , \"A2\" : 1.972 , \"\u03b7\" : 0.4062 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.327 , \"A2\" : 2.260 , \"\u03b7\" : 0.4819 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.221 , \"A2\" : 2.744 , \"\u03b7\" : 0.5699 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.152 , \"A2\" : 3.206 , \"\u03b7\" : 0.6254 }), } ), 3 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.652 , \"A2\" : 1.458 , \"\u03b7\" : 0.2222 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.580 , \"A2\" : 1.586 , \"\u03b7\" : 0.2736 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.505 , \"A2\" : 1.751 , \"\u03b7\" : 0.3280 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.419 , \"A2\" : 1.865 , \"\u03b7\" : 0.3892 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.313 , \"A2\" : 2.320 , \"\u03b7\" : 0.4624 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.238 , \"A2\" : 2.656 , \"\u03b7\" : 0.5084 }), } ), 4 : ee . Dictionary ( { 0.5 : ee . Dictionary ({ \"A1\" : 0.694 , \"A2\" : 1.385 , \"\u03b7\" : 0.1921 }), 0.6 : ee . Dictionary ({ \"A1\" : 0.630 , \"A2\" : 1.495 , \"\u03b7\" : 0.2348 }), 0.7 : ee . Dictionary ({ \"A1\" : 0.560 , \"A2\" : 1.627 , \"\u03b7\" : 0.2825 }), 0.8 : ee . Dictionary ({ \"A1\" : 0.480 , \"A2\" : 1.804 , \"\u03b7\" : 0.3354 }), 0.9 : ee . Dictionary ({ \"A1\" : 0.378 , \"A2\" : 2.094 , \"\u03b7\" : 0.3991 }), 0.95 : ee . Dictionary ({ \"A1\" : 0.302 , \"A2\" : 2.360 , \"\u03b7\" : 0.4391 }), } ), } ) # extract data from lookup looksDict = ee . Dictionary ( sigmaLookup . get ( ee . String ( str ( looks )))) sigmaImage = ee . Dictionary ( looksDict . get ( ee . String ( str ( sigma )))) . toImage () a1 = sigmaImage . select ( \"A1\" ) a2 = sigmaImage . select ( \"A2\" ) aRange = a2 . subtract ( a1 ) eta = sigmaImage . select ( \"\u03b7\" ) . pow ( 2 ) img = geeutils . db_to_power ( img ) # MMSE estimator mmseMask = img . gte ( a1 ) . Or ( img . lte ( a2 )) mmseIn = img . updateMask ( mmseMask ) oneImg = ee . Image ( 1 ) z = mmseIn . reduceNeighborhood ( ee . Reducer . mean (), kernel , None , True ) varz = mmseIn . reduceNeighborhood ( ee . Reducer . variance (), kernel ) varx = ( varz . subtract ( z . abs () . pow ( 2 ) . multiply ( eta ))) . divide ( oneImg . add ( eta )) b = varx . divide ( varz ) mmse = oneImg . subtract ( b ) . multiply ( z . abs ()) . add ( b . multiply ( mmseIn )) # workflow z99 = ee . Dictionary ( img . reduceRegion ( reducer = ee . Reducer . percentile ([ 99 ], None , 255 , 0.001 , 1e6 ), geometry = img . geometry (), scale = 10 , bestEffort = True , ) ) . toImage () overThresh = img . gte ( z99 ) K = overThresh . reduceNeighborhood ( ee . Reducer . sum (), targetkernel , None , True ) retainPixel = K . gte ( tk ) xHat = geeutils . power_to_db ( img . updateMask ( retainPixel ) . unmask ( mmse )) output = ee . Image ( xHat ) . rename ( proc_bands ) if keep_bands is not None : output = output . addBands ( keep_img ) return output","title":"lee_sigma()"},{"location":"filtering/#hydrafloods.filtering.modified_median_zscore","text":"Outlier detection and filling on complete DEM using the modified z-score and a median filter Method from Iglewicz, B. and Hoaglin, D.C., 1993. How to detect and handle outliers (Vol. 16). Asq Press. Parameters: Name Type Description Default img ee.Image Earth engine image object to apply filter on required fill_img ee.Image Earth engine image object to fill values resulting from filter. If None provided, the fill operation will be on the input image. Default = None None Returns: Type Description ee.Image filtered image Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def modified_median_zscore ( img , fill_img = None ): \"\"\"Outlier detection and filling on complete DEM using the modified z-score and a median filter Method from Iglewicz, B. and Hoaglin, D.C., 1993. How to detect and handle outliers (Vol. 16). Asq Press. args: img (ee.Image): Earth engine image object to apply filter on fill_img (ee.Image): Earth engine image object to fill values resulting from filter. If None provided, the fill operation will be on the input image. Default = None returns: ee.Image: filtered image \"\"\" kernel = ee . Kernel . fixed ( 3 , 3 , [[ 1 , 1 , 1 ], [ 1 , 1 , 1 ], [ 1 , 1 , 1 ]]) kernel_weighted = ee . Kernel . fixed ( 3 , 3 , [[ 1 , 1 , 1 ], [ 1 , 0 , 1 ], [ 1 , 1 , 1 ]]) median = img . focal_median ( kernel = kernel ) median_weighted = img . focal_median ( kernel = kernel_weighted ) diff = img . subtract ( median ) mzscore = diff . multiply ( 0.6745 ) . divide ( diff . abs () . focal_median ( kernel = kernel )) if fill_img : filled = fill_img . where ( mzscore . gt ( 3.5 ), median_weighted ) else : filled = img . where ( mzscore . gt ( 3.5 ), median_weighted ) return filled","title":"modified_median_zscore()"},{"location":"filtering/#hydrafloods.filtering.open_binary","text":"Opening morphological filter. Opening is the dilation of the erosion of values greater than 1. Parameters: Name Type Description Default img ee.Image binary image to apply opening filter on required window int | ee.Number distance in pixels to consider for opening process 3 neighborhood int | ee.Number size of the neighborhood to perform fast distance trasnform. Smaller values speed up operations however must be greater than window. If no nerighborhood is provided, it will be double the window size. default = None None Returns: Type Description ee.Image the opened binary image Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def open_binary ( img , window = 3 , neighborhood = None ): \"\"\"Opening morphological filter. Opening is the dilation of the erosion of values greater than 1. args: img (ee.Image): binary image to apply opening filter on window (int | ee.Number, optional): distance in pixels to consider for opening process neighborhood (int | ee.Number, optional): size of the neighborhood to perform fast distance trasnform. Smaller values speed up operations however must be greater than window. If no nerighborhood is provided, it will be double the window size. default = None returns: ee.Image: the opened binary image \"\"\" if not isinstance ( window , ee . Number ): window = ee . Number ( window ) if neighborhood is None : neighborhood = window . multiply ( 2 ) erosion = img . Not () . fastDistanceTransform ( neighborhood ) . sqrt () . gt ( window ) opened = erosion . fastDistanceTransform ( neighborhood ) . sqrt () . lt ( window ) return opened . updateMask ( img . mask ())","title":"open_binary()"},{"location":"filtering/#hydrafloods.filtering.p_median","text":"P-Median filter for smoothing imagery. Calculates the average from the median along cross and diagnal pixels of a window Parameters: Name Type Description Default img ee.Image Earth engine image object to filter required window int moving window size to apply filter (i.e. a value of 5 == 5x5 window). default = 5 5 Returns: Type Description ee.Image filtered image Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def p_median ( img , window = 5 , keep_bands = [ \"angle\" ]): \"\"\"P-Median filter for smoothing imagery. Calculates the average from the median along cross and diagnal pixels of a window args: img (ee.Image): Earth engine image object to filter window (int, optional): moving window size to apply filter (i.e. a value of 5 == 5x5 window). default = 5 returns: ee.Image: filtered image \"\"\" def _band_filter ( bname ): selector = ee . List ([ bname ]) band_img = img . select ( selector ) hv_median = band_img . reduceNeighborhood ( ee . Reducer . median (), hv_kernel ) diag_median = band_img . reduceNeighborhood ( ee . Reducer . median (), diag_kernel ) return ee . Image ( ee . Image . cat ([ hv_median , diag_median ]) . reduce ( \"mean\" )) . rename ( selector ) if window % 2 == 0 : window += 1 center_idx = ( window - 1 ) // 2 hv = [ [ 1 if i == center_idx or j == center_idx else 0 for j in range ( window )] for i in range ( window ) ] diag = [ [ 1 if i == j or i == (( window - 1 ) - j ) else 0 for j in range ( window )] for i in range ( window ) ] # method based on ??? band_names = img . bandNames () hv_weights = ee . List ( hv ) diag_weights = ee . List ( diag ) hv_kernel = ee . Kernel . fixed ( window , window , hv_weights ) diag_kernel = ee . Kernel . fixed ( window , window , diag_weights ) reduced_bands = ee . ImageCollection . fromImages ( band_names . map ( _band_filter ) ) . toBands () return reduced_bands . rename ( band_names )","title":"p_median()"},{"location":"filtering/#hydrafloods.filtering.perona_malik","text":"Perona-Malik (anisotropic diffusion) convolution Developed by Gennadii Donchyts see https://groups.google.com/g/google-earth-engine-developers/c/umGlt5qIN1I/m/PD8lsJ7qBAAJ I(n+1, i, j) = I(n, i, j) + lambda * (cN * dN(I) + cS * dS(I) + cE * dE(I), cW * dW(I)) Parameters: Name Type Description Default img ee.Image Earth engine image object. Expects that imagery is a SAR image required n_iters int Number of interations to apply filter K (int,optional): moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 3 10 method int choose method 1 (default) or 2 1 Returns: Type Description ee.Image filtered SAR image using the perona malik algorithm Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def perona_malik ( img , n_iters = 10 , K = 3 , method = 1 ): \"\"\"Perona-Malik (anisotropic diffusion) convolution Developed by Gennadii Donchyts see https://groups.google.com/g/google-earth-engine-developers/c/umGlt5qIN1I/m/PD8lsJ7qBAAJ I(n+1, i, j) = I(n, i, j) + lambda * (cN * dN(I) + cS * dS(I) + cE * dE(I), cW * dW(I)) args: img (ee.Image): Earth engine image object. Expects that imagery is a SAR image n_iters (int, optional): Number of interations to apply filter K (int,optional): moving window size to apply filter (i.e. a value of 7 == 7x7 window). default = 3 method (int, optional): choose method 1 (default) or 2 returns: ee.Image: filtered SAR image using the perona malik algorithm \"\"\" def _method_1 ( dI_W , dI_E , dI_N , dI_S ): cW = dI_W . pow ( 2 ) . multiply ( k1 ) . exp () cE = dI_E . pow ( 2 ) . multiply ( k1 ) . exp () cN = dI_N . pow ( 2 ) . multiply ( k1 ) . exp () cS = dI_S . pow ( 2 ) . multiply ( k1 ) . exp () return cW , cE , cN , cS def _method_2 ( dI_W , dI_E , dI_N , dI_S ): cW = one . divide ( one . add ( dI_W . pow ( 2 ) . divide ( k2 ))) cE = one . divide ( one . add ( dI_E . pow ( 2 ) . divide ( k2 ))) cN = one . divide ( one . add ( dI_N . pow ( 2 ) . divide ( k2 ))) cS = one . divide ( one . add ( dI_S . pow ( 2 ) . divide ( k2 ))) return cW , cE , cN , cS # covnert db to natural units before applying filter power = geeutils . db_to_power ( img ) dxW = ee . Kernel . fixed ( 3 , 3 , [[ 0 , 0 , 0 ], [ 1 , - 1 , 0 ], [ 0 , 0 , 0 ]]) dxE = ee . Kernel . fixed ( 3 , 3 , [[ 0 , 0 , 0 ], [ 0 , - 1 , 1 ], [ 0 , 0 , 0 ]]) dyN = ee . Kernel . fixed ( 3 , 3 , [[ 0 , 1 , 0 ], [ 0 , - 1 , 0 ], [ 0 , 0 , 0 ]]) dyS = ee . Kernel . fixed ( 3 , 3 , [[ 0 , 0 , 0 ], [ 0 , - 1 , 0 ], [ 0 , 1 , 0 ]]) one = ee . Image . constant ( 1.0 ) l = ee . Image . constant ( 0.2 ) k = ee . Image . constant ( K ) k1 = ee . Image . constant ( - 1.0 / K ) k2 = k . pow ( 2 ) if method == 1 : _method = _method_1 elif method == 2 : _method = _method_2 else : raise NotImplementedError ( \"Could not determine algorithm to apply filter...options for `method` are 1 or 2\" ) for i in range ( n_iters ): dI_W = power . convolve ( dxW ) dI_E = power . convolve ( dxE ) dI_N = power . convolve ( dyN ) dI_S = power . convolve ( dyS ) cW , cE , cN , cS = _method ( dI_W , dI_E , dI_N , dI_S ) power = power . add ( l . multiply ( cN . multiply ( dI_N ) . add ( cS . multiply ( dI_S )) . add ( cE . multiply ( dI_E )) . add ( cW . multiply ( dI_W )) ) ) # covnert natural to db units after filter is done img = geeutils . power_to_db ( power ) return img","title":"perona_malik()"},{"location":"filtering/#hydrafloods.filtering.refined_lee","text":"Refined Lee speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/ExepnAmP-hQ/m/7e5DnjXXAQAJ Parameters: Name Type Description Default image ee.Image Earth engine image object. Expects that imagery is a SAR image required Returns: Type Description ee.Image filtered SAR image using the Refined Lee algorithm Source code in hydrafloods/filtering.py @decorators . keep_names @decorators . keep_attrs def refined_lee ( image , keep_bands = [ \"angle\" ]): \"\"\"Refined Lee speckle filtering algorithm. Algorithm adapted from https://groups.google.com/g/google-earth-engine-developers/c/ExepnAmP-hQ/m/7e5DnjXXAQAJ args: image (ee.Image): Earth engine image object. Expects that imagery is a SAR image returns: ee.Image: filtered SAR image using the Refined Lee algorithm \"\"\" # TODO: include keep bands...maybe one-shot filtering if using keep_bands??? def apply_filter ( b ): \"\"\"Closure function to apply the refined lee algorithm on individual bands\"\"\" b = ee . String ( b ) img = power . select ( b ) # img must be in natural units, i.e. not in dB! # Set up 3x3 kernels weights3 = ee . List . repeat ( ee . List . repeat ( 1 , 3 ), 3 ) kernel3 = ee . Kernel . fixed ( 3 , 3 , weights3 , 1 , 1 , False ) mean3 = img . reduceNeighborhood ( ee . Reducer . mean (), kernel3 ) variance3 = img . reduceNeighborhood ( ee . Reducer . variance (), kernel3 ) # Use a sample of the 3x3 windows inside a 7x7 windows to determine gradients and directions sample_weights = ee . List ( [ [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 0 , 1 , 0 , 1 , 0 , 1 , 0 ], [ 0 , 0 , 0 , 0 , 0 , 0 , 0 ], ] ) sample_kernel = ee . Kernel . fixed ( 7 , 7 , sample_weights , 3 , 3 , False ) # Calculate mean and variance for the sampled windows and store as 9 bands sample_mean = mean3 . neighborhoodToBands ( sample_kernel ) sample_var = variance3 . neighborhoodToBands ( sample_kernel ) # Determine the 4 gradients for the sampled windows gradients = sample_mean . select ( 1 ) . subtract ( sample_mean . select ( 7 )) . abs () gradients = gradients . addBands ( sample_mean . select ( 6 ) . subtract ( sample_mean . select ( 2 )) . abs () ) gradients = gradients . addBands ( sample_mean . select ( 3 ) . subtract ( sample_mean . select ( 5 )) . abs () ) gradients = gradients . addBands ( sample_mean . select ( 0 ) . subtract ( sample_mean . select ( 8 )) . abs () ) # And find the maximum gradient amongst gradient bands max_gradient = gradients . reduce ( ee . Reducer . max ()) # Create a mask for band pixels that are the maximum gradient gradmask = gradients . eq ( max_gradient ) # duplicate gradmask bands: each gradient represents 2 directions gradmask = gradmask . addBands ( gradmask ) # Determine the 8 directions directions = ( sample_mean . select ( 1 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 7 ))) . multiply ( 1 ) ) directions = directions . addBands ( sample_mean . select ( 6 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 2 ))) . multiply ( 2 ) ) directions = directions . addBands ( sample_mean . select ( 3 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 5 ))) . multiply ( 3 ) ) directions = directions . addBands ( sample_mean . select ( 0 ) . subtract ( sample_mean . select ( 4 )) . gt ( sample_mean . select ( 4 ) . subtract ( sample_mean . select ( 8 ))) . multiply ( 4 ) ) # The next 4 are the not() of the previous 4 directions = directions . addBands ( directions . select ( 0 ) . Not () . multiply ( 5 )) directions = directions . addBands ( directions . select ( 1 ) . Not () . multiply ( 6 )) directions = directions . addBands ( directions . select ( 2 ) . Not () . multiply ( 7 )) directions = directions . addBands ( directions . select ( 3 ) . Not () . multiply ( 8 )) # Mask all values that are not 1-8 directions = directions . updateMask ( gradmask ) # \"collapse\" the stack into a singe band image (due to masking, each pixel has just one value (1-8) in it's directional band, and is otherwise masked) directions = directions . reduce ( ee . Reducer . sum ()) sample_stats = sample_var . divide ( sample_mean . multiply ( sample_mean )) # Calculate localNoiseVariance sigmaV = ( sample_stats . toArray () . arraySort () . arraySlice ( 0 , 0 , 5 ) . arrayReduce ( ee . Reducer . mean (), [ 0 ]) ) # Set up the 7*7 kernels for directional statistics rect_weights = ee . List . repeat ( ee . List . repeat ( 0 , 7 ), 3 ) . cat ( ee . List . repeat ( ee . List . repeat ( 1 , 7 ), 4 ) ) diag_weights = ee . List ( [ [ 1 , 0 , 0 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 0 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 0 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 0 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 0 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 1 , 0 ], [ 1 , 1 , 1 , 1 , 1 , 1 , 1 ], ] ) rect_kernel = ee . Kernel . fixed ( 7 , 7 , rect_weights , 3 , 3 , False ) diag_kernel = ee . Kernel . fixed ( 7 , 7 , diag_weights , 3 , 3 , False ) # Create stacks for mean and variance using the original kernels. Mask with relevant direction. dir_mean = img . reduceNeighborhood ( ee . Reducer . mean (), rect_kernel ) . updateMask ( directions . eq ( 1 ) ) dir_var = img . reduceNeighborhood ( ee . Reducer . variance (), rect_kernel ) . updateMask ( directions . eq ( 1 ) ) dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), diag_kernel ) . updateMask ( directions . eq ( 2 ) ) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), diag_kernel ) . updateMask ( directions . eq ( 2 ) ) ) # and add the bands for rotated kernels for i in range ( 1 , 4 ): dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), rect_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 1 )) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), rect_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 1 )) ) dir_mean = dir_mean . addBands ( img . reduceNeighborhood ( ee . Reducer . mean (), diag_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 2 )) ) dir_var = dir_var . addBands ( img . reduceNeighborhood ( ee . Reducer . variance (), diag_kernel . rotate ( i ) ) . updateMask ( directions . eq ( 2 * i + 2 )) ) # \"collapse\" the stack into a single band image (due to masking, each pixel has just one value in it's directional band, and is otherwise masked) dir_mean = dir_mean . reduce ( ee . Reducer . sum ()) dir_var = dir_var . reduce ( ee . Reducer . sum ()) # A finally generate the filtered value varX = dir_var . subtract ( dir_mean . multiply ( dir_mean ) . multiply ( sigmaV )) . divide ( sigmaV . add ( 1.0 ) ) b = varX . divide ( dir_var ) # return multi-band image band from array return ( dir_mean . add ( b . multiply ( img . subtract ( dir_mean ))) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"sum\" ]]) . float () ) band_names = image . bandNames () if keep_bands is not None : keep_img = image . select ( keep_bands ) proc_bands = band_names . removeAll ( keep_bands ) else : proc_bands = band_names image = image . select ( proc_bands ) power = geeutils . db_to_power ( image ) result = ee . ImageCollection ( proc_bands . map ( apply_filter )) . toBands () output = geeutils . power_to_db ( ee . Image ( result )) . rename ( proc_bands ) if keep_bands is not None : output = output . addBands ( keep_img ) return output","title":"refined_lee()"},{"location":"floods/","text":"hydrafloods.floods discrete_difference ( observation , reference ) Function to find the difference between an observation and reference dataset. The data should be discrete values (i.e. a classification). This function expects that water/floods = 1 and land = 0. Unknown values should be masked. Parameters: Name Type Description Default observation ee.Image image object representing the observation of water to extract floods required reference ee.Image image object representing reference/permanent water to extract floods from required Returns: Type Description ee.Image extracted flood image where flood values = 1 Source code in hydrafloods/floods.py @decorators . keep_attrs def discrete_difference ( observation , reference ): \"\"\"Function to find the difference between an observation and reference dataset. The data should be discrete values (i.e. a classification). This function expects that water/floods = 1 and land = 0. Unknown values should be masked. args: observation (ee.Image): image object representing the observation of water to extract floods reference (ee.Image): image object representing reference/permanent water to extract floods from returns: ee.Image: extracted flood image where flood values = 1 \"\"\" og_mask = observation . mask () floods = observation . unmask ( 0 ) . add ( reference . unmask ( 0 ) . multiply ( 2 )) . eq ( 1 ) return floods . updateMask ( og_mask ) . rename ( \"flood\" ) extract_flood ( observation , reference = 'seasonal' , permanent_threshold = 75 ) Function used to extract flooded area based off of different JRC datasets. Expects that the water image has water = 1, land = 0, unknown = mask Parameters: Name Type Description Default observation ee.Image image object representing the observation of water to extract floods required reference str string to define how permanent water is defined. 'yearly' means use past 5 years of JRC yearly data and extract permanent class. 'seasonal' means use monthly water occurrence for the month of observation. 'occurrence' means use full JRC occurrence dataset irregardless of time. default = seasonal 'seasonal' permanent_threshold int threshold value in % to define permanent water. Only used when reference equals 'seasonal' or 'occurrence'. default = 75 75 Returns: Type Description ee.Image the extracted flood image where floods = 1 Exceptions: Type Description NotImplementedError when user provides an invalid option for reference parameter Source code in hydrafloods/floods.py @decorators . keep_attrs def extract_flood ( observation , reference = \"seasonal\" , permanent_threshold = 75 ): \"\"\"Function used to extract flooded area based off of different JRC datasets. Expects that the water image has water = 1, land = 0, unknown = mask args: observation (ee.Image): image object representing the observation of water to extract floods reference (str): string to define how permanent water is defined. 'yearly' means use past 5 years of JRC yearly data and extract permanent class. 'seasonal' means use monthly water occurrence for the month of observation. 'occurrence' means use full JRC occurrence dataset irregardless of time. default = seasonal permanent_threshold (int): threshold value in % to define permanent water. Only used when reference equals 'seasonal' or 'occurrence'. default = 75 returns: ee.Image: the extracted flood image where floods = 1 raises: NotImplementedError: when user provides an invalid option for reference parameter \"\"\" if reference == \"yearly\" : end_time = observation . date () permanent_water = ( ee . ImageCollection ( \"JRC/GSW1_2/YearlyHistory\" ) # get the JRC historical dataset . filterDate ( \"1985-01-01\" , end_time ) # filter for historical data up to date of interest . limit ( 5 , \"system:time_start\" , False ) # grab the 5 latest images . map ( lambda x : x . select ( \"waterClass\" ) . eq ( 3 ) ) # extract out the permanent water class . sum () # check if a pixel has been classified as permanent water in the past 5 years . unmask ( 0 ) . gt ( 0 ) ) elif reference == \"seasonal\" : month = observation . date () . get ( \"month\" ) permanent_water = ( ee . ImageCollection ( \"JRC/GSW1_3/MonthlyRecurrence\" ) . select ( \"monthly_recurrence\" ) . filter ( ee . Filter . eq ( \"month\" , month )) . first () . gt ( permanent_threshold ) ) elif reference == \"occurrence\" : permanent_water = ( ee . Image ( \"JRC/GSW1_3/GlobalSurfaceWater\" ) . select ( \"occurrence\" ) . gt ( permanent_threshold ) ) else : raise NotImplementedError ( \"the selected reference method, {reference} , is not implemeted. please select either 'yearly','seasonal', or 'occurrence'\" ) return discrete_difference ( observation , permanent_water ) lar_change_detection ( observation , reference , band = None , in_units = 'dB' , segmentation = 'edgeotsu' , ** kwargs ) Log Amplitude Ratio change detection method. https://doi.org/10.1080/014311698215649 Note: This method only works for SAR imagery. Parameters: Name Type Description Default observation ee.Image required reference ee.Image required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None in_units str string specifying the input units for the imagery. Options are 'dB' or 'power'. If in_units = 'dB', then the data is converted to power units. default = dB 'dB' segmentation str | None segmentation method to use to . Options are 'edgeotsu', 'bmaxotsu', or None. If none is provided then no segmentation is applied and the raw log amplitude ratio is returned. default = edgeotsu 'edgeotsu' **kwargs optional keywords to pass to segmentation method, not required if segmentation = None {} Returns: Type Description ee.Image Source code in hydrafloods/floods.py @decorators . keep_attrs def lar_change_detection ( observation , reference , band = None , in_units = \"dB\" , segmentation = \"edgeotsu\" , ** kwargs ): \"\"\"Log Amplitude Ratio change detection method. https://doi.org/10.1080/014311698215649 Note: This method only works for SAR imagery. args: observation (ee.Image): reference (ee.Image): band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None in_units (str, optional): string specifying the input units for the imagery. Options are 'dB' or 'power'. If in_units = 'dB', then the data is converted to power units. default = dB segmentation (str | None, optional): segmentation method to use to . Options are 'edgeotsu', 'bmaxotsu', or None. If none is provided then no segmentation is applied and the raw log amplitude ratio is returned. default = edgeotsu **kwargs: optional keywords to pass to segmentation method, not required if segmentation = None returns: ee.Image: \"\"\" if band is None : band = observation . bandNames () . get ( 0 ) # convert the db data to amplitude units # amplitude = sqrt(power) # then divide post/pre and take the log if in_units == \"dB\" : lar = ( geeutils . db_to_power ( observation ) . sqrt () . select ( band ) . divide ( geeutils . db_to_power ( reference ) . sqrt () . select ( band )) . log10 () ) elif in_units == \"power\" : lar = observation . sqrt () . select ( band ) . divide ( reference . sqrt () . select ( band )) . log10 () else : raise NotImplementedError ( f \"input units could not be infered from { in_units } , please select either 'dB' or 'power'\" ) if segmentation == \"edgeotsu\" : floods_lar = thresholding . edge_otsu ( lar , band = band , ** kwargs ) elif segmentation == \"bmaxotsu\" : floods_lar = thresholding . bmax_otsu ( lar , band = band , ** kwargs ) elif segmentation == None : floods_lar = lar else : raise NotImplementedError ( f \"selected segmentation method { segmentation } is not valid, please select 'edgeotsu', 'bmaxotsu', or None\" ) return floods_lar","title":"floods module"},{"location":"floods/#hydrafloods.floods","text":"","title":"floods"},{"location":"floods/#hydrafloods.floods.discrete_difference","text":"Function to find the difference between an observation and reference dataset. The data should be discrete values (i.e. a classification). This function expects that water/floods = 1 and land = 0. Unknown values should be masked. Parameters: Name Type Description Default observation ee.Image image object representing the observation of water to extract floods required reference ee.Image image object representing reference/permanent water to extract floods from required Returns: Type Description ee.Image extracted flood image where flood values = 1 Source code in hydrafloods/floods.py @decorators . keep_attrs def discrete_difference ( observation , reference ): \"\"\"Function to find the difference between an observation and reference dataset. The data should be discrete values (i.e. a classification). This function expects that water/floods = 1 and land = 0. Unknown values should be masked. args: observation (ee.Image): image object representing the observation of water to extract floods reference (ee.Image): image object representing reference/permanent water to extract floods from returns: ee.Image: extracted flood image where flood values = 1 \"\"\" og_mask = observation . mask () floods = observation . unmask ( 0 ) . add ( reference . unmask ( 0 ) . multiply ( 2 )) . eq ( 1 ) return floods . updateMask ( og_mask ) . rename ( \"flood\" )","title":"discrete_difference()"},{"location":"floods/#hydrafloods.floods.extract_flood","text":"Function used to extract flooded area based off of different JRC datasets. Expects that the water image has water = 1, land = 0, unknown = mask Parameters: Name Type Description Default observation ee.Image image object representing the observation of water to extract floods required reference str string to define how permanent water is defined. 'yearly' means use past 5 years of JRC yearly data and extract permanent class. 'seasonal' means use monthly water occurrence for the month of observation. 'occurrence' means use full JRC occurrence dataset irregardless of time. default = seasonal 'seasonal' permanent_threshold int threshold value in % to define permanent water. Only used when reference equals 'seasonal' or 'occurrence'. default = 75 75 Returns: Type Description ee.Image the extracted flood image where floods = 1 Exceptions: Type Description NotImplementedError when user provides an invalid option for reference parameter Source code in hydrafloods/floods.py @decorators . keep_attrs def extract_flood ( observation , reference = \"seasonal\" , permanent_threshold = 75 ): \"\"\"Function used to extract flooded area based off of different JRC datasets. Expects that the water image has water = 1, land = 0, unknown = mask args: observation (ee.Image): image object representing the observation of water to extract floods reference (str): string to define how permanent water is defined. 'yearly' means use past 5 years of JRC yearly data and extract permanent class. 'seasonal' means use monthly water occurrence for the month of observation. 'occurrence' means use full JRC occurrence dataset irregardless of time. default = seasonal permanent_threshold (int): threshold value in % to define permanent water. Only used when reference equals 'seasonal' or 'occurrence'. default = 75 returns: ee.Image: the extracted flood image where floods = 1 raises: NotImplementedError: when user provides an invalid option for reference parameter \"\"\" if reference == \"yearly\" : end_time = observation . date () permanent_water = ( ee . ImageCollection ( \"JRC/GSW1_2/YearlyHistory\" ) # get the JRC historical dataset . filterDate ( \"1985-01-01\" , end_time ) # filter for historical data up to date of interest . limit ( 5 , \"system:time_start\" , False ) # grab the 5 latest images . map ( lambda x : x . select ( \"waterClass\" ) . eq ( 3 ) ) # extract out the permanent water class . sum () # check if a pixel has been classified as permanent water in the past 5 years . unmask ( 0 ) . gt ( 0 ) ) elif reference == \"seasonal\" : month = observation . date () . get ( \"month\" ) permanent_water = ( ee . ImageCollection ( \"JRC/GSW1_3/MonthlyRecurrence\" ) . select ( \"monthly_recurrence\" ) . filter ( ee . Filter . eq ( \"month\" , month )) . first () . gt ( permanent_threshold ) ) elif reference == \"occurrence\" : permanent_water = ( ee . Image ( \"JRC/GSW1_3/GlobalSurfaceWater\" ) . select ( \"occurrence\" ) . gt ( permanent_threshold ) ) else : raise NotImplementedError ( \"the selected reference method, {reference} , is not implemeted. please select either 'yearly','seasonal', or 'occurrence'\" ) return discrete_difference ( observation , permanent_water )","title":"extract_flood()"},{"location":"floods/#hydrafloods.floods.lar_change_detection","text":"Log Amplitude Ratio change detection method. https://doi.org/10.1080/014311698215649 Note: This method only works for SAR imagery. Parameters: Name Type Description Default observation ee.Image required reference ee.Image required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None in_units str string specifying the input units for the imagery. Options are 'dB' or 'power'. If in_units = 'dB', then the data is converted to power units. default = dB 'dB' segmentation str | None segmentation method to use to . Options are 'edgeotsu', 'bmaxotsu', or None. If none is provided then no segmentation is applied and the raw log amplitude ratio is returned. default = edgeotsu 'edgeotsu' **kwargs optional keywords to pass to segmentation method, not required if segmentation = None {} Returns: Type Description ee.Image Source code in hydrafloods/floods.py @decorators . keep_attrs def lar_change_detection ( observation , reference , band = None , in_units = \"dB\" , segmentation = \"edgeotsu\" , ** kwargs ): \"\"\"Log Amplitude Ratio change detection method. https://doi.org/10.1080/014311698215649 Note: This method only works for SAR imagery. args: observation (ee.Image): reference (ee.Image): band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None in_units (str, optional): string specifying the input units for the imagery. Options are 'dB' or 'power'. If in_units = 'dB', then the data is converted to power units. default = dB segmentation (str | None, optional): segmentation method to use to . Options are 'edgeotsu', 'bmaxotsu', or None. If none is provided then no segmentation is applied and the raw log amplitude ratio is returned. default = edgeotsu **kwargs: optional keywords to pass to segmentation method, not required if segmentation = None returns: ee.Image: \"\"\" if band is None : band = observation . bandNames () . get ( 0 ) # convert the db data to amplitude units # amplitude = sqrt(power) # then divide post/pre and take the log if in_units == \"dB\" : lar = ( geeutils . db_to_power ( observation ) . sqrt () . select ( band ) . divide ( geeutils . db_to_power ( reference ) . sqrt () . select ( band )) . log10 () ) elif in_units == \"power\" : lar = observation . sqrt () . select ( band ) . divide ( reference . sqrt () . select ( band )) . log10 () else : raise NotImplementedError ( f \"input units could not be infered from { in_units } , please select either 'dB' or 'power'\" ) if segmentation == \"edgeotsu\" : floods_lar = thresholding . edge_otsu ( lar , band = band , ** kwargs ) elif segmentation == \"bmaxotsu\" : floods_lar = thresholding . bmax_otsu ( lar , band = band , ** kwargs ) elif segmentation == None : floods_lar = lar else : raise NotImplementedError ( f \"selected segmentation method { segmentation } is not valid, please select 'edgeotsu', 'bmaxotsu', or None\" ) return floods_lar","title":"lar_change_detection()"},{"location":"fuzzy/","text":"hydrafloods.fuzzy fuzzy_and ( img_list ) Fuzzy And overlay returning the minimum value of the input images. This technique is useful when you want to identify the least common denominator for the membership of all the input criteria Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_and ( img_list ): \"\"\"Fuzzy And overlay returning the minimum value of the input images. This technique is useful when you want to identify the least common denominator for the membership of all the input criteria args: img_list (list[ee.Image]): list of ee.Image objects to overlay together returns: ee.Image: output floating-point image with overlayed values \"\"\" in_img = ee . Image . cat ([ img_list ]) out_img = in_img . reduce ( ee . Reducer . min ()) . rename ( \"fuzzy_and\" ) return out_img fuzzy_gamma ( img_list , gamma = 0.5 ) Fuzzy Gamma is an algebraic product of fuzzy Product and fuzzy Sum, which are both raised to the power of gamma. If the specified gamma is 1, the output is the same as fuzzy Sum; if gamma is 0, the output is the same as fuzzy Product Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required gamma float the gamma value to be used when weighting Product vs Sum 0.5 Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_gamma ( img_list , gamma = 0.5 ): \"\"\"Fuzzy Gamma is an algebraic product of fuzzy Product and fuzzy Sum, which are both raised to the power of gamma. If the specified gamma is 1, the output is the same as fuzzy Sum; if gamma is 0, the output is the same as fuzzy Product args: img_list (list[ee.Image]): list of ee.Image objects to overlay together gamma (float): the gamma value to be used when weighting Product vs Sum returns: ee.Image: output floating-point image with overlayed values \"\"\" gamma = ee . Image . constant ( gamma ) one = ee . Image . constant ( 1 ) a = fuzzy_sum ( img_list ) b = fuzzy_product ( img_list ) out_img = a . pow ( gamma ) . multiply ( b . pow ( one . subtract ( gamma ))) . rename ( \"fuzzy_gamma\" ) return out_img fuzzy_gaussian ( img , midpoint , spread ) Fuzzy membership function through a Gaussian or normal distribution based around a user-specified midpoint (which is assigned a membership of 1) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzygaussian-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required midpoint float user-defined value with a fuzzy membership of 1 required spread float the spread of the Gaussian function. The spread generally ranges from 0.01 to 1, with the larger the value results in a steeper distribution around the midpoint required Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_gaussian ( img , midpoint , spread ): \"\"\"Fuzzy membership function through a Gaussian or normal distribution based around a user-specified midpoint (which is assigned a membership of 1) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzygaussian-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 midpoint (float): user-defined value with a fuzzy membership of 1 spread (float): the spread of the Gaussian function. The spread generally ranges from 0.01 to 1, with the larger the value results in a steeper distribution around the midpoint returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" bandNames = img . bandNames () spread = ee . Image . constant ( spread ) midpoint = ee . Image . constant ( midpoint ) e = ee . Image . constant ( math . e ) gauss = e . expression ( \"e ** (-s * (x-m)**2)\" , { \"e\" : e , \"x\" : img , \"s\" : spread , \"m\" : midpoint } ) return gauss . rename ( bandNames ) fuzzy_large ( img , midpoint , spread ) Fuzzy membership function where the larger input values have membership closer to 1. The function is defined by a user-specified midpoint (which is assigned a membership of 0.5) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylarge-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required midpoint float user-defined value with a fuzzy membership of 0.5 required spread float the spread of the Large function. The spread generally ranges from 1 to 10, with the larger the value results in a steeper distribution from the midpoint required Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_large ( img , midpoint , spread ): \"\"\"Fuzzy membership function where the larger input values have membership closer to 1. The function is defined by a user-specified midpoint (which is assigned a membership of 0.5) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylarge-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 midpoint (float): user-defined value with a fuzzy membership of 0.5 spread (float): the spread of the Large function. The spread generally ranges from 1 to 10, with the larger the value results in a steeper distribution from the midpoint returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" bandNames = img . bandNames () spread = ee . Image ( spread ) midpoint = ee . Image ( midpoint ) one = ee . Image . constant ( 1 ) large = one . expression ( \"o / ( o + (x / m) ** (s * -1))\" , { \"o\" : one , \"x\" : img , \"s\" : spread , \"m\" : midpoint }, ) return large . rename ( bandNames ) fuzzy_linear ( img , min_val , max_val ) Fuzzy membership function through a linear transformation between the user-specified minimum value, a membership of 0, to the user-defined maximum value, which is assigned a membership of 1. If the minimum value is less than the maximum, the linear function will have a positive slope. If the minimum value is greater than the maximum, the linear function will have a negative slope. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylinear-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled linearly from 0 to 1 required minimum float The value that will have a membership of 0 required maximum float The value that will have a membership of 1 required Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_linear ( img , min_val , max_val ): \"\"\"Fuzzy membership function through a linear transformation between the user-specified minimum value, a membership of 0, to the user-defined maximum value, which is assigned a membership of 1. If the minimum value is less than the maximum, the linear function will have a positive slope. If the minimum value is greater than the maximum, the linear function will have a negative slope. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylinear-class.htm args: img (ee.Image): The input image whose values will be scaled linearly from 0 to 1 minimum (float): The value that will have a membership of 0 maximum (float): The value that will have a membership of 1 returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" bandNames = img . bandNames () if ~ isinstance ( min_val , ee . Number ): min_val = ee . Number ( min_val ) if ~ isinstance ( max_val , ee . Number ): max_val = ee . Number ( max_val ) invert = min_val . gt ( max_val ) minimum = ee . Algorithms . If ( invert , max_val , min_val ) maximum = ee . Algorithms . If ( invert , min_val , max_val ) linear = img . unitScale ( minimum , maximum ) linear = ee . Algorithms . If ( invert , ee . Image . constant ( 1 ) . subtract ( linear ), linear ) linear = ee . Image ( linear ) . clamp ( 0 , 1 ) return linear . rename ( bandNames ) fuzzy_mslarge ( img , mean_scaling , std_scaling , region = None , scale = 90 ) Fuzzy membership through a function based on the mean and standard deviation, with the larger values having a membership closer to 1. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzymslarge-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required mean_scaling float multiplier for the mean of the input values in the MSLarge function equation. required std_scaling float multiplier for the standard deviation of the input values in the MSLarge function equation. required region ee.Geometry | None region to calculate mean/stdDev image statistics, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_mslarge ( img , mean_scaling , std_scaling , region = None , scale = 90 ): \"\"\"Fuzzy membership through a function based on the mean and standard deviation, with the larger values having a membership closer to 1. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzymslarge-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 mean_scaling (float): multiplier for the mean of the input values in the MSLarge function equation. std_scaling (float): multiplier for the standard deviation of the input values in the MSLarge function equation. region (ee.Geometry | None, optional): region to calculate mean/stdDev image statistics, if set to None will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" if region is None : region = img . geometry () bandNames = img . bandNames () mean_scale = ee . Image . constant ( mean_scaling ) std_scale = ee . Image . constant ( std_scaling ) one = ee . Image . constant ( 1 ) reducer = ee . Reducer . mean () . combine ( ee . Reducer . stdDev (), None , True ) stats = ee . Dictionary ( img . reduceRegion ( reducer , region , scale , bestEffort = True , tileScale = 16 ) ) . toImage () mslarge = one . expression ( \"o - (b * s ) / (x - (a * m) + (b * s))\" , { \"o\" : one , \"x\" : img , \"a\" : stats . select ( \".*(mean)$\" ), \"b\" : stats . select ( \".*(stdDev)$\" ), \"m\" : mean_scale , \"s\" : std_scale , }, ) mask = img . gte ( stats . select ( \".*(mean)$\" ) . multiply ( mean_scale )) return mslarge . multiply ( mask ) . rename ( bandNames ) fuzzy_mssmall ( img , mean_scale , std_scale , region = None , scale = 90 ) Fuzzy membership through a function based on the mean and standard deviation, with the smaller values having a membership closer to 1. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzymssmall-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required mean_scaling float multiplier for the mean of the input values in the MSSmall function equation. required std_scaling float multiplier for the standard deviation of the input values in the MSSmall function equation. required region ee.Geometry | None region to calculate mean/stdDev image statistics, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_mssmall ( img , mean_scale , std_scale , region = None , scale = 90 ): \"\"\"Fuzzy membership through a function based on the mean and standard deviation, with the smaller values having a membership closer to 1. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzymssmall-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 mean_scaling (float): multiplier for the mean of the input values in the MSSmall function equation. std_scaling (float): multiplier for the standard deviation of the input values in the MSSmall function equation. region (ee.Geometry | None, optional): region to calculate mean/stdDev image statistics, if set to None will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" if region is None : region = img . geometry () bandNames = img . bandNames () mean_scale = ee . Image . constant ( mean_scale ) std_scale = ee . Image . constant ( std_scale ) one = ee . Image . constant ( 1 ) reducer = ee . Reducer . mean () . combine ( ee . Reducer . stdDev (), None , True ) stats = ee . Dictionary ( img . reduceRegion ( reducer , region , scale , bestEffort = True , tileScale = 16 ) ) . toImage () mssmall = one . expression ( \"(b * s ) / (x - (a * m) + (b * s))\" , { \"o\" : one , \"x\" : img , \"a\" : stats . select ( \".*(mean)$\" ), \"b\" : stats . select ( \".*(stdDev)$\" ), \"m\" : mean_scale , \"s\" : std_scale , }, ) mask = img . gte ( stats . select ( \".*(mean)$\" ) . multiply ( mean_scale )) return mssmall . multiply ( mask ) . rename ( bandNames ) fuzzy_near ( img , midpoint , spread ) Fuzzy membership function around a specific value which is defined by a user-defined midpoint (which is assigned a membership of 1), with a defined spread decreasing to zero. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylarge-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required midpoint float user-defined value with a fuzzy membership of 1 required spread float the spread of the Near function. The spread generally ranges from 0.001 to 1, with the larger the value results in a steeper distribution from the midpoint required Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_near ( img , midpoint , spread ): \"\"\"Fuzzy membership function around a specific value which is defined by a user-defined midpoint (which is assigned a membership of 1), with a defined spread decreasing to zero. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylarge-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 midpoint (float): user-defined value with a fuzzy membership of 1 spread (float): the spread of the Near function. The spread generally ranges from 0.001 to 1, with the larger the value results in a steeper distribution from the midpoint returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" bandNames = img . bandNames () spread = ee . Image . constant ( spread ) midpoint = ee . Image . constant ( midpoint ) one = ee . Image . constant ( 1 ) near = one . expression ( \"o / (o + s * (x - m)**2)\" , { \"o\" : one , \"x\" : img , \"s\" : spread , \"m\" : midpoint } ) return near . rename ( bandNames ) fuzzy_or ( img_list ) Fuzzy Or overlay returning the maximum value of the input images. This technique is useful when you want to identify the highest membership values for any of the input criteria Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_or ( img_list ): \"\"\"Fuzzy Or overlay returning the maximum value of the input images. This technique is useful when you want to identify the highest membership values for any of the input criteria args: img_list (list[ee.Image]): list of ee.Image objects to overlay together returns: ee.Image: output floating-point image with overlayed values \"\"\" in_img = ee . Image . cat ([ img_list ]) out_img = in_img . reduce ( ee . Reducer . max ()) . rename ( \"fuzzy_or\" ) return out_img fuzzy_product ( img_list ) Fuzzy Product overlay which multiplies each of the fuzzy values togetherfor all the input images. The resulting product will be less than any of the input, and when a member of many sets is input, the value can be very small. Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_product ( img_list ): \"\"\"Fuzzy Product overlay which multiplies each of the fuzzy values togetherfor all the input images. The resulting product will be less than any of the input, and when a member of many sets is input, the value can be very small. args: img_list (list[ee.Image]): list of ee.Image objects to overlay together returns: ee.Image: output floating-point image with overlayed values \"\"\" in_img = ee . Image . cat ([ img_list ]) out_img = in_img . reduce ( ee . Reducer . product ()) . rename ( \"fuzzy_product\" ) return out_img fuzzy_small ( img , midpoint , spread ) Fuzzy membership function with the smaller input values having membership closer to 1. The function is defined by a user-specified midpoint (which is assigned a membership of 0.5) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzysmall-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required midpoint float user-defined value with a fuzzy membership of 0.5 required spread float the spread of the Small function. The spread generally ranges from 1 to 10, with the larger the value results in a steeper distribution from the midpoint required Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_small ( img , midpoint , spread ): \"\"\"Fuzzy membership function with the smaller input values having membership closer to 1. The function is defined by a user-specified midpoint (which is assigned a membership of 0.5) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzysmall-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 midpoint (float): user-defined value with a fuzzy membership of 0.5 spread (float): the spread of the Small function. The spread generally ranges from 1 to 10, with the larger the value results in a steeper distribution from the midpoint returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" bandNames = img . bandNames () spread = ee . Image ( spread ) midpoint = ee . Image ( midpoint ) one = ee . Image . constant ( 1 ) small = one . expression ( \"o / (o + (x / m) ** s)\" , { \"o\" : one , \"x\" : img , \"s\" : spread , \"m\" : midpoint } ) return small . rename ( bandNames ) fuzzy_sum ( img_list ) Fuzzy Product overlay add the fuzzy values for all the input images. The resulting sum is an increasing linear combination function that is based on the number of criteria entered into the analysis Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_sum ( img_list ): \"\"\"Fuzzy Product overlay add the fuzzy values for all the input images. The resulting sum is an increasing linear combination function that is based on the number of criteria entered into the analysis args: img_list (list[ee.Image]): list of ee.Image objects to overlay together returns: ee.Image: output floating-point image with overlayed values \"\"\" one = ee . Image . constant ( 1 ) in_img = one . subtract ( ee . Image . cat ([ img_list ])) out_img = one . subtract ( in_img . reduce ( ee . Reducer . product ())) . rename ( \"fuzzy_sum\" ) return out_img fuzzy_weighted ( img_list , weights ) Overlays several rasters, multiplying each by their given weight and summing them together. Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required weights list[float] list of weight values to assign images, must be in order required Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_weighted ( img_list , weights ): \"\"\"Overlays several rasters, multiplying each by their given weight and summing them together. args: img_list (list[ee.Image]): list of ee.Image objects to overlay together weights (list[float]): list of weight values to assign images, must be in order returns: ee.Image: output floating-point image with overlayed values \"\"\" weights = ee . Image . constant ( weights ) in_img = ee . Image . cat ([ img_list ]) out_img = in_img . multiply ( weights ) . reduce ( ee . Reducer . sum ()) . rename ( \"fuzzy_weighted\" ) return out_img fuzzy_zmf ( img , min_val , max_val ) Z-function fuzzy membership generator. Source code in hydrafloods/fuzzy.py def fuzzy_zmf ( img , min_val , max_val ): \"\"\" Z-function fuzzy membership generator. \"\"\" bandNames = img . bandNames () if ~ isinstance ( min_val , ee . Number ): min_val = ee . Number ( min_val ) if ~ isinstance ( max_val , ee . Number ): max_val = ee . Number ( max_val ) invert = min_val . gt ( max_val ) a = ee . Image . constant ( ee . Algorithms . If ( invert , max_val , min_val )) b = ee . Image . constant ( ee . Algorithms . If ( invert , min_val , max_val )) zmf = ee . Image ( 1 ) m1 = a . lte ( img ) . And ( img . lt ( a . add ( b ) . divide ( 2 ))) y1 = img . expression ( \"1 - 2 * ((img - a) / (b - a)) ** 2\" , { \"img\" : img , \"a\" : a , \"b\" : b } ) m2 = a . add ( b ) . divide ( 2 ) . lte ( img ) . And ( img . lte ( b )) y2 = img . expression ( \"2 * ((img - b) / (b - a)) ** 2\" , { \"img\" : img , \"a\" : a , \"b\" : b }) m3 = img . gte ( b ) zmf = zmf . where ( m1 , y1 ) . where ( m2 , y2 ) . where ( m3 , ee . Image ( 0 )) zmf = ee . Image ( ee . Algorithms . If ( invert , ee . Image ( 1 ) . subtract ( zmf ), zmf )) return zmf . rename ( bandNames )","title":"fuzzy module"},{"location":"fuzzy/#hydrafloods.fuzzy","text":"","title":"fuzzy"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_and","text":"Fuzzy And overlay returning the minimum value of the input images. This technique is useful when you want to identify the least common denominator for the membership of all the input criteria Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_and ( img_list ): \"\"\"Fuzzy And overlay returning the minimum value of the input images. This technique is useful when you want to identify the least common denominator for the membership of all the input criteria args: img_list (list[ee.Image]): list of ee.Image objects to overlay together returns: ee.Image: output floating-point image with overlayed values \"\"\" in_img = ee . Image . cat ([ img_list ]) out_img = in_img . reduce ( ee . Reducer . min ()) . rename ( \"fuzzy_and\" ) return out_img","title":"fuzzy_and()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_gamma","text":"Fuzzy Gamma is an algebraic product of fuzzy Product and fuzzy Sum, which are both raised to the power of gamma. If the specified gamma is 1, the output is the same as fuzzy Sum; if gamma is 0, the output is the same as fuzzy Product Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required gamma float the gamma value to be used when weighting Product vs Sum 0.5 Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_gamma ( img_list , gamma = 0.5 ): \"\"\"Fuzzy Gamma is an algebraic product of fuzzy Product and fuzzy Sum, which are both raised to the power of gamma. If the specified gamma is 1, the output is the same as fuzzy Sum; if gamma is 0, the output is the same as fuzzy Product args: img_list (list[ee.Image]): list of ee.Image objects to overlay together gamma (float): the gamma value to be used when weighting Product vs Sum returns: ee.Image: output floating-point image with overlayed values \"\"\" gamma = ee . Image . constant ( gamma ) one = ee . Image . constant ( 1 ) a = fuzzy_sum ( img_list ) b = fuzzy_product ( img_list ) out_img = a . pow ( gamma ) . multiply ( b . pow ( one . subtract ( gamma ))) . rename ( \"fuzzy_gamma\" ) return out_img","title":"fuzzy_gamma()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_gaussian","text":"Fuzzy membership function through a Gaussian or normal distribution based around a user-specified midpoint (which is assigned a membership of 1) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzygaussian-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required midpoint float user-defined value with a fuzzy membership of 1 required spread float the spread of the Gaussian function. The spread generally ranges from 0.01 to 1, with the larger the value results in a steeper distribution around the midpoint required Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_gaussian ( img , midpoint , spread ): \"\"\"Fuzzy membership function through a Gaussian or normal distribution based around a user-specified midpoint (which is assigned a membership of 1) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzygaussian-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 midpoint (float): user-defined value with a fuzzy membership of 1 spread (float): the spread of the Gaussian function. The spread generally ranges from 0.01 to 1, with the larger the value results in a steeper distribution around the midpoint returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" bandNames = img . bandNames () spread = ee . Image . constant ( spread ) midpoint = ee . Image . constant ( midpoint ) e = ee . Image . constant ( math . e ) gauss = e . expression ( \"e ** (-s * (x-m)**2)\" , { \"e\" : e , \"x\" : img , \"s\" : spread , \"m\" : midpoint } ) return gauss . rename ( bandNames )","title":"fuzzy_gaussian()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_large","text":"Fuzzy membership function where the larger input values have membership closer to 1. The function is defined by a user-specified midpoint (which is assigned a membership of 0.5) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylarge-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required midpoint float user-defined value with a fuzzy membership of 0.5 required spread float the spread of the Large function. The spread generally ranges from 1 to 10, with the larger the value results in a steeper distribution from the midpoint required Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_large ( img , midpoint , spread ): \"\"\"Fuzzy membership function where the larger input values have membership closer to 1. The function is defined by a user-specified midpoint (which is assigned a membership of 0.5) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylarge-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 midpoint (float): user-defined value with a fuzzy membership of 0.5 spread (float): the spread of the Large function. The spread generally ranges from 1 to 10, with the larger the value results in a steeper distribution from the midpoint returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" bandNames = img . bandNames () spread = ee . Image ( spread ) midpoint = ee . Image ( midpoint ) one = ee . Image . constant ( 1 ) large = one . expression ( \"o / ( o + (x / m) ** (s * -1))\" , { \"o\" : one , \"x\" : img , \"s\" : spread , \"m\" : midpoint }, ) return large . rename ( bandNames )","title":"fuzzy_large()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_linear","text":"Fuzzy membership function through a linear transformation between the user-specified minimum value, a membership of 0, to the user-defined maximum value, which is assigned a membership of 1. If the minimum value is less than the maximum, the linear function will have a positive slope. If the minimum value is greater than the maximum, the linear function will have a negative slope. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylinear-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled linearly from 0 to 1 required minimum float The value that will have a membership of 0 required maximum float The value that will have a membership of 1 required Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_linear ( img , min_val , max_val ): \"\"\"Fuzzy membership function through a linear transformation between the user-specified minimum value, a membership of 0, to the user-defined maximum value, which is assigned a membership of 1. If the minimum value is less than the maximum, the linear function will have a positive slope. If the minimum value is greater than the maximum, the linear function will have a negative slope. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylinear-class.htm args: img (ee.Image): The input image whose values will be scaled linearly from 0 to 1 minimum (float): The value that will have a membership of 0 maximum (float): The value that will have a membership of 1 returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" bandNames = img . bandNames () if ~ isinstance ( min_val , ee . Number ): min_val = ee . Number ( min_val ) if ~ isinstance ( max_val , ee . Number ): max_val = ee . Number ( max_val ) invert = min_val . gt ( max_val ) minimum = ee . Algorithms . If ( invert , max_val , min_val ) maximum = ee . Algorithms . If ( invert , min_val , max_val ) linear = img . unitScale ( minimum , maximum ) linear = ee . Algorithms . If ( invert , ee . Image . constant ( 1 ) . subtract ( linear ), linear ) linear = ee . Image ( linear ) . clamp ( 0 , 1 ) return linear . rename ( bandNames )","title":"fuzzy_linear()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_mslarge","text":"Fuzzy membership through a function based on the mean and standard deviation, with the larger values having a membership closer to 1. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzymslarge-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required mean_scaling float multiplier for the mean of the input values in the MSLarge function equation. required std_scaling float multiplier for the standard deviation of the input values in the MSLarge function equation. required region ee.Geometry | None region to calculate mean/stdDev image statistics, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_mslarge ( img , mean_scaling , std_scaling , region = None , scale = 90 ): \"\"\"Fuzzy membership through a function based on the mean and standard deviation, with the larger values having a membership closer to 1. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzymslarge-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 mean_scaling (float): multiplier for the mean of the input values in the MSLarge function equation. std_scaling (float): multiplier for the standard deviation of the input values in the MSLarge function equation. region (ee.Geometry | None, optional): region to calculate mean/stdDev image statistics, if set to None will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" if region is None : region = img . geometry () bandNames = img . bandNames () mean_scale = ee . Image . constant ( mean_scaling ) std_scale = ee . Image . constant ( std_scaling ) one = ee . Image . constant ( 1 ) reducer = ee . Reducer . mean () . combine ( ee . Reducer . stdDev (), None , True ) stats = ee . Dictionary ( img . reduceRegion ( reducer , region , scale , bestEffort = True , tileScale = 16 ) ) . toImage () mslarge = one . expression ( \"o - (b * s ) / (x - (a * m) + (b * s))\" , { \"o\" : one , \"x\" : img , \"a\" : stats . select ( \".*(mean)$\" ), \"b\" : stats . select ( \".*(stdDev)$\" ), \"m\" : mean_scale , \"s\" : std_scale , }, ) mask = img . gte ( stats . select ( \".*(mean)$\" ) . multiply ( mean_scale )) return mslarge . multiply ( mask ) . rename ( bandNames )","title":"fuzzy_mslarge()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_mssmall","text":"Fuzzy membership through a function based on the mean and standard deviation, with the smaller values having a membership closer to 1. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzymssmall-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required mean_scaling float multiplier for the mean of the input values in the MSSmall function equation. required std_scaling float multiplier for the standard deviation of the input values in the MSSmall function equation. required region ee.Geometry | None region to calculate mean/stdDev image statistics, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_mssmall ( img , mean_scale , std_scale , region = None , scale = 90 ): \"\"\"Fuzzy membership through a function based on the mean and standard deviation, with the smaller values having a membership closer to 1. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzymssmall-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 mean_scaling (float): multiplier for the mean of the input values in the MSSmall function equation. std_scaling (float): multiplier for the standard deviation of the input values in the MSSmall function equation. region (ee.Geometry | None, optional): region to calculate mean/stdDev image statistics, if set to None will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" if region is None : region = img . geometry () bandNames = img . bandNames () mean_scale = ee . Image . constant ( mean_scale ) std_scale = ee . Image . constant ( std_scale ) one = ee . Image . constant ( 1 ) reducer = ee . Reducer . mean () . combine ( ee . Reducer . stdDev (), None , True ) stats = ee . Dictionary ( img . reduceRegion ( reducer , region , scale , bestEffort = True , tileScale = 16 ) ) . toImage () mssmall = one . expression ( \"(b * s ) / (x - (a * m) + (b * s))\" , { \"o\" : one , \"x\" : img , \"a\" : stats . select ( \".*(mean)$\" ), \"b\" : stats . select ( \".*(stdDev)$\" ), \"m\" : mean_scale , \"s\" : std_scale , }, ) mask = img . gte ( stats . select ( \".*(mean)$\" ) . multiply ( mean_scale )) return mssmall . multiply ( mask ) . rename ( bandNames )","title":"fuzzy_mssmall()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_near","text":"Fuzzy membership function around a specific value which is defined by a user-defined midpoint (which is assigned a membership of 1), with a defined spread decreasing to zero. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylarge-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required midpoint float user-defined value with a fuzzy membership of 1 required spread float the spread of the Near function. The spread generally ranges from 0.001 to 1, with the larger the value results in a steeper distribution from the midpoint required Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_near ( img , midpoint , spread ): \"\"\"Fuzzy membership function around a specific value which is defined by a user-defined midpoint (which is assigned a membership of 1), with a defined spread decreasing to zero. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzylarge-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 midpoint (float): user-defined value with a fuzzy membership of 1 spread (float): the spread of the Near function. The spread generally ranges from 0.001 to 1, with the larger the value results in a steeper distribution from the midpoint returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" bandNames = img . bandNames () spread = ee . Image . constant ( spread ) midpoint = ee . Image . constant ( midpoint ) one = ee . Image . constant ( 1 ) near = one . expression ( \"o / (o + s * (x - m)**2)\" , { \"o\" : one , \"x\" : img , \"s\" : spread , \"m\" : midpoint } ) return near . rename ( bandNames )","title":"fuzzy_near()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_or","text":"Fuzzy Or overlay returning the maximum value of the input images. This technique is useful when you want to identify the highest membership values for any of the input criteria Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_or ( img_list ): \"\"\"Fuzzy Or overlay returning the maximum value of the input images. This technique is useful when you want to identify the highest membership values for any of the input criteria args: img_list (list[ee.Image]): list of ee.Image objects to overlay together returns: ee.Image: output floating-point image with overlayed values \"\"\" in_img = ee . Image . cat ([ img_list ]) out_img = in_img . reduce ( ee . Reducer . max ()) . rename ( \"fuzzy_or\" ) return out_img","title":"fuzzy_or()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_product","text":"Fuzzy Product overlay which multiplies each of the fuzzy values togetherfor all the input images. The resulting product will be less than any of the input, and when a member of many sets is input, the value can be very small. Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_product ( img_list ): \"\"\"Fuzzy Product overlay which multiplies each of the fuzzy values togetherfor all the input images. The resulting product will be less than any of the input, and when a member of many sets is input, the value can be very small. args: img_list (list[ee.Image]): list of ee.Image objects to overlay together returns: ee.Image: output floating-point image with overlayed values \"\"\" in_img = ee . Image . cat ([ img_list ]) out_img = in_img . reduce ( ee . Reducer . product ()) . rename ( \"fuzzy_product\" ) return out_img","title":"fuzzy_product()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_small","text":"Fuzzy membership function with the smaller input values having membership closer to 1. The function is defined by a user-specified midpoint (which is assigned a membership of 0.5) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzysmall-class.htm Parameters: Name Type Description Default img ee.Image The input image whose values will be scaled from 0 to 1 required midpoint float user-defined value with a fuzzy membership of 0.5 required spread float the spread of the Small function. The spread generally ranges from 1 to 10, with the larger the value results in a steeper distribution from the midpoint required Returns: Type Description ee.Image output floating-point image with values ranging from 0 to 1 Source code in hydrafloods/fuzzy.py @decorators . keep_attrs def fuzzy_small ( img , midpoint , spread ): \"\"\"Fuzzy membership function with the smaller input values having membership closer to 1. The function is defined by a user-specified midpoint (which is assigned a membership of 0.5) with a defined spread. https://desktop.arcgis.com/en/arcmap/10.3/analyze/arcpy-spatial-analyst/fuzzysmall-class.htm args: img (ee.Image): The input image whose values will be scaled from 0 to 1 midpoint (float): user-defined value with a fuzzy membership of 0.5 spread (float): the spread of the Small function. The spread generally ranges from 1 to 10, with the larger the value results in a steeper distribution from the midpoint returns: ee.Image: output floating-point image with values ranging from 0 to 1 \"\"\" bandNames = img . bandNames () spread = ee . Image ( spread ) midpoint = ee . Image ( midpoint ) one = ee . Image . constant ( 1 ) small = one . expression ( \"o / (o + (x / m) ** s)\" , { \"o\" : one , \"x\" : img , \"s\" : spread , \"m\" : midpoint } ) return small . rename ( bandNames )","title":"fuzzy_small()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_sum","text":"Fuzzy Product overlay add the fuzzy values for all the input images. The resulting sum is an increasing linear combination function that is based on the number of criteria entered into the analysis Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_sum ( img_list ): \"\"\"Fuzzy Product overlay add the fuzzy values for all the input images. The resulting sum is an increasing linear combination function that is based on the number of criteria entered into the analysis args: img_list (list[ee.Image]): list of ee.Image objects to overlay together returns: ee.Image: output floating-point image with overlayed values \"\"\" one = ee . Image . constant ( 1 ) in_img = one . subtract ( ee . Image . cat ([ img_list ])) out_img = one . subtract ( in_img . reduce ( ee . Reducer . product ())) . rename ( \"fuzzy_sum\" ) return out_img","title":"fuzzy_sum()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_weighted","text":"Overlays several rasters, multiplying each by their given weight and summing them together. Parameters: Name Type Description Default img_list list[ee.Image] list of ee.Image objects to overlay together required weights list[float] list of weight values to assign images, must be in order required Returns: Type Description ee.Image output floating-point image with overlayed values Source code in hydrafloods/fuzzy.py def fuzzy_weighted ( img_list , weights ): \"\"\"Overlays several rasters, multiplying each by their given weight and summing them together. args: img_list (list[ee.Image]): list of ee.Image objects to overlay together weights (list[float]): list of weight values to assign images, must be in order returns: ee.Image: output floating-point image with overlayed values \"\"\" weights = ee . Image . constant ( weights ) in_img = ee . Image . cat ([ img_list ]) out_img = in_img . multiply ( weights ) . reduce ( ee . Reducer . sum ()) . rename ( \"fuzzy_weighted\" ) return out_img","title":"fuzzy_weighted()"},{"location":"fuzzy/#hydrafloods.fuzzy.fuzzy_zmf","text":"Z-function fuzzy membership generator. Source code in hydrafloods/fuzzy.py def fuzzy_zmf ( img , min_val , max_val ): \"\"\" Z-function fuzzy membership generator. \"\"\" bandNames = img . bandNames () if ~ isinstance ( min_val , ee . Number ): min_val = ee . Number ( min_val ) if ~ isinstance ( max_val , ee . Number ): max_val = ee . Number ( max_val ) invert = min_val . gt ( max_val ) a = ee . Image . constant ( ee . Algorithms . If ( invert , max_val , min_val )) b = ee . Image . constant ( ee . Algorithms . If ( invert , min_val , max_val )) zmf = ee . Image ( 1 ) m1 = a . lte ( img ) . And ( img . lt ( a . add ( b ) . divide ( 2 ))) y1 = img . expression ( \"1 - 2 * ((img - a) / (b - a)) ** 2\" , { \"img\" : img , \"a\" : a , \"b\" : b } ) m2 = a . add ( b ) . divide ( 2 ) . lte ( img ) . And ( img . lte ( b )) y2 = img . expression ( \"2 * ((img - b) / (b - a)) ** 2\" , { \"img\" : img , \"a\" : a , \"b\" : b }) m3 = img . gte ( b ) zmf = zmf . where ( m1 , y1 ) . where ( m2 , y2 ) . where ( m3 , ee . Image ( 0 )) zmf = ee . Image ( ee . Algorithms . If ( invert , ee . Image ( 1 ) . subtract ( zmf ), zmf )) return zmf . rename ( bandNames )","title":"fuzzy_zmf()"},{"location":"geeutils/","text":"hydrafloods.geeutils add_indices ( img , indices = [ 'mndwi' ]) Function to calculate multiple band indices and add to image as bands Parameters: Name Type Description Default img ee.Image image to calculate indices from required indices list[str] list of strings of index names to calculate. can use any named index function in geeutils. default = [\"mndwi\"] ['mndwi'] Returns: Type Description ee.Image image object with added indices Source code in hydrafloods/geeutils.py @decorators . keep_attrs def add_indices ( img , indices = [ \"mndwi\" ]): \"\"\"Function to calculate multiple band indices and add to image as bands args: img (ee.Image): image to calculate indices from indices (list[str], optional): list of strings of index names to calculate. can use any named index function in geeutils. default = [\"mndwi\"] returns: ee.Image: image object with added indices \"\"\" # loop through each index and append to images list cat_bands = [ img ] for index in indices : index_func = getattr ( all_indices , index ) cat_bands . append ( index_func ( img )) # return images as concatenated bands return ee . Image . cat ( cat_bands ) admin_bbox ( admin_name , level = 0 , max_error = 1000 ) Function to get a bounding box geometry of an administrative area Parameters: Name Type Description Default admin_name str US-recognized country name required max_error float,optional The maximum amount of error tolerated when performing any necessary reprojection. default = 100 1000 Returns: Type Description ee.Geometry geometry of country bounding box Source code in hydrafloods/geeutils.py def admin_bbox ( admin_name , level = 0 , max_error = 1000 ): \"\"\"Function to get a bounding box geometry of an administrative area args: admin_name (str): US-recognized country name max_error (float,optional): The maximum amount of error tolerated when performing any necessary reprojection. default = 100 returns: ee.Geometry: geometry of country bounding box \"\"\" if level not in range ( 0 , 3 ): raise ValueError ( f \"Administrative level is 0-2, provided level { level } is outside of range\" ) admin_bounds = ee . FeatureCollection ( \"FAO/GAUL/2015/level2\" ) return ( admin_bounds . filter ( ee . Filter . eq ( f \"ADM { level } _NAME\" , admin_name )) . geometry ( max_error ) . bounds ( max_error ) ) batch_export ( collection , collection_asset , region = None , prefix = None , suffix = None , scale = 1000 , crs = 'EPSG:4326' , pyramiding = None , export_type = 'toAsset' , folder = None , metadata = None , verbose = False ) Function to export each image in a collection Wraps export_image will set YYYYMMdd formatted time in file name Parameters: Name Type Description Default collection ee.ImageCollection image collection to export required collection_asset str image collection asset ID to export to required region ee.Geometry region to export image None prefix str prefix string to add before time info in name None suffix str suffix string to add after time info in name None scale int resolution in meters to export image to. default = 1000 1000 crs str epsg code to export image to. default = \"EPSG:4326\" 'EPSG:4326' pyramiding dict | None dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None None export_type str, optional) method by which to export the image. Default is 'toAsset', can also be 'toDrive'. 'toAsset' folder str | None target folder to export for 'toDrive'/ if None then export should go to root of Drive None metadata dict | None None verbose bool False Source code in hydrafloods/geeutils.py def batch_export ( collection , collection_asset , region = None , prefix = None , suffix = None , scale = 1000 , crs = \"EPSG:4326\" , pyramiding = None , export_type = \"toAsset\" , folder = None , metadata = None , verbose = False , ): \"\"\"Function to export each image in a collection Wraps `export_image` will set YYYYMMdd formatted time in file name args: collection (ee.ImageCollection): image collection to export collection_asset (str): image collection asset ID to export to region (ee.Geometry): region to export image prefix (str): prefix string to add before time info in name suffix (str): suffix string to add after time info in name scale (int, optional): resolution in meters to export image to. default = 1000 crs (str, optional): epsg code to export image to. default = \"EPSG:4326\" pyramiding (dict | None, optional): dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None export_type (str, optional) : method by which to export the image. Default is 'toAsset', can also be 'toDrive'. folder (str | None, optional): target folder to export for 'toDrive'/ if None then export should go to root of Drive metadata (dict | None, optional): verbose (bool, optional): \"\"\" if type ( collection ) is not ee . imagecollection . ImageCollection : try : collection = getattr ( collection , \"collection\" ) except Exception as e : raise TypeError ( \"argument collection needs to be either of type ee.ImageCollection \" \"or hydrafloods.hfCollection\" ) n = collection . size () exportImages = collection . sort ( \"system:time_start\" , False ) . toList ( n ) nIter = n . getInfo () for i in range ( nIter ): img = ee . Image ( exportImages . get ( i )) if metadata is not None : img = img . set ( metadata ) t = img . get ( \"system:time_start\" ) . getInfo () date = datetime . datetime . utcfromtimestamp ( t / 1e3 ) . strftime ( \"%Y%m %d %H%M%S\" ) if region is None : region = img . geometry () exportName = date if prefix is not None : exportName = f \" { prefix } _\" + exportName if suffix is not None : exportName = exportName + f \"_ { suffix } \" description = exportName if verbose : print ( f \"running export for { description } \" ) if not collection_asset . endswith ( \"/\" ): collection_asset += \"/\" exportName = collection_asset + description export_image ( img , region , asset_id = exportName , description = description , scale = scale , crs = crs , pyramiding = pyramiding , export_type = export_type , folder = folder , ) return country_bbox ( country_name , max_error = 1000 ) Function to get a bounding box geometry of a country Parameters: Name Type Description Default country_name str US-recognized country name required max_error float,optional The maximum amount of error tolerated when performing any necessary reprojection. default = 100 1000 Returns: Type Description ee.Geometry geometry of country bounding box Source code in hydrafloods/geeutils.py def country_bbox ( country_name , max_error = 1000 ): \"\"\"Function to get a bounding box geometry of a country args: country_name (str): US-recognized country name max_error (float,optional): The maximum amount of error tolerated when performing any necessary reprojection. default = 100 returns: ee.Geometry: geometry of country bounding box \"\"\" all_countries = ee . FeatureCollection ( \"USDOS/LSIB_SIMPLE/2017\" ) return ( all_countries . filter ( ee . Filter . eq ( \"country_na\" , country_name )) . geometry ( max_error ) . bounds ( max_error ) ) db_to_power ( img ) Function to convert SAR units from dB to power Parameters: Name Type Description Default img ee.Image SAR dB image to convert to power required Returns: Type Description ee.Image power SAR image Source code in hydrafloods/geeutils.py @decorators . keep_names @decorators . keep_attrs def db_to_power ( img ): \"\"\"Function to convert SAR units from dB to power args: img (ee.Image): SAR dB image to convert to power returns: ee.Image: power SAR image \"\"\" return ee . Image ( 10 ) . pow ( img . divide ( 10 )) export_image ( image , region , asset_id = None , description = None , scale = 1000 , crs = 'EPSG:4326' , pyramiding = None , export_type = 'toAsset' , folder = None ) Function to wrap image export with EE Python API Parameters: Name Type Description Default image ee.Image image to export required region ee.Geometry region to export image required asset_id str | None asset ID to export image to if None then asset_id will be a random string. default = None None description str | None description to identify image export/ if None then description will be random string. default = None None scale int resolution in meters to export image to. default = 1000 1000 crs str epsg code to export image to. default = \"EPSG:4326\" 'EPSG:4326' pyramiding dict | None dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None None export_type str, optional) method by which to export the image. Default is 'toAsset', can also be 'toDrive'. 'toAsset' folder str | None target folder to export for 'toDrive'/ if None then export should go to root of Drive None Source code in hydrafloods/geeutils.py def export_image ( image , region , asset_id = None , description = None , scale = 1000 , crs = \"EPSG:4326\" , pyramiding = None , export_type = \"toAsset\" , folder = None , ): \"\"\"Function to wrap image export with EE Python API args: image (ee.Image): image to export region (ee.Geometry): region to export image asset_id (str | None, optional): asset ID to export image to\\ if None then asset_id will be a random string. default = None description (str | None, optional): description to identify image export/ if None then description will be random string. default = None scale (int, optional): resolution in meters to export image to. default = 1000 crs (str, optional): epsg code to export image to. default = \"EPSG:4326\" pyramiding (dict | None, optional): dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None export_type (str, optional) : method by which to export the image. Default is 'toAsset', can also be 'toDrive'. folder (str | None, optional): target folder to export for 'toDrive'/ if None then export should go to root of Drive \"\"\" if ( asset_id is None ) or ( type ( asset_id ) != str ): asset_id = \"\" . join ( random . SystemRandom () . choice ( string . ascii_letters ) for _ in range ( 8 ) ) . lower () if ( description is None ) or ( type ( description ) != str ): description = \"\" . join ( random . SystemRandom () . choice ( string . ascii_letters ) for _ in range ( 8 ) ) . lower () if type ( export_type ) != str : raise TypeError ( f \"Input for export_type not a string, was a \" f \" { type ( export_type ) } .\" ) elif ( export_type != \"toAsset\" ) and ( export_type != \"toDrive\" ): raise ValueError ( \"Invalid input for export_type, must be \" '\"toAsset\" or \"toDrive\".' ) if ( folder is not None ) and ( type ( folder ) != str ): raise TypeError ( f \"Input for folder was not a string, was a \" f \" { type ( folder ) } \" ) # get serializable geometry for export export_region = region . bounds ( maxError = 10 ) . getInfo ()[ \"coordinates\" ] if pyramiding is None : pyramiding = { \".default\" : \"mean\" } # set export process if export_type == \"toAsset\" : export = ee . batch . Export . image . toAsset ( image , description = description , assetId = asset_id , scale = scale , region = export_region , maxPixels = 1e13 , crs = crs , pyramidingPolicy = pyramiding , ) elif export_type == \"toDrive\" : export = ee . batch . Export . image . toDrive ( image , description = description , folder = folder , scale = scale , region = export_region , maxPixels = 1e13 , crs = crs , ) # start export process export . start () return extract_bits ( image , start , end = None , new_name = None ) Function to conver qa bits to binary flag image Parameters: Name Type Description Default image ee.Image qa image to extract bit from required start int starting bit for flag required end int | None ending bit for flag, if None then will only use start bit. default = None None new_name str | None output name of resulting image, if None name will be {start}Bits. default = None None Returns: Type Description ee.Image image with extract bits Source code in hydrafloods/geeutils.py def extract_bits ( image , start , end = None , new_name = None ): \"\"\"Function to conver qa bits to binary flag image args: image (ee.Image): qa image to extract bit from start (int): starting bit for flag end (int | None, optional): ending bit for flag, if None then will only use start bit. default = None new_name (str | None, optional): output name of resulting image, if None name will be {start}Bits. default = None returns: ee.Image: image with extract bits \"\"\" newname = new_name if new_name is not None else f \" { start } Bits\" if ( start == end ) or ( end is None ): # perform a bit shift with bitwiseAnd return image . select ([ 0 ], [ newname ]) . bitwiseAnd ( 1 << start ) else : # Compute the bits we need to extract. pattern = 0 for i in range ( start , end ): pattern += int ( math . pow ( 2 , i )) # Return a single band image of the extracted QA bits, giving the band # a new name. return image . select ([ 0 ], [ newname ]) . bitwiseAnd ( pattern ) . rightShift ( start ) get_geoms ( img ) Helper function to get geometry from image Parameters: Name Type Description Default img ee.Image image to get geometry from required Returns: Type Description ee.Geometry geometry of image Source code in hydrafloods/geeutils.py def get_geoms ( img ): \"\"\"Helper function to get geometry from image args: img (ee.Image): image to get geometry from returns: ee.Geometry: geometry of image \"\"\" return img . geometry () power_to_db ( img ) Function to convert SAR units from power to dB Parameters: Name Type Description Default img ee.Image SAR power image to convert to dB required Returns: Type Description ee.Image dB SAR image Source code in hydrafloods/geeutils.py @decorators . keep_names @decorators . keep_attrs def power_to_db ( img ): \"\"\"Function to convert SAR units from power to dB args: img (ee.Image): SAR power image to convert to dB returns: ee.Image: dB SAR image \"\"\" return ee . Image ( 10 ) . multiply ( img . log10 ()) rescale ( img , scale = 0.0001 , offset = 0 ) Function to linearly rescale units using user defined scale and offset Parameters: Name Type Description Default img ee.Image image to rescale required scale float,optional scale value (i.e. slope of linear equation). default = 0.0001 0.0001 offset float offset value (i.e. y-intercept). default = 0 0 Returns: Type Description ee.Image rescaled image Source code in hydrafloods/geeutils.py @decorators . keep_names @decorators . keep_attrs def rescale ( img , scale = 0.0001 , offset = 0 ): \"\"\"Function to linearly rescale units using user defined scale and offset args: img (ee.Image): image to rescale scale (float,optional): scale value (i.e. slope of linear equation). default = 0.0001 offset (float, optional): offset value (i.e. y-intercept). default = 0 returns: ee.Image: rescaled image \"\"\" return img . multiply ( scale ) . add ( offset ) tile_region ( region , grid_size = 0.1 , intersect_geom = None , contain_geom = None , centroid_within = None ) Function to create a feature collection of tiles covering a region Parameters: Name Type Description Default region ee.Geometry region to create tile grid over required grid_size float resolution in decimal degrees to create tiles. default = 0.1 0.1 intersect_geom ee.Geometry | None geometry object to filter tiles that intesect with geometry useful for filtering tiles that are created over oceans with no data. default = None None contain_geom ee.Geometry | None geometry object to filter tiles that are contained within geometry useful for filtering tiles that are only in an area. default = None None Returns: Type Description ee.FeatureCollection collection of feature tiles at a given grid_size over a region Source code in hydrafloods/geeutils.py def tile_region ( region , grid_size = 0.1 , intersect_geom = None , contain_geom = None , centroid_within = None ): \"\"\"Function to create a feature collection of tiles covering a region args: region (ee.Geometry): region to create tile grid over grid_size (float, optional): resolution in decimal degrees to create tiles. default = 0.1 intersect_geom (ee.Geometry | None, optional): geometry object to filter tiles that intesect with geometry useful for filtering tiles that are created over oceans with no data. default = None contain_geom (ee.Geometry | None, optional): geometry object to filter tiles that are contained within geometry useful for filtering tiles that are only in an area. default = None returns: ee.FeatureCollection: collection of feature tiles at a given grid_size over a region \"\"\" # nesting grid construction along y and then x coordinates def constuctGrid ( i ): \"\"\"Closure function to contruct grid\"\"\" def contructXGrid ( j ): j = ee . Number ( j ) box = ( ee . Geometry . Rectangle ( [ j , i , j . add ( grid_res ), i . add ( grid_res )], \"epsg:4326\" , geodesic = False , ) ) if contain_geom is not None : keep = contain_geom . contains ( box , maxError = 500 ) elif intersect_geom is not None : keep = box . intersects ( intersect_geom , maxError = 500 ) elif centroid_within is not None : keep = box . centroid () . intersects ( centroid_within , maxError = 500 ) return ee . Feature ( box ,{ \"ul_lat\" : i . add ( grid_res ), \"ul_lon\" : j , \"keep\" : keep } ) i = ee . Number ( i ) out = ee . List . sequence ( west , east . subtract ( grid_res ), grid_res ) . map ( contructXGrid , True ) return out if ( contain_geom is not None ) and ( intersect_geom is not None ): raise ValueError ( \"contains and intersection keywords are mutually exclusive, please define only one\" ) bounds = region . bounds ( maxError = 1000 ) coords = ee . List ( bounds . coordinates () . get ( 0 )) grid_res = ee . Number ( grid_size ) west = ee . Number ( ee . List ( coords . get ( 0 )) . get ( 0 )) south = ee . Number ( ee . List ( coords . get ( 0 )) . get ( 1 )) east = ee . Number ( ee . List ( coords . get ( 2 )) . get ( 0 )) north = ee . Number ( ee . List ( coords . get ( 2 )) . get ( 1 )) west = ee . Algorithms . If ( west . lt ( 0 ), west . subtract ( west . mod ( grid_res ) . add ( grid_res )), west . subtract ( west . mod ( grid_res )), ) south = ee . Algorithms . If ( south . lt ( 0 ), south . subtract ( south . mod ( grid_res ) . add ( grid_res )), south . subtract ( south . mod ( grid_res )), ) east = east . add ( grid_res . subtract ( east . mod ( grid_res ))) north = north . add ( grid_res . subtract ( north . mod ( grid_res ))) grid = ee . FeatureCollection ( ee . List . sequence ( south , north . subtract ( grid_res ), grid_res ) . map ( constuctGrid ) . flatten () ) . filter ( ee . Filter . eq ( \"keep\" , True )) return grid","title":"geeutils module"},{"location":"geeutils/#hydrafloods.geeutils","text":"","title":"geeutils"},{"location":"geeutils/#hydrafloods.geeutils.add_indices","text":"Function to calculate multiple band indices and add to image as bands Parameters: Name Type Description Default img ee.Image image to calculate indices from required indices list[str] list of strings of index names to calculate. can use any named index function in geeutils. default = [\"mndwi\"] ['mndwi'] Returns: Type Description ee.Image image object with added indices Source code in hydrafloods/geeutils.py @decorators . keep_attrs def add_indices ( img , indices = [ \"mndwi\" ]): \"\"\"Function to calculate multiple band indices and add to image as bands args: img (ee.Image): image to calculate indices from indices (list[str], optional): list of strings of index names to calculate. can use any named index function in geeutils. default = [\"mndwi\"] returns: ee.Image: image object with added indices \"\"\" # loop through each index and append to images list cat_bands = [ img ] for index in indices : index_func = getattr ( all_indices , index ) cat_bands . append ( index_func ( img )) # return images as concatenated bands return ee . Image . cat ( cat_bands )","title":"add_indices()"},{"location":"geeutils/#hydrafloods.geeutils.admin_bbox","text":"Function to get a bounding box geometry of an administrative area Parameters: Name Type Description Default admin_name str US-recognized country name required max_error float,optional The maximum amount of error tolerated when performing any necessary reprojection. default = 100 1000 Returns: Type Description ee.Geometry geometry of country bounding box Source code in hydrafloods/geeutils.py def admin_bbox ( admin_name , level = 0 , max_error = 1000 ): \"\"\"Function to get a bounding box geometry of an administrative area args: admin_name (str): US-recognized country name max_error (float,optional): The maximum amount of error tolerated when performing any necessary reprojection. default = 100 returns: ee.Geometry: geometry of country bounding box \"\"\" if level not in range ( 0 , 3 ): raise ValueError ( f \"Administrative level is 0-2, provided level { level } is outside of range\" ) admin_bounds = ee . FeatureCollection ( \"FAO/GAUL/2015/level2\" ) return ( admin_bounds . filter ( ee . Filter . eq ( f \"ADM { level } _NAME\" , admin_name )) . geometry ( max_error ) . bounds ( max_error ) )","title":"admin_bbox()"},{"location":"geeutils/#hydrafloods.geeutils.batch_export","text":"Function to export each image in a collection Wraps export_image will set YYYYMMdd formatted time in file name Parameters: Name Type Description Default collection ee.ImageCollection image collection to export required collection_asset str image collection asset ID to export to required region ee.Geometry region to export image None prefix str prefix string to add before time info in name None suffix str suffix string to add after time info in name None scale int resolution in meters to export image to. default = 1000 1000 crs str epsg code to export image to. default = \"EPSG:4326\" 'EPSG:4326' pyramiding dict | None dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None None export_type str, optional) method by which to export the image. Default is 'toAsset', can also be 'toDrive'. 'toAsset' folder str | None target folder to export for 'toDrive'/ if None then export should go to root of Drive None metadata dict | None None verbose bool False Source code in hydrafloods/geeutils.py def batch_export ( collection , collection_asset , region = None , prefix = None , suffix = None , scale = 1000 , crs = \"EPSG:4326\" , pyramiding = None , export_type = \"toAsset\" , folder = None , metadata = None , verbose = False , ): \"\"\"Function to export each image in a collection Wraps `export_image` will set YYYYMMdd formatted time in file name args: collection (ee.ImageCollection): image collection to export collection_asset (str): image collection asset ID to export to region (ee.Geometry): region to export image prefix (str): prefix string to add before time info in name suffix (str): suffix string to add after time info in name scale (int, optional): resolution in meters to export image to. default = 1000 crs (str, optional): epsg code to export image to. default = \"EPSG:4326\" pyramiding (dict | None, optional): dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None export_type (str, optional) : method by which to export the image. Default is 'toAsset', can also be 'toDrive'. folder (str | None, optional): target folder to export for 'toDrive'/ if None then export should go to root of Drive metadata (dict | None, optional): verbose (bool, optional): \"\"\" if type ( collection ) is not ee . imagecollection . ImageCollection : try : collection = getattr ( collection , \"collection\" ) except Exception as e : raise TypeError ( \"argument collection needs to be either of type ee.ImageCollection \" \"or hydrafloods.hfCollection\" ) n = collection . size () exportImages = collection . sort ( \"system:time_start\" , False ) . toList ( n ) nIter = n . getInfo () for i in range ( nIter ): img = ee . Image ( exportImages . get ( i )) if metadata is not None : img = img . set ( metadata ) t = img . get ( \"system:time_start\" ) . getInfo () date = datetime . datetime . utcfromtimestamp ( t / 1e3 ) . strftime ( \"%Y%m %d %H%M%S\" ) if region is None : region = img . geometry () exportName = date if prefix is not None : exportName = f \" { prefix } _\" + exportName if suffix is not None : exportName = exportName + f \"_ { suffix } \" description = exportName if verbose : print ( f \"running export for { description } \" ) if not collection_asset . endswith ( \"/\" ): collection_asset += \"/\" exportName = collection_asset + description export_image ( img , region , asset_id = exportName , description = description , scale = scale , crs = crs , pyramiding = pyramiding , export_type = export_type , folder = folder , ) return","title":"batch_export()"},{"location":"geeutils/#hydrafloods.geeutils.country_bbox","text":"Function to get a bounding box geometry of a country Parameters: Name Type Description Default country_name str US-recognized country name required max_error float,optional The maximum amount of error tolerated when performing any necessary reprojection. default = 100 1000 Returns: Type Description ee.Geometry geometry of country bounding box Source code in hydrafloods/geeutils.py def country_bbox ( country_name , max_error = 1000 ): \"\"\"Function to get a bounding box geometry of a country args: country_name (str): US-recognized country name max_error (float,optional): The maximum amount of error tolerated when performing any necessary reprojection. default = 100 returns: ee.Geometry: geometry of country bounding box \"\"\" all_countries = ee . FeatureCollection ( \"USDOS/LSIB_SIMPLE/2017\" ) return ( all_countries . filter ( ee . Filter . eq ( \"country_na\" , country_name )) . geometry ( max_error ) . bounds ( max_error ) )","title":"country_bbox()"},{"location":"geeutils/#hydrafloods.geeutils.db_to_power","text":"Function to convert SAR units from dB to power Parameters: Name Type Description Default img ee.Image SAR dB image to convert to power required Returns: Type Description ee.Image power SAR image Source code in hydrafloods/geeutils.py @decorators . keep_names @decorators . keep_attrs def db_to_power ( img ): \"\"\"Function to convert SAR units from dB to power args: img (ee.Image): SAR dB image to convert to power returns: ee.Image: power SAR image \"\"\" return ee . Image ( 10 ) . pow ( img . divide ( 10 ))","title":"db_to_power()"},{"location":"geeutils/#hydrafloods.geeutils.export_image","text":"Function to wrap image export with EE Python API Parameters: Name Type Description Default image ee.Image image to export required region ee.Geometry region to export image required asset_id str | None asset ID to export image to if None then asset_id will be a random string. default = None None description str | None description to identify image export/ if None then description will be random string. default = None None scale int resolution in meters to export image to. default = 1000 1000 crs str epsg code to export image to. default = \"EPSG:4326\" 'EPSG:4326' pyramiding dict | None dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None None export_type str, optional) method by which to export the image. Default is 'toAsset', can also be 'toDrive'. 'toAsset' folder str | None target folder to export for 'toDrive'/ if None then export should go to root of Drive None Source code in hydrafloods/geeutils.py def export_image ( image , region , asset_id = None , description = None , scale = 1000 , crs = \"EPSG:4326\" , pyramiding = None , export_type = \"toAsset\" , folder = None , ): \"\"\"Function to wrap image export with EE Python API args: image (ee.Image): image to export region (ee.Geometry): region to export image asset_id (str | None, optional): asset ID to export image to\\ if None then asset_id will be a random string. default = None description (str | None, optional): description to identify image export/ if None then description will be random string. default = None scale (int, optional): resolution in meters to export image to. default = 1000 crs (str, optional): epsg code to export image to. default = \"EPSG:4326\" pyramiding (dict | None, optional): dictionary defining band pyramiding scheme. if None then \"mean\" will be used as default for all bands. default = None export_type (str, optional) : method by which to export the image. Default is 'toAsset', can also be 'toDrive'. folder (str | None, optional): target folder to export for 'toDrive'/ if None then export should go to root of Drive \"\"\" if ( asset_id is None ) or ( type ( asset_id ) != str ): asset_id = \"\" . join ( random . SystemRandom () . choice ( string . ascii_letters ) for _ in range ( 8 ) ) . lower () if ( description is None ) or ( type ( description ) != str ): description = \"\" . join ( random . SystemRandom () . choice ( string . ascii_letters ) for _ in range ( 8 ) ) . lower () if type ( export_type ) != str : raise TypeError ( f \"Input for export_type not a string, was a \" f \" { type ( export_type ) } .\" ) elif ( export_type != \"toAsset\" ) and ( export_type != \"toDrive\" ): raise ValueError ( \"Invalid input for export_type, must be \" '\"toAsset\" or \"toDrive\".' ) if ( folder is not None ) and ( type ( folder ) != str ): raise TypeError ( f \"Input for folder was not a string, was a \" f \" { type ( folder ) } \" ) # get serializable geometry for export export_region = region . bounds ( maxError = 10 ) . getInfo ()[ \"coordinates\" ] if pyramiding is None : pyramiding = { \".default\" : \"mean\" } # set export process if export_type == \"toAsset\" : export = ee . batch . Export . image . toAsset ( image , description = description , assetId = asset_id , scale = scale , region = export_region , maxPixels = 1e13 , crs = crs , pyramidingPolicy = pyramiding , ) elif export_type == \"toDrive\" : export = ee . batch . Export . image . toDrive ( image , description = description , folder = folder , scale = scale , region = export_region , maxPixels = 1e13 , crs = crs , ) # start export process export . start () return","title":"export_image()"},{"location":"geeutils/#hydrafloods.geeutils.extract_bits","text":"Function to conver qa bits to binary flag image Parameters: Name Type Description Default image ee.Image qa image to extract bit from required start int starting bit for flag required end int | None ending bit for flag, if None then will only use start bit. default = None None new_name str | None output name of resulting image, if None name will be {start}Bits. default = None None Returns: Type Description ee.Image image with extract bits Source code in hydrafloods/geeutils.py def extract_bits ( image , start , end = None , new_name = None ): \"\"\"Function to conver qa bits to binary flag image args: image (ee.Image): qa image to extract bit from start (int): starting bit for flag end (int | None, optional): ending bit for flag, if None then will only use start bit. default = None new_name (str | None, optional): output name of resulting image, if None name will be {start}Bits. default = None returns: ee.Image: image with extract bits \"\"\" newname = new_name if new_name is not None else f \" { start } Bits\" if ( start == end ) or ( end is None ): # perform a bit shift with bitwiseAnd return image . select ([ 0 ], [ newname ]) . bitwiseAnd ( 1 << start ) else : # Compute the bits we need to extract. pattern = 0 for i in range ( start , end ): pattern += int ( math . pow ( 2 , i )) # Return a single band image of the extracted QA bits, giving the band # a new name. return image . select ([ 0 ], [ newname ]) . bitwiseAnd ( pattern ) . rightShift ( start )","title":"extract_bits()"},{"location":"geeutils/#hydrafloods.geeutils.get_geoms","text":"Helper function to get geometry from image Parameters: Name Type Description Default img ee.Image image to get geometry from required Returns: Type Description ee.Geometry geometry of image Source code in hydrafloods/geeutils.py def get_geoms ( img ): \"\"\"Helper function to get geometry from image args: img (ee.Image): image to get geometry from returns: ee.Geometry: geometry of image \"\"\" return img . geometry ()","title":"get_geoms()"},{"location":"geeutils/#hydrafloods.geeutils.power_to_db","text":"Function to convert SAR units from power to dB Parameters: Name Type Description Default img ee.Image SAR power image to convert to dB required Returns: Type Description ee.Image dB SAR image Source code in hydrafloods/geeutils.py @decorators . keep_names @decorators . keep_attrs def power_to_db ( img ): \"\"\"Function to convert SAR units from power to dB args: img (ee.Image): SAR power image to convert to dB returns: ee.Image: dB SAR image \"\"\" return ee . Image ( 10 ) . multiply ( img . log10 ())","title":"power_to_db()"},{"location":"geeutils/#hydrafloods.geeutils.rescale","text":"Function to linearly rescale units using user defined scale and offset Parameters: Name Type Description Default img ee.Image image to rescale required scale float,optional scale value (i.e. slope of linear equation). default = 0.0001 0.0001 offset float offset value (i.e. y-intercept). default = 0 0 Returns: Type Description ee.Image rescaled image Source code in hydrafloods/geeutils.py @decorators . keep_names @decorators . keep_attrs def rescale ( img , scale = 0.0001 , offset = 0 ): \"\"\"Function to linearly rescale units using user defined scale and offset args: img (ee.Image): image to rescale scale (float,optional): scale value (i.e. slope of linear equation). default = 0.0001 offset (float, optional): offset value (i.e. y-intercept). default = 0 returns: ee.Image: rescaled image \"\"\" return img . multiply ( scale ) . add ( offset )","title":"rescale()"},{"location":"geeutils/#hydrafloods.geeutils.tile_region","text":"Function to create a feature collection of tiles covering a region Parameters: Name Type Description Default region ee.Geometry region to create tile grid over required grid_size float resolution in decimal degrees to create tiles. default = 0.1 0.1 intersect_geom ee.Geometry | None geometry object to filter tiles that intesect with geometry useful for filtering tiles that are created over oceans with no data. default = None None contain_geom ee.Geometry | None geometry object to filter tiles that are contained within geometry useful for filtering tiles that are only in an area. default = None None Returns: Type Description ee.FeatureCollection collection of feature tiles at a given grid_size over a region Source code in hydrafloods/geeutils.py def tile_region ( region , grid_size = 0.1 , intersect_geom = None , contain_geom = None , centroid_within = None ): \"\"\"Function to create a feature collection of tiles covering a region args: region (ee.Geometry): region to create tile grid over grid_size (float, optional): resolution in decimal degrees to create tiles. default = 0.1 intersect_geom (ee.Geometry | None, optional): geometry object to filter tiles that intesect with geometry useful for filtering tiles that are created over oceans with no data. default = None contain_geom (ee.Geometry | None, optional): geometry object to filter tiles that are contained within geometry useful for filtering tiles that are only in an area. default = None returns: ee.FeatureCollection: collection of feature tiles at a given grid_size over a region \"\"\" # nesting grid construction along y and then x coordinates def constuctGrid ( i ): \"\"\"Closure function to contruct grid\"\"\" def contructXGrid ( j ): j = ee . Number ( j ) box = ( ee . Geometry . Rectangle ( [ j , i , j . add ( grid_res ), i . add ( grid_res )], \"epsg:4326\" , geodesic = False , ) ) if contain_geom is not None : keep = contain_geom . contains ( box , maxError = 500 ) elif intersect_geom is not None : keep = box . intersects ( intersect_geom , maxError = 500 ) elif centroid_within is not None : keep = box . centroid () . intersects ( centroid_within , maxError = 500 ) return ee . Feature ( box ,{ \"ul_lat\" : i . add ( grid_res ), \"ul_lon\" : j , \"keep\" : keep } ) i = ee . Number ( i ) out = ee . List . sequence ( west , east . subtract ( grid_res ), grid_res ) . map ( contructXGrid , True ) return out if ( contain_geom is not None ) and ( intersect_geom is not None ): raise ValueError ( \"contains and intersection keywords are mutually exclusive, please define only one\" ) bounds = region . bounds ( maxError = 1000 ) coords = ee . List ( bounds . coordinates () . get ( 0 )) grid_res = ee . Number ( grid_size ) west = ee . Number ( ee . List ( coords . get ( 0 )) . get ( 0 )) south = ee . Number ( ee . List ( coords . get ( 0 )) . get ( 1 )) east = ee . Number ( ee . List ( coords . get ( 2 )) . get ( 0 )) north = ee . Number ( ee . List ( coords . get ( 2 )) . get ( 1 )) west = ee . Algorithms . If ( west . lt ( 0 ), west . subtract ( west . mod ( grid_res ) . add ( grid_res )), west . subtract ( west . mod ( grid_res )), ) south = ee . Algorithms . If ( south . lt ( 0 ), south . subtract ( south . mod ( grid_res ) . add ( grid_res )), south . subtract ( south . mod ( grid_res )), ) east = east . add ( grid_res . subtract ( east . mod ( grid_res ))) north = north . add ( grid_res . subtract ( north . mod ( grid_res ))) grid = ee . FeatureCollection ( ee . List . sequence ( south , north . subtract ( grid_res ), grid_res ) . map ( constuctGrid ) . flatten () ) . filter ( ee . Filter . eq ( \"keep\" , True )) return grid","title":"tile_region()"},{"location":"getting-started/","text":"Here are some quick examples of what you can do with hydrafloods . It is expected that the code is run in an interactive python session such as IPython or in a Jupyter Notebook as later code blocks will use variables from previous ones. To get started, first import the ee , trigger the Earth Engine authentication flow, and import the hydrafloods package: import ee ee . Initialize () import hydrafloods as hf Get a hf.Dataset You can access commonly used image collections on Earth Engine as a hydrafloods.Dataset to quickly filter by space and time as well as apply pre-written QA masking functions. # define a geographic region region = hf . country_bbox ( \"Cambodia\" ) # define start and end times start_time = \"2019-09-15\" end_time = \"2019-09-20\" # get the Sentinel 1 collection as a Dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) # print dataset info print ( s1 ) # print the number of images in Dataset print ( s1 . n_images ) # print a list of image acquisition dates for the Dataset print ( s1 . dates ) # access the actual ee.ImageCollection object ee_collection = s1 . collection The hydrafloods.Dataset object is a wrapper around an ee.ImageCollection by applying the spatial and temporal filtering upon initialization. This provides a quick and consistent access to imagery. The Dataset class also provides utility functionality to make working with and managing multiple image collections less verbose. There are many ways to interface with datasets (i.e. ImageCollections) using hydrafloods , more examples on merging or joining datasets can be found on the Using Dataset class page. Image processing The main purpose of hydrafloods is to lower the barrier to creating high-quality surface water maps, this requires image processing. Although the Dataset class wraps an Earth Engine image collection we can apply image processing functions using apply_func() by passing a function object. This method wraps a function that accepts an image as the first argument (which most hydrafloods image processing algorithms do) and maps it over the collection. For example, we would like to apply a speckle filter algorithm on SAR imagery. We can easily do this with the following code. # apply a speckle filtering algorithm on SAR imagery # here we will use the Gamma Map filter filtered = s1 . apply_func ( hf . gamma_map ) The previous example is synonymous with using s1.collection = s1.collection.map(hf.gamma_map) which access the image collection, applies the function, and sets the results to the s1.collection property. Although this technically works, using the apply_func() method is advantageous and preferred as it allows us to pass arbitrary keyword parameters to functions which we want to apply. For example, the water mapping algorithms found in hydrafloods.thresholding take many keyword parameters and we can customize function as in the following example. # apply the edge otsu surface water mapping # we apply this on the speckle filtered SAR data water_maps = filtered . apply_func ( hf . edge_otsu , initial_threshold =- 16 , thresh_no_data =- 20 , edge_buffer = 300 , scale = 250 ) It should be noted that using the apply_func() method will return a hydrafloods.Dataset where the collection property has the results of the function. One can access the ee.ImageCollection object and reduce to and image using the following code: # reduce the Dataset.collection property to an ee.Image water_img = water_maps . collection . reduce ( \"mode\" ) There are a variety of image processing functions available in hydrafloods , more information on specific algorithms can be found on the Algorithms page. Time series processing In addition to image processing, processing data in time is valuable. Therefore, hydrafloods has a specific module for time series processing, hydrafloods.timeseries , specifically for processing stacks of imagery in time. # import in the timeseries module from hydrafloods import timeseries Here we are going to take a longer time series of SAR imagery for 2019 so we have more data for our model: # define start and end times for one year in 2019 start_time = \"2019-01-01\" end_time = \"2020-01-01\" # get the Sentinel 1 collection as a Dataset # using Cambodia still as the region s1 = hf . Sentinel1 ( region , start_time , end_time ) Now that we have our time series of data, we can begin to model some temporal information. For example, we want to model a harmonic trend of SAR imagery to predict an image using time information. # fit a harmonic trend model on the VV band in time # use two harmonic cycles harmonics_weights = timeseries . fit_harmonic_trend ( s1 , dependent = 'VV' , n_cycles = 2 ) The result from fit_harmonic_trend() will be an image with many bands. Some bands are the coefficeint weights for prediction (i.e. cos_1, sin_1, or time), others can be awareness information such as number of valid observations used (i.e. n). So we will filter out the coefficient weight bands we need which are cos_n, sin_n and time which start with either \"c\", \"t\", or \"s\". Then get a dummy image with time information and apply the prediction. # extract bands needed for prediction harmonic_weights = harmonics_weights . select ( \"^c|t|s).*\" ) # get a dummy image with just time information for prediction # for flooding date in Oct 2019 dummy_img = timeseries . get_dummy_img ( \"2019-10-05\" ) # predict the VV values using the dummy img and computed harmonic coeffients prediction = ( timeseries . add_harmonic_coefs ( dummy_img ) . multiply ( harmonic_weights ) . reduce ( \"sum\" ) ) Time series functionality in hydrafloods is focused around modeling data in time, more information on the functions can be found in the timeseries module API reference Machine Learning hydrafloods also has a specific module for machine learning workflows with Earth Engine, hydrafloods.ml . # import in the ml module from hydrafloods import ml The aim with this module is to make high-quality machine learning workflows easier and less verbose when working with Earth Engine. However, we will will still need to access feature collection information to train models. Here we will define some parameters for an example: # define some parameters for the ml workflow we will use # define feature columns to use for training/prediction feature_names = [ 'VV' , 'VH' , 'ratio' , 'ndpi' ] # get a feature collection for training/testing fc = ( ee . FeatureCollection ( \"projects/servir-ee/assets/sar_wi_samples_20200825104400\" ) . randomColumn ( \"random\" ) ) # split the feature collection into training/testing datasets # good practice to do this training = fc . filter ( ee . Filter . lte ( \"random\" , 0.7 )) testing = fc . filter ( ee . Filter . gt ( \"random\" , 0.7 )) Now that we have our datasets and features defined, we can begin the workflow. Typically with machine learning one would perform a feature scaling to get all features within the same range, this helps with numerical stability, training speed, and model accuracy. This can be quite cumbersome to do efficiently in Earth Engine...however, the ml module allows us to scale and train in one shot. # scale training dataset and train random forest model # note this returns a trained ee.Classifier and dictionary to scale data later rf , scaling_dict = ml . random_forest_ee ( 25 , training , feature_names , 'mndwi' , scaling = \"standard\" , mode = \"regression\" ) This function returns a train random forest ee.Classifier and a ee.Dictionary with per band values needed to scale other feature collections or imagery as seen in the next example. Here we scale the testing dataset using the values from the training dataset and apply the model on the feature collection. # scale the testing dataset using the scaling values from training testing_norm = ml . standard_feature_scaling ( testing , scaling_dict , feature_names ) # apply random forest model on scaled test feature collection dataset y_test = testing_norm . classify ( rf , \"predicted\" ) Majority of the time we would like to apply the predictions on imagery and the ml module has functionality to perform the scaling for imagery easily. First we have to add the bands to dataset collection which the Sentinel1 dataset class has a custom method to add the VV/VH ratio and VV-VH normalized difference bands. # add bands for features used in RF model s1_features = s1 . apply_func ( hf . add_indices , indices = [ \"vv_vh_ratio\" , \"ndpi\" ]) # scale the bands using the scaling_dict s1_norm = s1_features . apply_func ( ml . standard_image_scaling , scaling_dict = scaling_dict , feature_names = feature_names ) # apply the prediction on the dataset predicted = s1_norm . apply_func ( lambda x : x . classify ( rf )) Again, most of the functionality around the hydrafloods.ml module is to make end-to-end machine learning work flows more straightforward. Please see the ml module documentation for information on functions.","title":"Getting Started"},{"location":"getting-started/#get-a-hfdataset","text":"You can access commonly used image collections on Earth Engine as a hydrafloods.Dataset to quickly filter by space and time as well as apply pre-written QA masking functions. # define a geographic region region = hf . country_bbox ( \"Cambodia\" ) # define start and end times start_time = \"2019-09-15\" end_time = \"2019-09-20\" # get the Sentinel 1 collection as a Dataset s1 = hf . Sentinel1 ( region , start_time , end_time ) # print dataset info print ( s1 ) # print the number of images in Dataset print ( s1 . n_images ) # print a list of image acquisition dates for the Dataset print ( s1 . dates ) # access the actual ee.ImageCollection object ee_collection = s1 . collection The hydrafloods.Dataset object is a wrapper around an ee.ImageCollection by applying the spatial and temporal filtering upon initialization. This provides a quick and consistent access to imagery. The Dataset class also provides utility functionality to make working with and managing multiple image collections less verbose. There are many ways to interface with datasets (i.e. ImageCollections) using hydrafloods , more examples on merging or joining datasets can be found on the Using Dataset class page.","title":"Get a hf.Dataset"},{"location":"getting-started/#image-processing","text":"The main purpose of hydrafloods is to lower the barrier to creating high-quality surface water maps, this requires image processing. Although the Dataset class wraps an Earth Engine image collection we can apply image processing functions using apply_func() by passing a function object. This method wraps a function that accepts an image as the first argument (which most hydrafloods image processing algorithms do) and maps it over the collection. For example, we would like to apply a speckle filter algorithm on SAR imagery. We can easily do this with the following code. # apply a speckle filtering algorithm on SAR imagery # here we will use the Gamma Map filter filtered = s1 . apply_func ( hf . gamma_map ) The previous example is synonymous with using s1.collection = s1.collection.map(hf.gamma_map) which access the image collection, applies the function, and sets the results to the s1.collection property. Although this technically works, using the apply_func() method is advantageous and preferred as it allows us to pass arbitrary keyword parameters to functions which we want to apply. For example, the water mapping algorithms found in hydrafloods.thresholding take many keyword parameters and we can customize function as in the following example. # apply the edge otsu surface water mapping # we apply this on the speckle filtered SAR data water_maps = filtered . apply_func ( hf . edge_otsu , initial_threshold =- 16 , thresh_no_data =- 20 , edge_buffer = 300 , scale = 250 ) It should be noted that using the apply_func() method will return a hydrafloods.Dataset where the collection property has the results of the function. One can access the ee.ImageCollection object and reduce to and image using the following code: # reduce the Dataset.collection property to an ee.Image water_img = water_maps . collection . reduce ( \"mode\" ) There are a variety of image processing functions available in hydrafloods , more information on specific algorithms can be found on the Algorithms page.","title":"Image processing"},{"location":"getting-started/#time-series-processing","text":"In addition to image processing, processing data in time is valuable. Therefore, hydrafloods has a specific module for time series processing, hydrafloods.timeseries , specifically for processing stacks of imagery in time. # import in the timeseries module from hydrafloods import timeseries Here we are going to take a longer time series of SAR imagery for 2019 so we have more data for our model: # define start and end times for one year in 2019 start_time = \"2019-01-01\" end_time = \"2020-01-01\" # get the Sentinel 1 collection as a Dataset # using Cambodia still as the region s1 = hf . Sentinel1 ( region , start_time , end_time ) Now that we have our time series of data, we can begin to model some temporal information. For example, we want to model a harmonic trend of SAR imagery to predict an image using time information. # fit a harmonic trend model on the VV band in time # use two harmonic cycles harmonics_weights = timeseries . fit_harmonic_trend ( s1 , dependent = 'VV' , n_cycles = 2 ) The result from fit_harmonic_trend() will be an image with many bands. Some bands are the coefficeint weights for prediction (i.e. cos_1, sin_1, or time), others can be awareness information such as number of valid observations used (i.e. n). So we will filter out the coefficient weight bands we need which are cos_n, sin_n and time which start with either \"c\", \"t\", or \"s\". Then get a dummy image with time information and apply the prediction. # extract bands needed for prediction harmonic_weights = harmonics_weights . select ( \"^c|t|s).*\" ) # get a dummy image with just time information for prediction # for flooding date in Oct 2019 dummy_img = timeseries . get_dummy_img ( \"2019-10-05\" ) # predict the VV values using the dummy img and computed harmonic coeffients prediction = ( timeseries . add_harmonic_coefs ( dummy_img ) . multiply ( harmonic_weights ) . reduce ( \"sum\" ) ) Time series functionality in hydrafloods is focused around modeling data in time, more information on the functions can be found in the timeseries module API reference","title":"Time series processing"},{"location":"getting-started/#machine-learning","text":"hydrafloods also has a specific module for machine learning workflows with Earth Engine, hydrafloods.ml . # import in the ml module from hydrafloods import ml The aim with this module is to make high-quality machine learning workflows easier and less verbose when working with Earth Engine. However, we will will still need to access feature collection information to train models. Here we will define some parameters for an example: # define some parameters for the ml workflow we will use # define feature columns to use for training/prediction feature_names = [ 'VV' , 'VH' , 'ratio' , 'ndpi' ] # get a feature collection for training/testing fc = ( ee . FeatureCollection ( \"projects/servir-ee/assets/sar_wi_samples_20200825104400\" ) . randomColumn ( \"random\" ) ) # split the feature collection into training/testing datasets # good practice to do this training = fc . filter ( ee . Filter . lte ( \"random\" , 0.7 )) testing = fc . filter ( ee . Filter . gt ( \"random\" , 0.7 )) Now that we have our datasets and features defined, we can begin the workflow. Typically with machine learning one would perform a feature scaling to get all features within the same range, this helps with numerical stability, training speed, and model accuracy. This can be quite cumbersome to do efficiently in Earth Engine...however, the ml module allows us to scale and train in one shot. # scale training dataset and train random forest model # note this returns a trained ee.Classifier and dictionary to scale data later rf , scaling_dict = ml . random_forest_ee ( 25 , training , feature_names , 'mndwi' , scaling = \"standard\" , mode = \"regression\" ) This function returns a train random forest ee.Classifier and a ee.Dictionary with per band values needed to scale other feature collections or imagery as seen in the next example. Here we scale the testing dataset using the values from the training dataset and apply the model on the feature collection. # scale the testing dataset using the scaling values from training testing_norm = ml . standard_feature_scaling ( testing , scaling_dict , feature_names ) # apply random forest model on scaled test feature collection dataset y_test = testing_norm . classify ( rf , \"predicted\" ) Majority of the time we would like to apply the predictions on imagery and the ml module has functionality to perform the scaling for imagery easily. First we have to add the bands to dataset collection which the Sentinel1 dataset class has a custom method to add the VV/VH ratio and VV-VH normalized difference bands. # add bands for features used in RF model s1_features = s1 . apply_func ( hf . add_indices , indices = [ \"vv_vh_ratio\" , \"ndpi\" ]) # scale the bands using the scaling_dict s1_norm = s1_features . apply_func ( ml . standard_image_scaling , scaling_dict = scaling_dict , feature_names = feature_names ) # apply the prediction on the dataset predicted = s1_norm . apply_func ( lambda x : x . classify ( rf )) Again, most of the functionality around the hydrafloods.ml module is to make end-to-end machine learning work flows more straightforward. Please see the ml module documentation for information on functions.","title":"Machine Learning"},{"location":"indices/","text":"hydrafloods.indices aewinsh ( img ) Function to calculate automated water extraction index (AEWI) no shadow Expects image has \"green\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate AEWInsh required Returns: Type Description ee.Image AEWInsh image Source code in hydrafloods/indices.py @decorators . keep_attrs def aewinsh ( img ): \"\"\"Function to calculate automated water extraction index (AEWI) no shadow Expects image has \"green\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate AEWInsh returns: ee.Image: AEWInsh image \"\"\" return img . expression ( \"4.0 * (g-s) - ((0.25*n) + (2.75*w))\" , { \"g\" : img . select ( \"green\" ), \"s\" : img . select ( \"swir1\" ), \"n\" : img . select ( \"nir\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"aewinsh\" ) aewish ( img ) Function to calculate automated water extraction index (AEWI) shadow Expects image has \"blue\", \"green\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate AEWIsh required Returns: Type Description ee.Image AEWIsh image Source code in hydrafloods/indices.py @decorators . keep_attrs def aewish ( img ): \"\"\"Function to calculate automated water extraction index (AEWI) shadow Expects image has \"blue\", \"green\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate AEWIsh returns: ee.Image: AEWIsh image \"\"\" return img . expression ( \"b+2.5*g-1.5*(n+s)-0.25*w\" , { \"b\" : img . select ( \"blue\" ), \"g\" : img . select ( \"green\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"aewish\" ) evi ( img ) Function to calculate Enhanced Vegetation Index (EVI). Expects image has \"blue\", \"red\", and \"nir\" bands. Parameters: Name Type Description Default img ee.Image image to calculate EVI required Returns: Type Description ee.Image EVI image Source code in hydrafloods/indices.py @decorators . keep_attrs def evi ( img ): \"\"\"Function to calculate Enhanced Vegetation Index (EVI). Expects image has \"blue\", \"red\", and \"nir\" bands. args: img (ee.Image): image to calculate EVI returns: ee.Image: EVI image \"\"\" return img . expression ( \"2.5*(nir-red)/(nir+6.0*red-7.5*blue+1)\" , { \"blue\" : img . select ( \"blue\" ), \"red\" : img . select ( \"red\" ), \"nir\" : img . select ( \"nir\" ), }, ) . rename ( \"evi\" ) gwi ( img ) Function to calculate general water index (GWI) Expects image has \"green\", \"red\", \"nir\", and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate GWI required Returns: Type Description ee.Image GWI image Source code in hydrafloods/indices.py @decorators . keep_attrs def gwi ( img ): \"\"\"Function to calculate general water index (GWI) Expects image has \"green\", \"red\", \"nir\", and \"swir1\" bands. args: img (ee.Image): image to calculate GWI returns: ee.Image: GWI image \"\"\" return img . expression ( \"(g+r)-(n+s)\" , { \"g\" : img . select ( \"green\" ), \"r\" : img . select ( \"red\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), }, ) . rename ( \"gwi\" ) lswi ( img ) Function to calculate land surface water index (LSWI). Expects image has \"nir\" and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate LSWI required Returns: Type Description ee.Image LSWI image Source code in hydrafloods/indices.py @decorators . keep_attrs def lswi ( img ): \"\"\"Function to calculate land surface water index (LSWI). Expects image has \"nir\" and \"swir1\" bands. args: img (ee.Image): image to calculate LSWI returns: ee.Image: LSWI image \"\"\" return img . expression ( \"(nir-swir)/(nir+swir)\" , { \"nir\" : img . select ( \"nir\" ), \"swir\" : img . select ( \"swir1\" )} ) . rename ( \"lswi\" ) mbwi ( img , factor = 3 ) Function to calculate multi band water index (MBWI). Expects image has \"green\", \"red\", \"nir\", \"swir1\", and \"swir2\" bands. https://doi.org/10.1016/j.jag.2018.01.018 Parameters: Name Type Description Default img ee.Image image to calculate MBWI required factor int,optional factor to scale green band for index. default=3 3 Returns: Type Description ee.Image MBWI image Source code in hydrafloods/indices.py @decorators . keep_attrs def mbwi ( img , factor = 3 ): \"\"\"Function to calculate multi band water index (MBWI). Expects image has \"green\", \"red\", \"nir\", \"swir1\", and \"swir2\" bands. https://doi.org/10.1016/j.jag.2018.01.018 args: img (ee.Image): image to calculate MBWI factor (int,optional): factor to scale green band for index. default=3 returns: ee.Image: MBWI image \"\"\" return img . expression ( \"((factor*green)-red-nir-swir1-swir2)\" , { \"factor\" : factor , \"green\" : img . select ( \"green\" ), \"red\" : img . select ( \"red\" ), \"nir\" : img . select ( \"nir\" ), \"swir1\" : img . select ( \"swir1\" ), \"swir2\" : img . select ( \"swir2\" ), }, ) . rename ( \"mbwi\" ) mndwi ( img ) Function to calculate modified Difference Water Index (MNDWI). Expects image has \"green\" and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate MNDWI required Returns: Type Description ee.Image MNDWI image Source code in hydrafloods/indices.py @decorators . keep_attrs def mndwi ( img ): \"\"\"Function to calculate modified Difference Water Index (MNDWI). Expects image has \"green\" and \"swir1\" bands. args: img (ee.Image): image to calculate MNDWI returns: ee.Image: MNDWI image \"\"\" return img . normalizedDifference ([ \"green\" , \"swir1\" ]) . rename ( \"mndwi\" ) mwi ( img ) Function to calculate the Modified Water Index (MWI) Expect image has \"green\", \"red\", \"nir\", and \"swir1\" bands https://doi.org/10.1007/978-3-662-45737-5_51 , https://ieeexplore.ieee.org/document/9011209 Source code in hydrafloods/indices.py @decorators . keep_attrs def mwi ( img ): \"\"\"Function to calculate the Modified Water Index (MWI) Expect image has \"green\", \"red\", \"nir\", and \"swir1\" bands https://doi.org/10.1007/978-3-662-45737-5_51 , https://ieeexplore.ieee.org/document/9011209 \"\"\" # calculate ndvi ndvi_img = ndvi ( img ) # calculate mndwi mndwi_img = mndwi ( img ) # mwi = 1 - (ndvi - mndwi) return ee . Image . constant ( 1 ) . subtract ( ndvi_img . subtract ( mndwi_img )) . rename ( \"mwi\" ) ndpi ( img ) Function to calculate nomalized difference polarization index (NDPI). Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NDPI required Returns: Type Description ee.Image NPDI image Source code in hydrafloods/indices.py @decorators . keep_attrs def ndpi ( img ): \"\"\"Function to calculate nomalized difference polarization index (NDPI). Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to calculate NDPI returns: ee.Image: NPDI image \"\"\" return img . expression ( \"(VV-VH)/(VV+VH)\" , { \"VV\" : img . select ( \"VV\" ), \"VH\" : img . select ( \"VH\" )} ) . rename ( \"ndpi\" ) ndvi ( img ) Function to calculate Normalized Difference Vegetation Index (NDVI). Expects image has \"nir\" and \"red\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NDVI required Returns: Type Description ee.Image NDVI image Source code in hydrafloods/indices.py @decorators . keep_attrs def ndvi ( img ): \"\"\"Function to calculate Normalized Difference Vegetation Index (NDVI). Expects image has \"nir\" and \"red\" bands. args: img (ee.Image): image to calculate NDVI returns: ee.Image: NDVI image \"\"\" return img . normalizedDifference ([ \"nir\" , \"red\" ]) . rename ( \"ndvi\" ) nvhi ( img ) Function to calculate nomalized VH index (NVHI). Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NVHI required Returns: Type Description ee.Image NVHI image Source code in hydrafloods/indices.py @decorators . keep_attrs def nvhi ( img ): \"\"\"Function to calculate nomalized VH index (NVHI). Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to calculate NVHI returns: ee.Image: NVHI image \"\"\" return img . expression ( \"(VH)/(VV+VH)\" , { \"VV\" : img . select ( \"VV\" ), \"VH\" : img . select ( \"VH\" )} ) . rename ( \"nvhi\" ) nvvi ( img ) Function to calculate nomalized VV index (NVVI). Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NVVI required Returns: Type Description ee.Image NVVI image Source code in hydrafloods/indices.py @decorators . keep_attrs def nvvi ( img ): \"\"\"Function to calculate nomalized VV index (NVVI). Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to calculate NVVI returns: ee.Image: NVVI image \"\"\" return img . expression ( \"(VV)/(VV+VH)\" , { \"VV\" : img . select ( \"VV\" ), \"VH\" : img . select ( \"VH\" )} ) . rename ( \"nvvi\" ) nwi ( img ) Function to calculate new water index (NWI). Expects image has \"blue\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NWI required Returns: Type Description ee.Image NWI image Source code in hydrafloods/indices.py @decorators . keep_attrs def nwi ( img ): \"\"\"Function to calculate new water index (NWI). Expects image has \"blue\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate NWI returns: ee.Image: NWI image \"\"\" return img . expression ( \"((b-(n+s+w))/(b+(n+s+w)))\" , { \"b\" : img . select ( \"blue\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"nwi\" ) rfi ( img ) Function to calculate SAR RFI index. Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to calculate RFI required Returns: Type Description ee.Image RFI image Source code in hydrafloods/indices.py @decorators . keep_attrs def rfi ( img ): \"\"\"Function to calculate SAR RFI index. Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to calculate RFI returns: ee.Image: RFI image \"\"\" return img . expression ( \"(4*VH)/(VV+VH)\" , { \"VV\" : img . select ( \"VV\" ), \"VH\" : img . select ( \"VH\" )} ) . rename ( \"rfi\" ) vv_vh_abs_sum ( img ) Function to calculate the absolute value of the sum of VV and VH bands. Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to apply calculation required Returns: Type Description ee.Image image name 'vv_vh_abs_sum' Source code in hydrafloods/indices.py @decorators . keep_attrs def vv_vh_abs_sum ( img ): \"\"\"Function to calculate the absolute value of the sum of VV and VH bands. Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to apply calculation returns: ee.Image: image name 'vv_vh_abs_sum' \"\"\" return img . select ( \"VV\" ) . add ( img . select ( \"VH\" )) . abs () . rename ( \"vv_vh_abs_sum\" ) vv_vh_ratio ( img ) Function to calculate ratio between VV and VH bands. Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to calculate ration required Returns: Type Description ee.Image ratio image name 'ratio' Source code in hydrafloods/indices.py @decorators . keep_attrs def vv_vh_ratio ( img ): \"\"\"Function to calculate ratio between VV and VH bands. Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to calculate ration returns: ee.Image: ratio image name 'ratio' \"\"\" return img . expression ( \"(VV/VH)\" , { \"VV\" : img . select ( \"VV\" ), \"VH\" : img . select ( \"VH\" )} ) . rename ( \"ratio\" ) wri ( img ) Function to calculate water ratio index (WRI). Expects image has \"green\", \"red\", \"nir\" and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate WRI required Returns: Type Description ee.Image WRI image Source code in hydrafloods/indices.py @decorators . keep_attrs def wri ( img ): \"\"\"Function to calculate water ratio index (WRI). Expects image has \"green\", \"red\", \"nir\" and \"swir1\" bands. args: img (ee.Image): image to calculate WRI returns: ee.Image: WRI image \"\"\" return img . expression ( \"(green+red)/(nir+swir)\" , { \"green\" : img . select ( \"green\" ), \"red\" : img . select ( \"red\" ), \"nir\" : img . select ( \"nir\" ), \"swir\" : img . select ( \"swir1\" ), }, ) . rename ( \"wri\" )","title":"indices module"},{"location":"indices/#hydrafloods.indices","text":"","title":"indices"},{"location":"indices/#hydrafloods.indices.aewinsh","text":"Function to calculate automated water extraction index (AEWI) no shadow Expects image has \"green\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate AEWInsh required Returns: Type Description ee.Image AEWInsh image Source code in hydrafloods/indices.py @decorators . keep_attrs def aewinsh ( img ): \"\"\"Function to calculate automated water extraction index (AEWI) no shadow Expects image has \"green\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate AEWInsh returns: ee.Image: AEWInsh image \"\"\" return img . expression ( \"4.0 * (g-s) - ((0.25*n) + (2.75*w))\" , { \"g\" : img . select ( \"green\" ), \"s\" : img . select ( \"swir1\" ), \"n\" : img . select ( \"nir\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"aewinsh\" )","title":"aewinsh()"},{"location":"indices/#hydrafloods.indices.aewish","text":"Function to calculate automated water extraction index (AEWI) shadow Expects image has \"blue\", \"green\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate AEWIsh required Returns: Type Description ee.Image AEWIsh image Source code in hydrafloods/indices.py @decorators . keep_attrs def aewish ( img ): \"\"\"Function to calculate automated water extraction index (AEWI) shadow Expects image has \"blue\", \"green\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate AEWIsh returns: ee.Image: AEWIsh image \"\"\" return img . expression ( \"b+2.5*g-1.5*(n+s)-0.25*w\" , { \"b\" : img . select ( \"blue\" ), \"g\" : img . select ( \"green\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"aewish\" )","title":"aewish()"},{"location":"indices/#hydrafloods.indices.evi","text":"Function to calculate Enhanced Vegetation Index (EVI). Expects image has \"blue\", \"red\", and \"nir\" bands. Parameters: Name Type Description Default img ee.Image image to calculate EVI required Returns: Type Description ee.Image EVI image Source code in hydrafloods/indices.py @decorators . keep_attrs def evi ( img ): \"\"\"Function to calculate Enhanced Vegetation Index (EVI). Expects image has \"blue\", \"red\", and \"nir\" bands. args: img (ee.Image): image to calculate EVI returns: ee.Image: EVI image \"\"\" return img . expression ( \"2.5*(nir-red)/(nir+6.0*red-7.5*blue+1)\" , { \"blue\" : img . select ( \"blue\" ), \"red\" : img . select ( \"red\" ), \"nir\" : img . select ( \"nir\" ), }, ) . rename ( \"evi\" )","title":"evi()"},{"location":"indices/#hydrafloods.indices.gwi","text":"Function to calculate general water index (GWI) Expects image has \"green\", \"red\", \"nir\", and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate GWI required Returns: Type Description ee.Image GWI image Source code in hydrafloods/indices.py @decorators . keep_attrs def gwi ( img ): \"\"\"Function to calculate general water index (GWI) Expects image has \"green\", \"red\", \"nir\", and \"swir1\" bands. args: img (ee.Image): image to calculate GWI returns: ee.Image: GWI image \"\"\" return img . expression ( \"(g+r)-(n+s)\" , { \"g\" : img . select ( \"green\" ), \"r\" : img . select ( \"red\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), }, ) . rename ( \"gwi\" )","title":"gwi()"},{"location":"indices/#hydrafloods.indices.lswi","text":"Function to calculate land surface water index (LSWI). Expects image has \"nir\" and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate LSWI required Returns: Type Description ee.Image LSWI image Source code in hydrafloods/indices.py @decorators . keep_attrs def lswi ( img ): \"\"\"Function to calculate land surface water index (LSWI). Expects image has \"nir\" and \"swir1\" bands. args: img (ee.Image): image to calculate LSWI returns: ee.Image: LSWI image \"\"\" return img . expression ( \"(nir-swir)/(nir+swir)\" , { \"nir\" : img . select ( \"nir\" ), \"swir\" : img . select ( \"swir1\" )} ) . rename ( \"lswi\" )","title":"lswi()"},{"location":"indices/#hydrafloods.indices.mbwi","text":"Function to calculate multi band water index (MBWI). Expects image has \"green\", \"red\", \"nir\", \"swir1\", and \"swir2\" bands. https://doi.org/10.1016/j.jag.2018.01.018 Parameters: Name Type Description Default img ee.Image image to calculate MBWI required factor int,optional factor to scale green band for index. default=3 3 Returns: Type Description ee.Image MBWI image Source code in hydrafloods/indices.py @decorators . keep_attrs def mbwi ( img , factor = 3 ): \"\"\"Function to calculate multi band water index (MBWI). Expects image has \"green\", \"red\", \"nir\", \"swir1\", and \"swir2\" bands. https://doi.org/10.1016/j.jag.2018.01.018 args: img (ee.Image): image to calculate MBWI factor (int,optional): factor to scale green band for index. default=3 returns: ee.Image: MBWI image \"\"\" return img . expression ( \"((factor*green)-red-nir-swir1-swir2)\" , { \"factor\" : factor , \"green\" : img . select ( \"green\" ), \"red\" : img . select ( \"red\" ), \"nir\" : img . select ( \"nir\" ), \"swir1\" : img . select ( \"swir1\" ), \"swir2\" : img . select ( \"swir2\" ), }, ) . rename ( \"mbwi\" )","title":"mbwi()"},{"location":"indices/#hydrafloods.indices.mndwi","text":"Function to calculate modified Difference Water Index (MNDWI). Expects image has \"green\" and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate MNDWI required Returns: Type Description ee.Image MNDWI image Source code in hydrafloods/indices.py @decorators . keep_attrs def mndwi ( img ): \"\"\"Function to calculate modified Difference Water Index (MNDWI). Expects image has \"green\" and \"swir1\" bands. args: img (ee.Image): image to calculate MNDWI returns: ee.Image: MNDWI image \"\"\" return img . normalizedDifference ([ \"green\" , \"swir1\" ]) . rename ( \"mndwi\" )","title":"mndwi()"},{"location":"indices/#hydrafloods.indices.mwi","text":"Function to calculate the Modified Water Index (MWI) Expect image has \"green\", \"red\", \"nir\", and \"swir1\" bands https://doi.org/10.1007/978-3-662-45737-5_51 , https://ieeexplore.ieee.org/document/9011209 Source code in hydrafloods/indices.py @decorators . keep_attrs def mwi ( img ): \"\"\"Function to calculate the Modified Water Index (MWI) Expect image has \"green\", \"red\", \"nir\", and \"swir1\" bands https://doi.org/10.1007/978-3-662-45737-5_51 , https://ieeexplore.ieee.org/document/9011209 \"\"\" # calculate ndvi ndvi_img = ndvi ( img ) # calculate mndwi mndwi_img = mndwi ( img ) # mwi = 1 - (ndvi - mndwi) return ee . Image . constant ( 1 ) . subtract ( ndvi_img . subtract ( mndwi_img )) . rename ( \"mwi\" )","title":"mwi()"},{"location":"indices/#hydrafloods.indices.ndpi","text":"Function to calculate nomalized difference polarization index (NDPI). Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NDPI required Returns: Type Description ee.Image NPDI image Source code in hydrafloods/indices.py @decorators . keep_attrs def ndpi ( img ): \"\"\"Function to calculate nomalized difference polarization index (NDPI). Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to calculate NDPI returns: ee.Image: NPDI image \"\"\" return img . expression ( \"(VV-VH)/(VV+VH)\" , { \"VV\" : img . select ( \"VV\" ), \"VH\" : img . select ( \"VH\" )} ) . rename ( \"ndpi\" )","title":"ndpi()"},{"location":"indices/#hydrafloods.indices.ndvi","text":"Function to calculate Normalized Difference Vegetation Index (NDVI). Expects image has \"nir\" and \"red\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NDVI required Returns: Type Description ee.Image NDVI image Source code in hydrafloods/indices.py @decorators . keep_attrs def ndvi ( img ): \"\"\"Function to calculate Normalized Difference Vegetation Index (NDVI). Expects image has \"nir\" and \"red\" bands. args: img (ee.Image): image to calculate NDVI returns: ee.Image: NDVI image \"\"\" return img . normalizedDifference ([ \"nir\" , \"red\" ]) . rename ( \"ndvi\" )","title":"ndvi()"},{"location":"indices/#hydrafloods.indices.nvhi","text":"Function to calculate nomalized VH index (NVHI). Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NVHI required Returns: Type Description ee.Image NVHI image Source code in hydrafloods/indices.py @decorators . keep_attrs def nvhi ( img ): \"\"\"Function to calculate nomalized VH index (NVHI). Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to calculate NVHI returns: ee.Image: NVHI image \"\"\" return img . expression ( \"(VH)/(VV+VH)\" , { \"VV\" : img . select ( \"VV\" ), \"VH\" : img . select ( \"VH\" )} ) . rename ( \"nvhi\" )","title":"nvhi()"},{"location":"indices/#hydrafloods.indices.nvvi","text":"Function to calculate nomalized VV index (NVVI). Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NVVI required Returns: Type Description ee.Image NVVI image Source code in hydrafloods/indices.py @decorators . keep_attrs def nvvi ( img ): \"\"\"Function to calculate nomalized VV index (NVVI). Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to calculate NVVI returns: ee.Image: NVVI image \"\"\" return img . expression ( \"(VV)/(VV+VH)\" , { \"VV\" : img . select ( \"VV\" ), \"VH\" : img . select ( \"VH\" )} ) . rename ( \"nvvi\" )","title":"nvvi()"},{"location":"indices/#hydrafloods.indices.nwi","text":"Function to calculate new water index (NWI). Expects image has \"blue\", \"nir\", \"swir1\" and \"swir2\" bands. Parameters: Name Type Description Default img ee.Image image to calculate NWI required Returns: Type Description ee.Image NWI image Source code in hydrafloods/indices.py @decorators . keep_attrs def nwi ( img ): \"\"\"Function to calculate new water index (NWI). Expects image has \"blue\", \"nir\", \"swir1\" and \"swir2\" bands. args: img (ee.Image): image to calculate NWI returns: ee.Image: NWI image \"\"\" return img . expression ( \"((b-(n+s+w))/(b+(n+s+w)))\" , { \"b\" : img . select ( \"blue\" ), \"n\" : img . select ( \"nir\" ), \"s\" : img . select ( \"swir1\" ), \"w\" : img . select ( \"swir2\" ), }, ) . rename ( \"nwi\" )","title":"nwi()"},{"location":"indices/#hydrafloods.indices.rfi","text":"Function to calculate SAR RFI index. Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to calculate RFI required Returns: Type Description ee.Image RFI image Source code in hydrafloods/indices.py @decorators . keep_attrs def rfi ( img ): \"\"\"Function to calculate SAR RFI index. Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to calculate RFI returns: ee.Image: RFI image \"\"\" return img . expression ( \"(4*VH)/(VV+VH)\" , { \"VV\" : img . select ( \"VV\" ), \"VH\" : img . select ( \"VH\" )} ) . rename ( \"rfi\" )","title":"rfi()"},{"location":"indices/#hydrafloods.indices.vv_vh_abs_sum","text":"Function to calculate the absolute value of the sum of VV and VH bands. Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to apply calculation required Returns: Type Description ee.Image image name 'vv_vh_abs_sum' Source code in hydrafloods/indices.py @decorators . keep_attrs def vv_vh_abs_sum ( img ): \"\"\"Function to calculate the absolute value of the sum of VV and VH bands. Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to apply calculation returns: ee.Image: image name 'vv_vh_abs_sum' \"\"\" return img . select ( \"VV\" ) . add ( img . select ( \"VH\" )) . abs () . rename ( \"vv_vh_abs_sum\" )","title":"vv_vh_abs_sum()"},{"location":"indices/#hydrafloods.indices.vv_vh_ratio","text":"Function to calculate ratio between VV and VH bands. Expects image has \"VV\" and \"VH\" bands. Parameters: Name Type Description Default img ee.Image image to calculate ration required Returns: Type Description ee.Image ratio image name 'ratio' Source code in hydrafloods/indices.py @decorators . keep_attrs def vv_vh_ratio ( img ): \"\"\"Function to calculate ratio between VV and VH bands. Expects image has \"VV\" and \"VH\" bands. args: img (ee.Image): image to calculate ration returns: ee.Image: ratio image name 'ratio' \"\"\" return img . expression ( \"(VV/VH)\" , { \"VV\" : img . select ( \"VV\" ), \"VH\" : img . select ( \"VH\" )} ) . rename ( \"ratio\" )","title":"vv_vh_ratio()"},{"location":"indices/#hydrafloods.indices.wri","text":"Function to calculate water ratio index (WRI). Expects image has \"green\", \"red\", \"nir\" and \"swir1\" bands. Parameters: Name Type Description Default img ee.Image image to calculate WRI required Returns: Type Description ee.Image WRI image Source code in hydrafloods/indices.py @decorators . keep_attrs def wri ( img ): \"\"\"Function to calculate water ratio index (WRI). Expects image has \"green\", \"red\", \"nir\" and \"swir1\" bands. args: img (ee.Image): image to calculate WRI returns: ee.Image: WRI image \"\"\" return img . expression ( \"(green+red)/(nir+swir)\" , { \"green\" : img . select ( \"green\" ), \"red\" : img . select ( \"red\" ), \"nir\" : img . select ( \"nir\" ), \"swir\" : img . select ( \"swir1\" ), }, ) . rename ( \"wri\" )","title":"wri()"},{"location":"installation/","text":"Installation hydrafloods itself is a pure Python package, but some of its dependencies are not. Furthermore, the package relies on Google Cloud and Google Earth Engine to stage and process data relying on specific software and even more importantly account authentication. There are two ways to install for use, one via a manual installation and another through using a Docker Image. Manual installation The most convient way to install the package and its dependencies by creating a virtual environment using anaconda . To create a new environment and activate the environment: conda create -n hydra -c conda-forge python = 3 .7 -y conda activate hydra Finally, we need to install the hydrafloods package and one last dependency via pip : pip install hydrafloods pip should handle some of the basic dependencies such as the Earth Engine Python API that we need for the majority of the functionality. You will now also need to install the Google Cloud SDK to interface to with the Google cloud. Follow the directions provided by the website. Once all of the source code and dependencies have been installed successfully, you will need to authenticate the cloud APIs Using the Docker Image A convient way to get up and started using the hydrafloods packages is via a Docker Image. Caution: This is installation method is recommended for advanced users that plan to deploy workflows on servers . The Docker Image comes with pre-installed software and dependencies so you do not have to deal with mis-matching dependencies or sometimes difficult installations. To start you will need to have Docker installed on your system and running. You will need to pull the pre-built Docker Image for hydrafloods and start a new Container from the Image using the following command: docker run --interactive --tty \\ --volume ~/<PROJECT-DIR>/:/mnt/ \\ --name hydrafloods_container kmarkert/hydrafloods This command should be a one-time process to download the package and start the Container. Additionally, this command will mount a local directory (i.e. ~/<PROJECT-DIR>/ ) for use within the Docker Container which allows you to edit files locally and use within the container. Be sure to change <PROJECT-DIR> within the command to an exisiting local directory. Now the Docker Container is running for use! Within the Docker Container the hydrafloods package and dependencies are pre-installed so all that is left is to authenticate the cloud APIs then we will be ready to test and start processing. If you have exited the Docker Container and want to start it again, use the following command: docker start -ia hydrafloods_container This command to restart an existing Container is important especially after authenticating the cloud environment so that you do not have to go through the authentication process everytime you run the Docker container. For more information on working with Docker Images/Containers using the CLI see the Docker command line documentation . Cloud authentication After successful installation of the package and dependencies we will need to authenticate our local installation (or within the Docker Container) to interface with Google Cloud and Earth Engine. Running these command will prompt you through the authentication process using a web browser. Warning: Make sure you initialize the earthengine and gcloud APIs with Google accounts that have permissions to read and write to Google Cloud Storage and Google Earth Engine assets. These do not have to be the same account (although this helps) they simply need to be authenticated to read and write Earth Engine and Cloud Storage assets. To intialize the Google Cloud environment and authenticate using your credentials, run the following command: gcloud init To authenticate the Earth Engine Python API with your credentials, run the following: earthengine authenticate Now we are ready to test our installation! Testing installation \ud83d\udea7 Coming soon! \ud83d\udea7","title":"Installation"},{"location":"installation/#installation","text":"hydrafloods itself is a pure Python package, but some of its dependencies are not. Furthermore, the package relies on Google Cloud and Google Earth Engine to stage and process data relying on specific software and even more importantly account authentication. There are two ways to install for use, one via a manual installation and another through using a Docker Image.","title":"Installation"},{"location":"installation/#manual-installation","text":"The most convient way to install the package and its dependencies by creating a virtual environment using anaconda . To create a new environment and activate the environment: conda create -n hydra -c conda-forge python = 3 .7 -y conda activate hydra Finally, we need to install the hydrafloods package and one last dependency via pip : pip install hydrafloods pip should handle some of the basic dependencies such as the Earth Engine Python API that we need for the majority of the functionality. You will now also need to install the Google Cloud SDK to interface to with the Google cloud. Follow the directions provided by the website. Once all of the source code and dependencies have been installed successfully, you will need to authenticate the cloud APIs","title":"Manual installation"},{"location":"installation/#using-the-docker-image","text":"A convient way to get up and started using the hydrafloods packages is via a Docker Image. Caution: This is installation method is recommended for advanced users that plan to deploy workflows on servers . The Docker Image comes with pre-installed software and dependencies so you do not have to deal with mis-matching dependencies or sometimes difficult installations. To start you will need to have Docker installed on your system and running. You will need to pull the pre-built Docker Image for hydrafloods and start a new Container from the Image using the following command: docker run --interactive --tty \\ --volume ~/<PROJECT-DIR>/:/mnt/ \\ --name hydrafloods_container kmarkert/hydrafloods This command should be a one-time process to download the package and start the Container. Additionally, this command will mount a local directory (i.e. ~/<PROJECT-DIR>/ ) for use within the Docker Container which allows you to edit files locally and use within the container. Be sure to change <PROJECT-DIR> within the command to an exisiting local directory. Now the Docker Container is running for use! Within the Docker Container the hydrafloods package and dependencies are pre-installed so all that is left is to authenticate the cloud APIs then we will be ready to test and start processing. If you have exited the Docker Container and want to start it again, use the following command: docker start -ia hydrafloods_container This command to restart an existing Container is important especially after authenticating the cloud environment so that you do not have to go through the authentication process everytime you run the Docker container. For more information on working with Docker Images/Containers using the CLI see the Docker command line documentation .","title":"Using the Docker Image"},{"location":"installation/#cloud-authentication","text":"After successful installation of the package and dependencies we will need to authenticate our local installation (or within the Docker Container) to interface with Google Cloud and Earth Engine. Running these command will prompt you through the authentication process using a web browser. Warning: Make sure you initialize the earthengine and gcloud APIs with Google accounts that have permissions to read and write to Google Cloud Storage and Google Earth Engine assets. These do not have to be the same account (although this helps) they simply need to be authenticated to read and write Earth Engine and Cloud Storage assets. To intialize the Google Cloud environment and authenticate using your credentials, run the following command: gcloud init To authenticate the Earth Engine Python API with your credentials, run the following: earthengine authenticate Now we are ready to test our installation!","title":"Cloud authentication"},{"location":"installation/#testing-installation","text":"\ud83d\udea7 Coming soon! \ud83d\udea7","title":"Testing installation"},{"location":"ml/","text":"hydrafloods.ml apply_fcnn ( image , project_name , model_name , model_kwargs = None , output_probas = False , output_names = None ) Parameters: Name Type Description Default image ee.Image input image for FCNN model, must have all of the features as bands required project_name str cloud project name to reference the model required model_name str ai platform model name required model_kwargs dict dictionary of keyword arguments to pass to ee.Model. default = None None output_probas bool flag to set the output image as class probabilities. If False then the ouput will be a one band output of the classification. default = False False output_bands Iterable list of band names to set for the output image required Source code in hydrafloods/ml.py @decorators . keep_attrs def apply_fcnn ( image , project_name , model_name , model_kwargs = None , output_probas = False , output_names = None , ): \"\"\" args: image (ee.Image): input image for FCNN model, must have all of the features as bands project_name (str): cloud project name to reference the model model_name (str): ai platform model name model_kwargs (dict, optional): dictionary of keyword arguments to pass to ee.Model. default = None output_probas (bool, optional): flag to set the output image as class probabilities. If False then the ouput will be a one band output of the classification. default = False output_bands (Iterable, optional): list of band names to set for the output image \"\"\" if model_kwargs is None : model_kwargs = OrderedDict ( projectName = project_name , modelName = model_name ) else : positional = OrderedDict ( projectName = project_name , modelName = model_name ) model_kwargs = OrderedDict ({ ** positional , ** model_kwargs }) # Load the trained model and use it for prediction. model = ee . Model . fromAiPlatformPredictor ( ** model_kwargs ) # run the predictions predictions = model . predictImage ( image . toFloat () . toArray ()) if output_probas : if output_names is None : raise ValueError ( \"please provide `output_names` when `ouput_probas` is set to True\" ) output = predictions . arrayFlatten ([ output_names ]) else : output_names = \"classification\" if output_names is None else output_names # find highest probability class output = predictions . arrayArgmax () . arrayFlatten ([[ output_names ]]) return output apply_feature_pca ( fc , eigen_vecs , names , center = None ) Applies Principal component decomposition on features Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to caluculate pricipal components from required eigen_vecs ee.Array eigen vectors of PCA to transform features required names list[str] property names to uses as features in PCA required center ee.Array | None Array of mean values to center features. If None then no centering is applies. default = None None Returns: Type Description ee.FeatureCollection feacture collection with new properties within each feature being the principal components Source code in hydrafloods/ml.py def apply_feature_pca ( fc , eigen_vecs , names , center = None ): \"\"\"Applies Principal component decomposition on features args: fc (ee.FeatureCollection): feature collection to caluculate pricipal components from eigen_vecs (ee.Array): eigen vectors of PCA to transform features names (list[str]): property names to uses as features in PCA center (ee.Array | None, optional): Array of mean values to center features. If None then no centering is applies. default = None returns: ee.FeatureCollection: feacture collection with new properties within each feature being the principal components \"\"\" array_ = ee . Array ( ee . List ( fc . makeArray ( names ) . aggregate_array ( \"array\" ) . map ( lambda x : ee . Array ( x ) . toList ()) ) ) if center is not None : centered = array_ . subtract ( ee . Array . cat ([ center ], 1 ) . transpose () . repeat ( 0 , array_ . length () . get ([ 0 ])) ) else : centered = array_ pca_arr = eigen_vecs . matrixMultiply ( centered . transpose ()) . transpose () out_band_names = [ f \"pc_ { i } \" for i in range ( len ( names ))] fc_size = fc . size () fc_list = fc . toList ( fc_size ) fc_pca = ee . FeatureCollection ( ee . List . sequence ( 0 , fc_size . subtract ( 1 )) . map ( lambda x : ee . Feature ( fc_list . get ( x )) . set ( ee . Dictionary . fromLists ( out_band_names , pca_arr . slice ( 0 , x , ee . Number ( x ) . add ( 1 ), 1 ) . project ([ 1 ]) . toList (), ) ) ) ) return fc_pca apply_image_pca ( img , eigen_vecs , names , center = None ) Applies Principal component decomposition on image Parameters: Name Type Description Default img ee.Image image to caluculate pricipal components from required eigen_vecs ee.Array eigen vectors of PCA to transform features required names list[str] band names to uses as features in PCA required center ee.Array | None Array of mean values to center features. If None then no centering is applies. default = None None Returns: Type Description ee.Image principal components calculated from image Source code in hydrafloods/ml.py @decorators . keep_attrs def apply_image_pca ( img , eigen_vecs , names , center = None ): \"\"\"Applies Principal component decomposition on image args: img (ee.Image): image to caluculate pricipal components from eigen_vecs (ee.Array): eigen vectors of PCA to transform features names (list[str]): band names to uses as features in PCA center (ee.Array | None, optional): Array of mean values to center features. If None then no centering is applies. default = None returns: ee.Image: principal components calculated from image \"\"\" if center is not None : arrayImage = ( img . select ( names ) . subtract ( ee . Image . constant ( center . toList ())) . toArray () . toArray ( 1 ) ) else : arrayImage = img . select ( names ) . toArray () . toArray ( 1 ) principalComponents = ee . Image ( eigen_vecs ) . matrixMultiply ( arrayImage ) out_band_names = [ f \"pc_ { i } \" for i in range ( len ( names ))] pcaImage = ( principalComponents # Throw out an an unneeded dimension, [[]] -> []. . arrayProject ([ 0 ]) # Make the one band array image a multi-band image, [] -> image. . arrayFlatten ([ out_band_names ]) ) return pcaImage calc_feature_pca ( fc , names , is_centered = False , method = 'svd' ) Principal component decomposition of features Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to caluculate PCA from required names list[str] property names to uses as features in PCA required is_centered bool boolean to identify if features need to be centered before PCA. False means apply centering. default = False False method str the decomposition method for obtaining the eigen vectors and values options are 'svd' or 'eigendecomp'. note: svd is usually faster as is does not need to compute the covariance matrix of input features. default = 'svd' 'svd' Returns: Type Description ee.Array eigen vectors of PCA ee.Array: eigen values of PCA ee.Array: mean values of each feature Source code in hydrafloods/ml.py def calc_feature_pca ( fc , names , is_centered = False , method = \"svd\" ): \"\"\"Principal component decomposition of features args: fc (ee.FeatureCollection): feature collection to caluculate PCA from names (list[str]): property names to uses as features in PCA is_centered (bool, optional): boolean to identify if features need to be centered before PCA. False means apply centering. default = False method (str, optional): the decomposition method for obtaining the eigen vectors and values options are 'svd' or 'eigendecomp'. note: svd is usually faster as is does not need to compute the covariance matrix of input features. default = 'svd' returns: ee.Array: eigen vectors of PCA ee.Array: eigen values of PCA ee.Array: mean values of each feature \"\"\" array_ = ee . Array ( ee . List ( fc . makeArray ( names ) . aggregate_array ( \"array\" ) . map ( lambda x : ee . Array ( x ) . toList ()) ) ) center = array_ . reduce ( ee . Reducer . mean (), [ 0 ]) . repeat ( 0 , array_ . length () . get ([ 0 ])) if not is_centered : centered = array_ . subtract ( center ) else : centered = array_ if method == \"svd\" : svd = centered . matrixSingularValueDecomposition () eigen_vecs = ee . Array ( svd . get ( \"V\" )) . transpose () eigen_vals = ee . Array ( svd . get ( \"S\" )) . matrixDiagonal () elif method == \"eigendecomp\" : # Compute the covariance of the bands within the region. covar = centered . transpose () . matrixMultiply ( centered ) # Perform an eigen analysis and slice apart the values and vectors. eigens = covar . eigen () eigen_vecs = eigens . slice ( 1 , 1 ) eigen_vals = eigens . slice ( 1 , 0 , 1 ) else : raise ValueError ( \"could not understand provided method keyword. Options are 'svd' or 'eigendecomp'\" ) out_band_names = [ f \"pc_ { i } \" for i in range ( len ( names ))] return eigen_vecs , eigen_vals , center . slice ( 0 , 0 , 1 ) . project ([ 1 ]) calc_image_pca ( image , region = None , scale = 90 , max_pixels = 1000000000.0 , method = 'svd' ) Principal component analysis decomposition of image bands Parameters: Name Type Description Default image ee.Image image to apply pca to required region ee.Geometry | None region to sample values for covariance matrix, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 max_pixels int maximum number of pixels to use in reduction operations. default = 1e9 1000000000.0 method str the decomposition method for obtaining the eigen vectors and values options are 'svd' or 'eigendecomp'. note: svd is usually faster as is does not need to compute the covariance matrix of input features. default = 'svd' 'svd' Returns: Type Description ee.Image principal components scaled by eigen values Source code in hydrafloods/ml.py def calc_image_pca ( image , region = None , scale = 90 , max_pixels = 1e9 , method = \"svd\" ): \"\"\"Principal component analysis decomposition of image bands args: image (ee.Image): image to apply pca to region (ee.Geometry | None, optional): region to sample values for covariance matrix, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 max_pixels (int, optional): maximum number of pixels to use in reduction operations. default = 1e9 method (str, optional): the decomposition method for obtaining the eigen vectors and values options are 'svd' or 'eigendecomp'. note: svd is usually faster as is does not need to compute the covariance matrix of input features. default = 'svd' returns: ee.Image: principal components scaled by eigen values \"\"\" bandNames = image . bandNames () out_band_names = ee . List . sequence ( 1 , bandNames . length ()) . map ( lambda x : ee . String ( \"pc_\" ) . cat ( ee . Number ( x ) . int ()) ) # Mean center the data to enable a faster covariance reducer # and an SD stretch of the principal components. meanDict = image . reduceRegion ( reducer = ee . Reducer . mean (), geometry = region , scale = scale , maxPixels = max_pixels ) means = ee . Image . constant ( meanDict . values ( bandNames )) centered = image . subtract ( means ) # Collapse the bands of the image into a 1D array per pixel. arrays = centered . toArray () if method == \"svd\" : svd = arrays . toArray ( 1 ) . matrixSingularValueDecomposition () eigen_vecs = svd . select ( \"V\" ) # .arrayTranspose() eigen_vals = svd . select ( \"S\" ) . matrixDiagonal () elif method == \"eigendecomp\" : # Compute the covariance of the bands within the region. covar = arrays . reduceRegion ( reducer = ee . Reducer . centeredCovariance (), geometry = region , scale = scale , maxPixels = max_pixels , ) # Get the 'array' covariance result and cast to an array. # This represents the band-to-band covariance within the region. covarArray = ee . Array ( covar . get ( \"array\" )) # Perform an eigen analysis and slice apart the values and vectors. eigens = covarArray . eigen () # This is a P-length vector of Eigenvalues. eigenValues = eigens . slice ( 1 , 0 , 1 ) # This is a PxP matrix with eigenvectors in rows. eigenVectors = eigens . slice ( 1 , 1 ) # Convert the array image to 2D arrays for matrix computations. arrayImage = arrays . toArray ( 1 ) # Left multiply the image array by the matrix of eigenvectors. principalComponents = ee . Image ( eigenVectors ) . matrixMultiply ( arrayImage ) # Turn the square roots of the Eigenvalues into a P-band image. sdImage = ( ee . Image ( eigenValues . sqrt ()) . arrayProject ([ 0 ]) . arrayFlatten ([ out_band_names ]) ) # Turn the PCs into a P-band image, normalized by SD. return ( principalComponents # Throw out an an unneeded dimension, [[]] -> []. . arrayProject ([ 0 ]) # Make the one band array image a multi-band image, [] -> image. . arrayFlatten ([ out_band_names ]) # Normalize the PCs by their SDs. . divide ( sdImage ) ) gradient_boosting_ee ( n_trees , feature_collection , feature_names , label , scaling = None , mode = 'classification' , shrinkage = 0.01 , loss = 'LeastAbsoluteDeviation' ) Helper function to scale feature collection and train gradient tree boosting model Parameters: Name Type Description Default n_trees int number of trees for gradient boosting model required feature_collection ee.FeatureCollection features to train random forest model required feature_names list[str] names of feature columns to use in random forest model (x values) required label str name of feature column to fit random forest model (y value) required scaling str | None name of scaling to apply before training. One of: \"minmax\", \"standard\", None . default = None None mode str The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" 'classification' learning_rate float,optional The shrinkage parameter in (0, 1] controls the learning rate of procedure. default = 0.01 required loss str Loss function to be optimized. default = \"LeastAbsoluteDeviation\" 'LeastAbsoluteDeviation' Source code in hydrafloods/ml.py def gradient_boosting_ee ( n_trees , feature_collection , feature_names , label , scaling = None , mode = \"classification\" , shrinkage = 0.01 , loss = \"LeastAbsoluteDeviation\" , ): \"\"\"Helper function to scale feature collection and train gradient tree boosting model args: n_trees (int): number of trees for gradient boosting model feature_collection (ee.FeatureCollection): features to train random forest model feature_names (list[str]): names of feature columns to use in random forest model (x values) label (str): name of feature column to fit random forest model (y value) scaling (str | None, optional): name of scaling to apply before training. One of: \"minmax\", \"standard\", `None`. default = `None` mode (str, optional): The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" learning_rate (float,optional): The shrinkage parameter in (0, 1] controls the learning rate of procedure. default = 0.01 loss (str, optional): Loss function to be optimized. default = \"LeastAbsoluteDeviation\" \"\"\" if scaling == \"minmax\" : scaling_dict = minmax_scaling_dict ( feature_collection , feature_names ) fc_norm = minmax_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling == \"standard\" : scaling_dict = standard_scaling_dict ( feature_collection , feature_names ) fc_norm = standard_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling is None : scaling_dict = None fc_norm = feature_collection else : raise ValueError ( \"Could not determine scaling option. Options are ['minmax', 'standard', or None]\" ) classifier = ( ee . Classifier . smileGradientTreeBoost ( numberOfTrees = n_trees , shrinkage = shrinkage , loss = loss ) . setOutputMode ( mode . upper ()) . train ( fc_norm , label , feature_names ) ) return classifier , scaling_dict hist_matching ( samples , predictor , target , n_estimators = 50 ) Trains classifiers to perform histogram matching Parameters: Name Type Description Default samples ee.FeatureCollection feature collection with samples for histogram matching required predictor str column name of values to transform required target str column name of values to match required n_estimators int number of trees to create random forest models from. default = 50 50 Returns: Type Description list[ee.Classifier] list of classifiers with first element being the val to proba and second being proba to val classifiers Source code in hydrafloods/ml.py def hist_matching ( samples , predictor , target , n_estimators = 50 ): \"\"\"Trains classifiers to perform histogram matching args: samples (ee.FeatureCollection): feature collection with samples for histogram matching predictor (str): column name of values to transform target (str): column name of values to match n_estimators (int, optional): number of trees to create random forest models from. default = 50 returns: list[ee.Classifier]: list of classifiers with first element being the val to proba and second being proba to val classifiers \"\"\" def get_cdf ( fc , column ): def array_to_features ( l ): return ee . Feature ( None , { column : ee . List ( l ) . get ( 0 ), \"probability\" : ee . List ( l ) . get ( 1 )} ) # Histogram equalization start: histo = ee . Dictionary ( fc . reduceColumns ( ee . Reducer . histogram ( maxBuckets = 2 ** 12 , ), [ column ], ) . get ( \"histogram\" ) ) valsList = ee . List ( histo . get ( \"bucketMeans\" )) freqsList = ee . List ( histo . get ( \"histogram\" )) cdfArray = ee . Array ( freqsList ) . accum ( 0 ) total = cdfArray . get ([ - 1 ]) normalizedCdf = cdfArray . divide ( total ) array = ee . Array . cat ([ valsList , normalizedCdf ], 1 ) return ee . FeatureCollection ( array . toList () . map ( array_to_features )) pred_cdf = get_cdf ( samples , predictor ) target_cdf = get_cdf ( samples , target ) proba_to_val = ( ee . Classifier . smileRandomForest ( n_estimators ) . setOutputMode ( \"REGRESSION\" ) . train ( features = target_cdf , classProperty = target , inputProperties = [ \"probability\" ] ) ) val_to_proba = ( ee . Classifier . smileRandomForest ( n_estimators ) . setOutputMode ( \"REGRESSION\" ) . train ( features = pred_cdf , classProperty = \"probability\" , inputProperties = [ predictor ] ) ) return val_to_proba , proba_to_val minmax_feature_scaling ( fc , scaling_dict , feature_names ) Function to apply min/max scaling to feature collection Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to scale required scaling_dict ee.Dictionary dictionary of min/max values to scale to required feature_names list[str] names of feature columns to calculate apply scaling to required Returns: Type Description ee.FeatureCollection scaled feature collection Source code in hydrafloods/ml.py def minmax_feature_scaling ( fc , scaling_dict , feature_names ): \"\"\"Function to apply min/max scaling to feature collection args: fc (ee.FeatureCollection): feature collection to scale scaling_dict (ee.Dictionary): dictionary of min/max values to scale to feature_names (list[str]): names of feature columns to calculate apply scaling to returns: ee.FeatureCollection: scaled feature collection \"\"\" def feature_scaling ( feature ): \"\"\"Nested closure function to apply scaling on each column in each feature\"\"\" def iter_cols ( i ): \"\"\"Loops through feature columns\"\"\" i = ee . String ( i ) v = ee . Number ( feature . get ( i )) minv = ee . Number ( scaling_dict . get ( i . cat ( \"_min\" ))) maxv = ee . Number ( scaling_dict . get ( i . cat ( \"_max\" ))) return v . subtract ( minv ) . divide ( maxv . subtract ( minv )) # apply scaling on each column of feature scaled = ee_feature_names . map ( iter_cols ) # get a dictionary of new values with old feature names newVals = ee . Dictionary . fromLists ( ee_feature_names , scaled ) # set feature columns new values return feature . set ( newVals ) # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # normalize the features in the entire featureCollection fc_norm = fc . map ( feature_scaling ) return fc_norm minmax_image_scaling ( image , scaling_dict , feature_names ) Function to scale image between min/max values Expects that scaling_dict keys match bands Parameters: Name Type Description Default image ee.Image image to scale required scaling_dict ee.Dictionary dictionary of min/max values to scale to required returns ee.Image: scaled image Source code in hydrafloods/ml.py @decorators . keep_attrs def minmax_image_scaling ( image , scaling_dict , feature_names ): \"\"\"Function to scale image between min/max values Expects that scaling_dict keys match bands args: image (ee.Image): image to scale scaling_dict (ee.Dictionary): dictionary of min/max values to scale to returns ee.Image: scaled image \"\"\" # get dict as image scaling_img = scaling_dict . toImage () # extract the min/max values per band min_img = scaling_img . select ( \".*_min\" ) max_img = scaling_img . select ( \".*_max\" ) # apply scaling return ( image . select ( sorted ( feature_names )) . subtract ( min_img ) . divide ( max_img . subtract ( min_img )) . float () ) minmax_scaling_dict ( fc , feature_names ) Function to calculate the minimum and maximum values of feautures in a collection Expects that fc has all feature names Parameters: Name Type Description Default fc ee.FeatureCollection feature collection with the features used to calculate min/max value required feature_names list[str] names of feature columns to calculat min/max values from required returns ee.Dictionary: dictionary of minimum and maximum values for each feature name Source code in hydrafloods/ml.py def minmax_scaling_dict ( fc , feature_names ): \"\"\"Function to calculate the minimum and maximum values of feautures in a collection Expects that fc has all feature names args: fc (ee.FeatureCollection): feature collection with the features used to calculate min/max value feature_names (list[str]): names of feature columns to calculat min/max values from returns ee.Dictionary: dictionary of minimum and maximum values for each feature name \"\"\" # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # apply reducer on each feature column feature_min_max = fc . reduceColumns ( ee . Reducer . minMax () . repeat ( ee_feature_names . length ()), ee_feature_names ) # min/max feature names names = ee_feature_names . map ( lambda x : ee . List ([ ee . String ( x ) . cat ( \"_min\" ), ee . String ( x ) . cat ( \"_max\" )]) ) . flatten () # get the min/max values for each feature # used to scale values from 0-1 min_max_dict = ee . Dictionary . fromLists ( names , ee . List ( feature_min_max . get ( \"min\" )) . zip ( feature_min_max . get ( \"max\" )) . flatten (), ) return min_max_dict onehot_feature_encoding ( fc , column_name , classes , class_names = None ) Function to calculate one-hot encoded columns from categorial columns where each new column equals 1 where the class value is the column index Parameters: Name Type Description Default fc ee.FeatureCollection Feature collection with categorial data to encode required column_name str | ee.String name of column that is categorial to encode required classes list[int] | ee.List list of class values to encode required !!! kwargs class_names (ee.List, optional): list of names to rename output bands. if None then bands will be named b0, b1, ...,bn. default = None Returns: Type Description ee.Image Feature collection with one-hot encoded columns with n new column as n classes Source code in hydrafloods/ml.py def onehot_feature_encoding ( fc , column_name , classes , class_names = None ): \"\"\"Function to calculate one-hot encoded columns from categorial columns where each new column equals 1 where the class value is the column index args: fc (ee.FeatureCollection): Feature collection with categorial data to encode column_name (str | ee.String): name of column that is categorial to encode classes (list[int] | ee.List): list of class values to encode kwargs: class_names (ee.List, optional): list of names to rename output bands. if None then bands will be named b0, b1, ...,bn. default = None returns: ee.Image: Feature collection with one-hot encoded columns with n new column as n classes \"\"\" def feature_encoding ( feature ): c = ee . Number ( feature . get ( column_name )) encoded = classes . map ( lambda x : c . eq ( ee . Number ( x ))) new_cols = ee . Dictionary . fromLists ( class_names , encoded ) return feature . set ( new_cols ) if class_names is None : class_names = ee . List . sequence ( 0 , classes . length ()) . map ( lambda x : ee . String ( \"b\" ) . cat ( ee . String ( x )) ) fc_encoded = fc . map ( feature_encoding ) return fc_encoded onehot_image_encoding ( img , classes , class_names = None , band = None ) Function to convert an categorial image image to one-hot encoded image where each new band equals 1 where the class value is the band index Parameters: Name Type Description Default img ee.Image categorical image to encode required classes list[int] | ee.List list of class values to encode required !!! kwargs class_names (ee.List, optional): list of names to rename output bands. if None then bands will be named b0, b1, ...,bn. default = None band (str | ee.String, optional): name of band from input image to endcode. if None then the first band is used. default = None Returns: Type Description ee.Image one-hot encoded image with n bands as n classes Source code in hydrafloods/ml.py @decorators . keep_attrs def onehot_image_encoding ( img , classes , class_names = None , band = None ): \"\"\"Function to convert an categorial image image to one-hot encoded image where each new band equals 1 where the class value is the band index args: img (ee.Image): categorical image to encode classes (list[int] | ee.List): list of class values to encode kwargs: class_names (ee.List, optional): list of names to rename output bands. if None then bands will be named b0, b1, ...,bn. default = None band (str | ee.String, optional): name of band from input image to endcode. if None then the first band is used. default = None returns: ee.Image: one-hot encoded image with n bands as n classes \"\"\" classes = ee . List ( classes ) if class_names is None : class_names = ee . List . sequence ( 0 , classes . length ()) . map ( lambda x : ee . String ( \"b\" ) . cat ( ee . String ( x )) ) if band is None : img = img . select ([ 0 ]) else : img = img . select ( band ) encoded_imgs = classes . map ( lambda x : img . eq ( ee . Number ( x ))) return ( ee . ImageCollection . fromImages ( ee . List ( encoded_imgs )) . toBands () . rename ( class_names ) ) random_forest_ee ( n_trees , feature_collection , feature_names , label , scaling = None , mode = 'classification' , min_samples_leaf = 1 ) Helper function to scale feature collection and train random forest model Parameters: Name Type Description Default n_trees int number of trees for random forest model required feature_collection ee.FeatureCollection features to train random forest model required feature_names list[str] names of feature columns to use in random forest model (x values) required label str name of feature column to fit random forest model (y value) required scaling str | None name of scaling to apply before training. One of: \"minmax\", \"standard\", None . default = None None mode str The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" 'classification' Source code in hydrafloods/ml.py def random_forest_ee ( n_trees , feature_collection , feature_names , label , scaling = None , mode = \"classification\" , min_samples_leaf = 1 , ): \"\"\"Helper function to scale feature collection and train random forest model args: n_trees (int): number of trees for random forest model feature_collection (ee.FeatureCollection): features to train random forest model feature_names (list[str]): names of feature columns to use in random forest model (x values) label (str): name of feature column to fit random forest model (y value) scaling (str | None, optional): name of scaling to apply before training. One of: \"minmax\", \"standard\", `None`. default = `None` mode (str, optional): The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" \"\"\" if scaling == \"minmax\" : scaling_dict = minmax_scaling_dict ( feature_collection , feature_names ) fc_norm = minmax_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling == \"standard\" : scaling_dict = standard_scaling_dict ( feature_collection , feature_names ) fc_norm = standard_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling is None : scaling_dict = None fc_norm = feature_collection else : raise ValueError ( \"Could not determine scaling option. Options are ['minmax', 'standard', or None]\" ) classifier = ( ee . Classifier . smileRandomForest ( n_trees , minLeafPopulation = min_samples_leaf ) . setOutputMode ( mode . upper ()) . train ( fc_norm , label , feature_names ) ) return classifier , scaling_dict standard_feature_scaling ( fc , scaling_dict , feature_names ) Function to apply standard (Z-score) scaling to feature collection Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to scale required scaling_dict ee.Dictionary dictionary of mean/std dev values for scaling required feature_names list[str] names of feature columns to calculate apply scaling to required Returns: Type Description ee.FeatureCollection scaled feature collection Source code in hydrafloods/ml.py def standard_feature_scaling ( fc , scaling_dict , feature_names ): \"\"\"Function to apply standard (Z-score) scaling to feature collection args: fc (ee.FeatureCollection): feature collection to scale scaling_dict (ee.Dictionary): dictionary of mean/std dev values for scaling feature_names (list[str]): names of feature columns to calculate apply scaling to returns: ee.FeatureCollection: scaled feature collection \"\"\" def feature_scaling ( feature ): \"\"\"Nested closure function to apply scaling on each column in each feature\"\"\" def iter_cols ( i ): \"\"\"Loops through feature columns\"\"\" i = ee . String ( i ) v = ee . Number ( feature . get ( i )) mean = ee . Number ( scaling_dict . get ( i . cat ( \"_mean\" ))) stddev = ee . Number ( scaling_dict . get ( i . cat ( \"_stdDev\" ))) return v . subtract ( mean ) . divide ( stddev ) # apply scaling on each column of feature scaled = ee_feature_names . map ( iter_cols ) # get a dictionary of new values with old feature names newVals = ee . Dictionary . fromLists ( ee_feature_names , scaled ) # set feature columns new values return feature . set ( newVals ) # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # normalize the features in the entire featureCollection fc_norm = fc . map ( feature_scaling ) return fc_norm standard_image_scaling ( image , scaling_dict , feature_names ) Function to apply z-score scaling to image Expects that scaling_dict keys match bands Parameters: Name Type Description Default image ee.Image image to scale required scaling_dict ee.Dictionary dictionary of mean/std dev values to scale to required returns ee.Image: scaled image Source code in hydrafloods/ml.py @decorators . keep_attrs def standard_image_scaling ( image , scaling_dict , feature_names ): \"\"\"Function to apply z-score scaling to image Expects that scaling_dict keys match bands args: image (ee.Image): image to scale scaling_dict (ee.Dictionary): dictionary of mean/std dev values to scale to returns ee.Image: scaled image \"\"\" # get dict as image scaling_img = scaling_dict . toImage () # extract the min/max values per band mean_img = scaling_img . select ( \".*_mean\" ) stddev_img = scaling_img . select ( \".*_stdDev\" ) # apply scaling return ( image . select ( sorted ( feature_names )) . subtract ( mean_img ) . divide ( stddev_img ) . float () ) standard_scaling_dict ( fc , feature_names ) Function to calculate the mean and standard deviation values of feautures in a collection Expects that fc has all feature names Parameters: Name Type Description Default fc ee.FeatureCollection feature collection with the features used to calculate mean/std dev value required feature_names list[str] names of feature columns to calculat mean/std dev values from required returns ee.Dictionary: dictionary of mean and standard deviation values for each feature name Source code in hydrafloods/ml.py def standard_scaling_dict ( fc , feature_names ): \"\"\"Function to calculate the mean and standard deviation values of feautures in a collection Expects that fc has all feature names args: fc (ee.FeatureCollection): feature collection with the features used to calculate mean/std dev value feature_names (list[str]): names of feature columns to calculat mean/std dev values from returns ee.Dictionary: dictionary of mean and standard deviation values for each feature name \"\"\" # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # get a combined reducer for caluclating mean and standard dev mean_stddev = ee . Reducer . mean () . combine ( ee . Reducer . stdDev (), None , True ) # apply reducer on each feature column feature_mean_stddev = fc . reduceColumns ( mean_stddev . repeat ( ee_feature_names . length ()), ee_feature_names ) # mean / std dev feature names names = ee_feature_names . map ( lambda x : ee . List ([ ee . String ( x ) . cat ( \"_mean\" ), ee . String ( x ) . cat ( \"_stdDev\" )]) ) . flatten () # get the mean / std dev values for each feature # used to scale values from ~ -3 to 3 mean_stddev_dict = ee . Dictionary . fromLists ( names , ee . List ( feature_mean_stddev . get ( \"mean\" )) . zip ( feature_mean_stddev . get ( \"stdDev\" )) . flatten (), ) return mean_stddev_dict unsupervised_rf ( n_trees , samples , features = None , rank_feature = None , ranking = 'min' ) Unserpersived machine learning workflow to classify water Methods similar to: https://doi.org/10.1016/j.rse.2020.112209 Parameters: Name Type Description Default n_trees int number of trees to creat random forest model for class generalization required samples ee.FeatureCollection input samples to create water classifier for required features list | ee.List property names from samples to use for the semi supervised classification, If none then all properties are used. default = None None rank_feature str property name used to rank which unserpervised class is water. If None then first band name in bands is used. default = None None ranking str method to rank the classes by rank_band . Options are 'min' or 'max'. If 'min', then the lowest class mean is considered water. default = 'min' 'min' Returns: Type Description ee.Classifier.RandomForest random forest classifier to estimate probability that a pixel is water Source code in hydrafloods/ml.py def unsupervised_rf ( n_trees , samples , features = None , rank_feature = None , ranking = \"min\" , ): \"\"\"Unserpersived machine learning workflow to classify water Methods similar to: https://doi.org/10.1016/j.rse.2020.112209 args: n_trees (int): number of trees to creat random forest model for class generalization samples (ee.FeatureCollection): input samples to create water classifier for features (list | ee.List): property names from samples to use for the semi supervised classification, If none then all properties are used. default = None rank_feature (str, optional): property name used to rank which unserpervised class is water. If None then first band name in `bands` is used. default = None ranking (str, optional): method to rank the classes by `rank_band`. Options are 'min' or 'max'. If 'min', then the lowest class mean is considered water. default = 'min' returns: ee.Classifier.RandomForest: random forest classifier to estimate probability that a pixel is water \"\"\" def _cluster_center ( x ): return ( feature_arr . mask ( classes . eq ( ee . Number ( x ))) . reduce ( ee . Reducer . mean (), [ 0 ]) ) . get ([ 0 ]) if features is None : bands = samples . first () . propertyNames () else : features = ee . List ( features ) if rank_feature is None : rank_feature = ee . String ( features . get ( 0 )) clusterer = ee . Clusterer . wekaXMeans ( 3 , 12 , 5 ) . train ( samples , features ) samples = samples . cluster ( clusterer , \"init_classes\" ) classes = samples . aggregate_array ( \"init_classes\" ) unique = classes . distinct () . sort () classes = ee . Array ( classes ) feature_arr = ee . Array ( samples . aggregate_array ( rank_feature )) class_means = unique . map ( _cluster_center ) if ranking == \"min\" : ranker = ee . Reducer . min () elif ranking == \"max\" : ranker = ee . Reducer . max () else : raise NotImplementedError ( \"ranking selection is not implemented. options are 'min' or 'max'\" ) ranked_mean = class_means . reduce ( ranker ) water_class = class_means . indexOf ( ranked_mean ) binary_samples = samples . map ( lambda x : ( ee . Feature ( x ) . set ( \"init_classes\" , ee . Number ( x . get ( \"init_classes\" )) . eq ( water_class ) ) ) ) classifier = ( ee . Classifier . smileRandomForest ( numberOfTrees = n_trees ) . setOutputMode ( \"PROBABILITY\" ) . train ( binary_samples , \"init_classes\" , features ) ) return classifier","title":"ml module"},{"location":"ml/#hydrafloods.ml","text":"","title":"ml"},{"location":"ml/#hydrafloods.ml.apply_fcnn","text":"Parameters: Name Type Description Default image ee.Image input image for FCNN model, must have all of the features as bands required project_name str cloud project name to reference the model required model_name str ai platform model name required model_kwargs dict dictionary of keyword arguments to pass to ee.Model. default = None None output_probas bool flag to set the output image as class probabilities. If False then the ouput will be a one band output of the classification. default = False False output_bands Iterable list of band names to set for the output image required Source code in hydrafloods/ml.py @decorators . keep_attrs def apply_fcnn ( image , project_name , model_name , model_kwargs = None , output_probas = False , output_names = None , ): \"\"\" args: image (ee.Image): input image for FCNN model, must have all of the features as bands project_name (str): cloud project name to reference the model model_name (str): ai platform model name model_kwargs (dict, optional): dictionary of keyword arguments to pass to ee.Model. default = None output_probas (bool, optional): flag to set the output image as class probabilities. If False then the ouput will be a one band output of the classification. default = False output_bands (Iterable, optional): list of band names to set for the output image \"\"\" if model_kwargs is None : model_kwargs = OrderedDict ( projectName = project_name , modelName = model_name ) else : positional = OrderedDict ( projectName = project_name , modelName = model_name ) model_kwargs = OrderedDict ({ ** positional , ** model_kwargs }) # Load the trained model and use it for prediction. model = ee . Model . fromAiPlatformPredictor ( ** model_kwargs ) # run the predictions predictions = model . predictImage ( image . toFloat () . toArray ()) if output_probas : if output_names is None : raise ValueError ( \"please provide `output_names` when `ouput_probas` is set to True\" ) output = predictions . arrayFlatten ([ output_names ]) else : output_names = \"classification\" if output_names is None else output_names # find highest probability class output = predictions . arrayArgmax () . arrayFlatten ([[ output_names ]]) return output","title":"apply_fcnn()"},{"location":"ml/#hydrafloods.ml.apply_feature_pca","text":"Applies Principal component decomposition on features Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to caluculate pricipal components from required eigen_vecs ee.Array eigen vectors of PCA to transform features required names list[str] property names to uses as features in PCA required center ee.Array | None Array of mean values to center features. If None then no centering is applies. default = None None Returns: Type Description ee.FeatureCollection feacture collection with new properties within each feature being the principal components Source code in hydrafloods/ml.py def apply_feature_pca ( fc , eigen_vecs , names , center = None ): \"\"\"Applies Principal component decomposition on features args: fc (ee.FeatureCollection): feature collection to caluculate pricipal components from eigen_vecs (ee.Array): eigen vectors of PCA to transform features names (list[str]): property names to uses as features in PCA center (ee.Array | None, optional): Array of mean values to center features. If None then no centering is applies. default = None returns: ee.FeatureCollection: feacture collection with new properties within each feature being the principal components \"\"\" array_ = ee . Array ( ee . List ( fc . makeArray ( names ) . aggregate_array ( \"array\" ) . map ( lambda x : ee . Array ( x ) . toList ()) ) ) if center is not None : centered = array_ . subtract ( ee . Array . cat ([ center ], 1 ) . transpose () . repeat ( 0 , array_ . length () . get ([ 0 ])) ) else : centered = array_ pca_arr = eigen_vecs . matrixMultiply ( centered . transpose ()) . transpose () out_band_names = [ f \"pc_ { i } \" for i in range ( len ( names ))] fc_size = fc . size () fc_list = fc . toList ( fc_size ) fc_pca = ee . FeatureCollection ( ee . List . sequence ( 0 , fc_size . subtract ( 1 )) . map ( lambda x : ee . Feature ( fc_list . get ( x )) . set ( ee . Dictionary . fromLists ( out_band_names , pca_arr . slice ( 0 , x , ee . Number ( x ) . add ( 1 ), 1 ) . project ([ 1 ]) . toList (), ) ) ) ) return fc_pca","title":"apply_feature_pca()"},{"location":"ml/#hydrafloods.ml.apply_image_pca","text":"Applies Principal component decomposition on image Parameters: Name Type Description Default img ee.Image image to caluculate pricipal components from required eigen_vecs ee.Array eigen vectors of PCA to transform features required names list[str] band names to uses as features in PCA required center ee.Array | None Array of mean values to center features. If None then no centering is applies. default = None None Returns: Type Description ee.Image principal components calculated from image Source code in hydrafloods/ml.py @decorators . keep_attrs def apply_image_pca ( img , eigen_vecs , names , center = None ): \"\"\"Applies Principal component decomposition on image args: img (ee.Image): image to caluculate pricipal components from eigen_vecs (ee.Array): eigen vectors of PCA to transform features names (list[str]): band names to uses as features in PCA center (ee.Array | None, optional): Array of mean values to center features. If None then no centering is applies. default = None returns: ee.Image: principal components calculated from image \"\"\" if center is not None : arrayImage = ( img . select ( names ) . subtract ( ee . Image . constant ( center . toList ())) . toArray () . toArray ( 1 ) ) else : arrayImage = img . select ( names ) . toArray () . toArray ( 1 ) principalComponents = ee . Image ( eigen_vecs ) . matrixMultiply ( arrayImage ) out_band_names = [ f \"pc_ { i } \" for i in range ( len ( names ))] pcaImage = ( principalComponents # Throw out an an unneeded dimension, [[]] -> []. . arrayProject ([ 0 ]) # Make the one band array image a multi-band image, [] -> image. . arrayFlatten ([ out_band_names ]) ) return pcaImage","title":"apply_image_pca()"},{"location":"ml/#hydrafloods.ml.calc_feature_pca","text":"Principal component decomposition of features Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to caluculate PCA from required names list[str] property names to uses as features in PCA required is_centered bool boolean to identify if features need to be centered before PCA. False means apply centering. default = False False method str the decomposition method for obtaining the eigen vectors and values options are 'svd' or 'eigendecomp'. note: svd is usually faster as is does not need to compute the covariance matrix of input features. default = 'svd' 'svd' Returns: Type Description ee.Array eigen vectors of PCA ee.Array: eigen values of PCA ee.Array: mean values of each feature Source code in hydrafloods/ml.py def calc_feature_pca ( fc , names , is_centered = False , method = \"svd\" ): \"\"\"Principal component decomposition of features args: fc (ee.FeatureCollection): feature collection to caluculate PCA from names (list[str]): property names to uses as features in PCA is_centered (bool, optional): boolean to identify if features need to be centered before PCA. False means apply centering. default = False method (str, optional): the decomposition method for obtaining the eigen vectors and values options are 'svd' or 'eigendecomp'. note: svd is usually faster as is does not need to compute the covariance matrix of input features. default = 'svd' returns: ee.Array: eigen vectors of PCA ee.Array: eigen values of PCA ee.Array: mean values of each feature \"\"\" array_ = ee . Array ( ee . List ( fc . makeArray ( names ) . aggregate_array ( \"array\" ) . map ( lambda x : ee . Array ( x ) . toList ()) ) ) center = array_ . reduce ( ee . Reducer . mean (), [ 0 ]) . repeat ( 0 , array_ . length () . get ([ 0 ])) if not is_centered : centered = array_ . subtract ( center ) else : centered = array_ if method == \"svd\" : svd = centered . matrixSingularValueDecomposition () eigen_vecs = ee . Array ( svd . get ( \"V\" )) . transpose () eigen_vals = ee . Array ( svd . get ( \"S\" )) . matrixDiagonal () elif method == \"eigendecomp\" : # Compute the covariance of the bands within the region. covar = centered . transpose () . matrixMultiply ( centered ) # Perform an eigen analysis and slice apart the values and vectors. eigens = covar . eigen () eigen_vecs = eigens . slice ( 1 , 1 ) eigen_vals = eigens . slice ( 1 , 0 , 1 ) else : raise ValueError ( \"could not understand provided method keyword. Options are 'svd' or 'eigendecomp'\" ) out_band_names = [ f \"pc_ { i } \" for i in range ( len ( names ))] return eigen_vecs , eigen_vals , center . slice ( 0 , 0 , 1 ) . project ([ 1 ])","title":"calc_feature_pca()"},{"location":"ml/#hydrafloods.ml.calc_image_pca","text":"Principal component analysis decomposition of image bands Parameters: Name Type Description Default image ee.Image image to apply pca to required region ee.Geometry | None region to sample values for covariance matrix, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 max_pixels int maximum number of pixels to use in reduction operations. default = 1e9 1000000000.0 method str the decomposition method for obtaining the eigen vectors and values options are 'svd' or 'eigendecomp'. note: svd is usually faster as is does not need to compute the covariance matrix of input features. default = 'svd' 'svd' Returns: Type Description ee.Image principal components scaled by eigen values Source code in hydrafloods/ml.py def calc_image_pca ( image , region = None , scale = 90 , max_pixels = 1e9 , method = \"svd\" ): \"\"\"Principal component analysis decomposition of image bands args: image (ee.Image): image to apply pca to region (ee.Geometry | None, optional): region to sample values for covariance matrix, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 max_pixels (int, optional): maximum number of pixels to use in reduction operations. default = 1e9 method (str, optional): the decomposition method for obtaining the eigen vectors and values options are 'svd' or 'eigendecomp'. note: svd is usually faster as is does not need to compute the covariance matrix of input features. default = 'svd' returns: ee.Image: principal components scaled by eigen values \"\"\" bandNames = image . bandNames () out_band_names = ee . List . sequence ( 1 , bandNames . length ()) . map ( lambda x : ee . String ( \"pc_\" ) . cat ( ee . Number ( x ) . int ()) ) # Mean center the data to enable a faster covariance reducer # and an SD stretch of the principal components. meanDict = image . reduceRegion ( reducer = ee . Reducer . mean (), geometry = region , scale = scale , maxPixels = max_pixels ) means = ee . Image . constant ( meanDict . values ( bandNames )) centered = image . subtract ( means ) # Collapse the bands of the image into a 1D array per pixel. arrays = centered . toArray () if method == \"svd\" : svd = arrays . toArray ( 1 ) . matrixSingularValueDecomposition () eigen_vecs = svd . select ( \"V\" ) # .arrayTranspose() eigen_vals = svd . select ( \"S\" ) . matrixDiagonal () elif method == \"eigendecomp\" : # Compute the covariance of the bands within the region. covar = arrays . reduceRegion ( reducer = ee . Reducer . centeredCovariance (), geometry = region , scale = scale , maxPixels = max_pixels , ) # Get the 'array' covariance result and cast to an array. # This represents the band-to-band covariance within the region. covarArray = ee . Array ( covar . get ( \"array\" )) # Perform an eigen analysis and slice apart the values and vectors. eigens = covarArray . eigen () # This is a P-length vector of Eigenvalues. eigenValues = eigens . slice ( 1 , 0 , 1 ) # This is a PxP matrix with eigenvectors in rows. eigenVectors = eigens . slice ( 1 , 1 ) # Convert the array image to 2D arrays for matrix computations. arrayImage = arrays . toArray ( 1 ) # Left multiply the image array by the matrix of eigenvectors. principalComponents = ee . Image ( eigenVectors ) . matrixMultiply ( arrayImage ) # Turn the square roots of the Eigenvalues into a P-band image. sdImage = ( ee . Image ( eigenValues . sqrt ()) . arrayProject ([ 0 ]) . arrayFlatten ([ out_band_names ]) ) # Turn the PCs into a P-band image, normalized by SD. return ( principalComponents # Throw out an an unneeded dimension, [[]] -> []. . arrayProject ([ 0 ]) # Make the one band array image a multi-band image, [] -> image. . arrayFlatten ([ out_band_names ]) # Normalize the PCs by their SDs. . divide ( sdImage ) )","title":"calc_image_pca()"},{"location":"ml/#hydrafloods.ml.gradient_boosting_ee","text":"Helper function to scale feature collection and train gradient tree boosting model Parameters: Name Type Description Default n_trees int number of trees for gradient boosting model required feature_collection ee.FeatureCollection features to train random forest model required feature_names list[str] names of feature columns to use in random forest model (x values) required label str name of feature column to fit random forest model (y value) required scaling str | None name of scaling to apply before training. One of: \"minmax\", \"standard\", None . default = None None mode str The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" 'classification' learning_rate float,optional The shrinkage parameter in (0, 1] controls the learning rate of procedure. default = 0.01 required loss str Loss function to be optimized. default = \"LeastAbsoluteDeviation\" 'LeastAbsoluteDeviation' Source code in hydrafloods/ml.py def gradient_boosting_ee ( n_trees , feature_collection , feature_names , label , scaling = None , mode = \"classification\" , shrinkage = 0.01 , loss = \"LeastAbsoluteDeviation\" , ): \"\"\"Helper function to scale feature collection and train gradient tree boosting model args: n_trees (int): number of trees for gradient boosting model feature_collection (ee.FeatureCollection): features to train random forest model feature_names (list[str]): names of feature columns to use in random forest model (x values) label (str): name of feature column to fit random forest model (y value) scaling (str | None, optional): name of scaling to apply before training. One of: \"minmax\", \"standard\", `None`. default = `None` mode (str, optional): The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" learning_rate (float,optional): The shrinkage parameter in (0, 1] controls the learning rate of procedure. default = 0.01 loss (str, optional): Loss function to be optimized. default = \"LeastAbsoluteDeviation\" \"\"\" if scaling == \"minmax\" : scaling_dict = minmax_scaling_dict ( feature_collection , feature_names ) fc_norm = minmax_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling == \"standard\" : scaling_dict = standard_scaling_dict ( feature_collection , feature_names ) fc_norm = standard_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling is None : scaling_dict = None fc_norm = feature_collection else : raise ValueError ( \"Could not determine scaling option. Options are ['minmax', 'standard', or None]\" ) classifier = ( ee . Classifier . smileGradientTreeBoost ( numberOfTrees = n_trees , shrinkage = shrinkage , loss = loss ) . setOutputMode ( mode . upper ()) . train ( fc_norm , label , feature_names ) ) return classifier , scaling_dict","title":"gradient_boosting_ee()"},{"location":"ml/#hydrafloods.ml.hist_matching","text":"Trains classifiers to perform histogram matching Parameters: Name Type Description Default samples ee.FeatureCollection feature collection with samples for histogram matching required predictor str column name of values to transform required target str column name of values to match required n_estimators int number of trees to create random forest models from. default = 50 50 Returns: Type Description list[ee.Classifier] list of classifiers with first element being the val to proba and second being proba to val classifiers Source code in hydrafloods/ml.py def hist_matching ( samples , predictor , target , n_estimators = 50 ): \"\"\"Trains classifiers to perform histogram matching args: samples (ee.FeatureCollection): feature collection with samples for histogram matching predictor (str): column name of values to transform target (str): column name of values to match n_estimators (int, optional): number of trees to create random forest models from. default = 50 returns: list[ee.Classifier]: list of classifiers with first element being the val to proba and second being proba to val classifiers \"\"\" def get_cdf ( fc , column ): def array_to_features ( l ): return ee . Feature ( None , { column : ee . List ( l ) . get ( 0 ), \"probability\" : ee . List ( l ) . get ( 1 )} ) # Histogram equalization start: histo = ee . Dictionary ( fc . reduceColumns ( ee . Reducer . histogram ( maxBuckets = 2 ** 12 , ), [ column ], ) . get ( \"histogram\" ) ) valsList = ee . List ( histo . get ( \"bucketMeans\" )) freqsList = ee . List ( histo . get ( \"histogram\" )) cdfArray = ee . Array ( freqsList ) . accum ( 0 ) total = cdfArray . get ([ - 1 ]) normalizedCdf = cdfArray . divide ( total ) array = ee . Array . cat ([ valsList , normalizedCdf ], 1 ) return ee . FeatureCollection ( array . toList () . map ( array_to_features )) pred_cdf = get_cdf ( samples , predictor ) target_cdf = get_cdf ( samples , target ) proba_to_val = ( ee . Classifier . smileRandomForest ( n_estimators ) . setOutputMode ( \"REGRESSION\" ) . train ( features = target_cdf , classProperty = target , inputProperties = [ \"probability\" ] ) ) val_to_proba = ( ee . Classifier . smileRandomForest ( n_estimators ) . setOutputMode ( \"REGRESSION\" ) . train ( features = pred_cdf , classProperty = \"probability\" , inputProperties = [ predictor ] ) ) return val_to_proba , proba_to_val","title":"hist_matching()"},{"location":"ml/#hydrafloods.ml.minmax_feature_scaling","text":"Function to apply min/max scaling to feature collection Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to scale required scaling_dict ee.Dictionary dictionary of min/max values to scale to required feature_names list[str] names of feature columns to calculate apply scaling to required Returns: Type Description ee.FeatureCollection scaled feature collection Source code in hydrafloods/ml.py def minmax_feature_scaling ( fc , scaling_dict , feature_names ): \"\"\"Function to apply min/max scaling to feature collection args: fc (ee.FeatureCollection): feature collection to scale scaling_dict (ee.Dictionary): dictionary of min/max values to scale to feature_names (list[str]): names of feature columns to calculate apply scaling to returns: ee.FeatureCollection: scaled feature collection \"\"\" def feature_scaling ( feature ): \"\"\"Nested closure function to apply scaling on each column in each feature\"\"\" def iter_cols ( i ): \"\"\"Loops through feature columns\"\"\" i = ee . String ( i ) v = ee . Number ( feature . get ( i )) minv = ee . Number ( scaling_dict . get ( i . cat ( \"_min\" ))) maxv = ee . Number ( scaling_dict . get ( i . cat ( \"_max\" ))) return v . subtract ( minv ) . divide ( maxv . subtract ( minv )) # apply scaling on each column of feature scaled = ee_feature_names . map ( iter_cols ) # get a dictionary of new values with old feature names newVals = ee . Dictionary . fromLists ( ee_feature_names , scaled ) # set feature columns new values return feature . set ( newVals ) # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # normalize the features in the entire featureCollection fc_norm = fc . map ( feature_scaling ) return fc_norm","title":"minmax_feature_scaling()"},{"location":"ml/#hydrafloods.ml.minmax_image_scaling","text":"Function to scale image between min/max values Expects that scaling_dict keys match bands Parameters: Name Type Description Default image ee.Image image to scale required scaling_dict ee.Dictionary dictionary of min/max values to scale to required returns ee.Image: scaled image Source code in hydrafloods/ml.py @decorators . keep_attrs def minmax_image_scaling ( image , scaling_dict , feature_names ): \"\"\"Function to scale image between min/max values Expects that scaling_dict keys match bands args: image (ee.Image): image to scale scaling_dict (ee.Dictionary): dictionary of min/max values to scale to returns ee.Image: scaled image \"\"\" # get dict as image scaling_img = scaling_dict . toImage () # extract the min/max values per band min_img = scaling_img . select ( \".*_min\" ) max_img = scaling_img . select ( \".*_max\" ) # apply scaling return ( image . select ( sorted ( feature_names )) . subtract ( min_img ) . divide ( max_img . subtract ( min_img )) . float () )","title":"minmax_image_scaling()"},{"location":"ml/#hydrafloods.ml.minmax_scaling_dict","text":"Function to calculate the minimum and maximum values of feautures in a collection Expects that fc has all feature names Parameters: Name Type Description Default fc ee.FeatureCollection feature collection with the features used to calculate min/max value required feature_names list[str] names of feature columns to calculat min/max values from required returns ee.Dictionary: dictionary of minimum and maximum values for each feature name Source code in hydrafloods/ml.py def minmax_scaling_dict ( fc , feature_names ): \"\"\"Function to calculate the minimum and maximum values of feautures in a collection Expects that fc has all feature names args: fc (ee.FeatureCollection): feature collection with the features used to calculate min/max value feature_names (list[str]): names of feature columns to calculat min/max values from returns ee.Dictionary: dictionary of minimum and maximum values for each feature name \"\"\" # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # apply reducer on each feature column feature_min_max = fc . reduceColumns ( ee . Reducer . minMax () . repeat ( ee_feature_names . length ()), ee_feature_names ) # min/max feature names names = ee_feature_names . map ( lambda x : ee . List ([ ee . String ( x ) . cat ( \"_min\" ), ee . String ( x ) . cat ( \"_max\" )]) ) . flatten () # get the min/max values for each feature # used to scale values from 0-1 min_max_dict = ee . Dictionary . fromLists ( names , ee . List ( feature_min_max . get ( \"min\" )) . zip ( feature_min_max . get ( \"max\" )) . flatten (), ) return min_max_dict","title":"minmax_scaling_dict()"},{"location":"ml/#hydrafloods.ml.onehot_feature_encoding","text":"Function to calculate one-hot encoded columns from categorial columns where each new column equals 1 where the class value is the column index Parameters: Name Type Description Default fc ee.FeatureCollection Feature collection with categorial data to encode required column_name str | ee.String name of column that is categorial to encode required classes list[int] | ee.List list of class values to encode required !!! kwargs class_names (ee.List, optional): list of names to rename output bands. if None then bands will be named b0, b1, ...,bn. default = None Returns: Type Description ee.Image Feature collection with one-hot encoded columns with n new column as n classes Source code in hydrafloods/ml.py def onehot_feature_encoding ( fc , column_name , classes , class_names = None ): \"\"\"Function to calculate one-hot encoded columns from categorial columns where each new column equals 1 where the class value is the column index args: fc (ee.FeatureCollection): Feature collection with categorial data to encode column_name (str | ee.String): name of column that is categorial to encode classes (list[int] | ee.List): list of class values to encode kwargs: class_names (ee.List, optional): list of names to rename output bands. if None then bands will be named b0, b1, ...,bn. default = None returns: ee.Image: Feature collection with one-hot encoded columns with n new column as n classes \"\"\" def feature_encoding ( feature ): c = ee . Number ( feature . get ( column_name )) encoded = classes . map ( lambda x : c . eq ( ee . Number ( x ))) new_cols = ee . Dictionary . fromLists ( class_names , encoded ) return feature . set ( new_cols ) if class_names is None : class_names = ee . List . sequence ( 0 , classes . length ()) . map ( lambda x : ee . String ( \"b\" ) . cat ( ee . String ( x )) ) fc_encoded = fc . map ( feature_encoding ) return fc_encoded","title":"onehot_feature_encoding()"},{"location":"ml/#hydrafloods.ml.onehot_image_encoding","text":"Function to convert an categorial image image to one-hot encoded image where each new band equals 1 where the class value is the band index Parameters: Name Type Description Default img ee.Image categorical image to encode required classes list[int] | ee.List list of class values to encode required !!! kwargs class_names (ee.List, optional): list of names to rename output bands. if None then bands will be named b0, b1, ...,bn. default = None band (str | ee.String, optional): name of band from input image to endcode. if None then the first band is used. default = None Returns: Type Description ee.Image one-hot encoded image with n bands as n classes Source code in hydrafloods/ml.py @decorators . keep_attrs def onehot_image_encoding ( img , classes , class_names = None , band = None ): \"\"\"Function to convert an categorial image image to one-hot encoded image where each new band equals 1 where the class value is the band index args: img (ee.Image): categorical image to encode classes (list[int] | ee.List): list of class values to encode kwargs: class_names (ee.List, optional): list of names to rename output bands. if None then bands will be named b0, b1, ...,bn. default = None band (str | ee.String, optional): name of band from input image to endcode. if None then the first band is used. default = None returns: ee.Image: one-hot encoded image with n bands as n classes \"\"\" classes = ee . List ( classes ) if class_names is None : class_names = ee . List . sequence ( 0 , classes . length ()) . map ( lambda x : ee . String ( \"b\" ) . cat ( ee . String ( x )) ) if band is None : img = img . select ([ 0 ]) else : img = img . select ( band ) encoded_imgs = classes . map ( lambda x : img . eq ( ee . Number ( x ))) return ( ee . ImageCollection . fromImages ( ee . List ( encoded_imgs )) . toBands () . rename ( class_names ) )","title":"onehot_image_encoding()"},{"location":"ml/#hydrafloods.ml.random_forest_ee","text":"Helper function to scale feature collection and train random forest model Parameters: Name Type Description Default n_trees int number of trees for random forest model required feature_collection ee.FeatureCollection features to train random forest model required feature_names list[str] names of feature columns to use in random forest model (x values) required label str name of feature column to fit random forest model (y value) required scaling str | None name of scaling to apply before training. One of: \"minmax\", \"standard\", None . default = None None mode str The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" 'classification' Source code in hydrafloods/ml.py def random_forest_ee ( n_trees , feature_collection , feature_names , label , scaling = None , mode = \"classification\" , min_samples_leaf = 1 , ): \"\"\"Helper function to scale feature collection and train random forest model args: n_trees (int): number of trees for random forest model feature_collection (ee.FeatureCollection): features to train random forest model feature_names (list[str]): names of feature columns to use in random forest model (x values) label (str): name of feature column to fit random forest model (y value) scaling (str | None, optional): name of scaling to apply before training. One of: \"minmax\", \"standard\", `None`. default = `None` mode (str, optional): The output mode of the random forest model. One of: \"classification\", \"regression\", \"probability\". default = \"classification\" \"\"\" if scaling == \"minmax\" : scaling_dict = minmax_scaling_dict ( feature_collection , feature_names ) fc_norm = minmax_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling == \"standard\" : scaling_dict = standard_scaling_dict ( feature_collection , feature_names ) fc_norm = standard_feature_scaling ( feature_collection , scaling_dict , feature_names ) elif scaling is None : scaling_dict = None fc_norm = feature_collection else : raise ValueError ( \"Could not determine scaling option. Options are ['minmax', 'standard', or None]\" ) classifier = ( ee . Classifier . smileRandomForest ( n_trees , minLeafPopulation = min_samples_leaf ) . setOutputMode ( mode . upper ()) . train ( fc_norm , label , feature_names ) ) return classifier , scaling_dict","title":"random_forest_ee()"},{"location":"ml/#hydrafloods.ml.standard_feature_scaling","text":"Function to apply standard (Z-score) scaling to feature collection Parameters: Name Type Description Default fc ee.FeatureCollection feature collection to scale required scaling_dict ee.Dictionary dictionary of mean/std dev values for scaling required feature_names list[str] names of feature columns to calculate apply scaling to required Returns: Type Description ee.FeatureCollection scaled feature collection Source code in hydrafloods/ml.py def standard_feature_scaling ( fc , scaling_dict , feature_names ): \"\"\"Function to apply standard (Z-score) scaling to feature collection args: fc (ee.FeatureCollection): feature collection to scale scaling_dict (ee.Dictionary): dictionary of mean/std dev values for scaling feature_names (list[str]): names of feature columns to calculate apply scaling to returns: ee.FeatureCollection: scaled feature collection \"\"\" def feature_scaling ( feature ): \"\"\"Nested closure function to apply scaling on each column in each feature\"\"\" def iter_cols ( i ): \"\"\"Loops through feature columns\"\"\" i = ee . String ( i ) v = ee . Number ( feature . get ( i )) mean = ee . Number ( scaling_dict . get ( i . cat ( \"_mean\" ))) stddev = ee . Number ( scaling_dict . get ( i . cat ( \"_stdDev\" ))) return v . subtract ( mean ) . divide ( stddev ) # apply scaling on each column of feature scaled = ee_feature_names . map ( iter_cols ) # get a dictionary of new values with old feature names newVals = ee . Dictionary . fromLists ( ee_feature_names , scaled ) # set feature columns new values return feature . set ( newVals ) # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # normalize the features in the entire featureCollection fc_norm = fc . map ( feature_scaling ) return fc_norm","title":"standard_feature_scaling()"},{"location":"ml/#hydrafloods.ml.standard_image_scaling","text":"Function to apply z-score scaling to image Expects that scaling_dict keys match bands Parameters: Name Type Description Default image ee.Image image to scale required scaling_dict ee.Dictionary dictionary of mean/std dev values to scale to required returns ee.Image: scaled image Source code in hydrafloods/ml.py @decorators . keep_attrs def standard_image_scaling ( image , scaling_dict , feature_names ): \"\"\"Function to apply z-score scaling to image Expects that scaling_dict keys match bands args: image (ee.Image): image to scale scaling_dict (ee.Dictionary): dictionary of mean/std dev values to scale to returns ee.Image: scaled image \"\"\" # get dict as image scaling_img = scaling_dict . toImage () # extract the min/max values per band mean_img = scaling_img . select ( \".*_mean\" ) stddev_img = scaling_img . select ( \".*_stdDev\" ) # apply scaling return ( image . select ( sorted ( feature_names )) . subtract ( mean_img ) . divide ( stddev_img ) . float () )","title":"standard_image_scaling()"},{"location":"ml/#hydrafloods.ml.standard_scaling_dict","text":"Function to calculate the mean and standard deviation values of feautures in a collection Expects that fc has all feature names Parameters: Name Type Description Default fc ee.FeatureCollection feature collection with the features used to calculate mean/std dev value required feature_names list[str] names of feature columns to calculat mean/std dev values from required returns ee.Dictionary: dictionary of mean and standard deviation values for each feature name Source code in hydrafloods/ml.py def standard_scaling_dict ( fc , feature_names ): \"\"\"Function to calculate the mean and standard deviation values of feautures in a collection Expects that fc has all feature names args: fc (ee.FeatureCollection): feature collection with the features used to calculate mean/std dev value feature_names (list[str]): names of feature columns to calculat mean/std dev values from returns ee.Dictionary: dictionary of mean and standard deviation values for each feature name \"\"\" # force ee types fc = ee . FeatureCollection ( fc ) ee_feature_names = ee . List ( feature_names ) # get a combined reducer for caluclating mean and standard dev mean_stddev = ee . Reducer . mean () . combine ( ee . Reducer . stdDev (), None , True ) # apply reducer on each feature column feature_mean_stddev = fc . reduceColumns ( mean_stddev . repeat ( ee_feature_names . length ()), ee_feature_names ) # mean / std dev feature names names = ee_feature_names . map ( lambda x : ee . List ([ ee . String ( x ) . cat ( \"_mean\" ), ee . String ( x ) . cat ( \"_stdDev\" )]) ) . flatten () # get the mean / std dev values for each feature # used to scale values from ~ -3 to 3 mean_stddev_dict = ee . Dictionary . fromLists ( names , ee . List ( feature_mean_stddev . get ( \"mean\" )) . zip ( feature_mean_stddev . get ( \"stdDev\" )) . flatten (), ) return mean_stddev_dict","title":"standard_scaling_dict()"},{"location":"ml/#hydrafloods.ml.unsupervised_rf","text":"Unserpersived machine learning workflow to classify water Methods similar to: https://doi.org/10.1016/j.rse.2020.112209 Parameters: Name Type Description Default n_trees int number of trees to creat random forest model for class generalization required samples ee.FeatureCollection input samples to create water classifier for required features list | ee.List property names from samples to use for the semi supervised classification, If none then all properties are used. default = None None rank_feature str property name used to rank which unserpervised class is water. If None then first band name in bands is used. default = None None ranking str method to rank the classes by rank_band . Options are 'min' or 'max'. If 'min', then the lowest class mean is considered water. default = 'min' 'min' Returns: Type Description ee.Classifier.RandomForest random forest classifier to estimate probability that a pixel is water Source code in hydrafloods/ml.py def unsupervised_rf ( n_trees , samples , features = None , rank_feature = None , ranking = \"min\" , ): \"\"\"Unserpersived machine learning workflow to classify water Methods similar to: https://doi.org/10.1016/j.rse.2020.112209 args: n_trees (int): number of trees to creat random forest model for class generalization samples (ee.FeatureCollection): input samples to create water classifier for features (list | ee.List): property names from samples to use for the semi supervised classification, If none then all properties are used. default = None rank_feature (str, optional): property name used to rank which unserpervised class is water. If None then first band name in `bands` is used. default = None ranking (str, optional): method to rank the classes by `rank_band`. Options are 'min' or 'max'. If 'min', then the lowest class mean is considered water. default = 'min' returns: ee.Classifier.RandomForest: random forest classifier to estimate probability that a pixel is water \"\"\" def _cluster_center ( x ): return ( feature_arr . mask ( classes . eq ( ee . Number ( x ))) . reduce ( ee . Reducer . mean (), [ 0 ]) ) . get ([ 0 ]) if features is None : bands = samples . first () . propertyNames () else : features = ee . List ( features ) if rank_feature is None : rank_feature = ee . String ( features . get ( 0 )) clusterer = ee . Clusterer . wekaXMeans ( 3 , 12 , 5 ) . train ( samples , features ) samples = samples . cluster ( clusterer , \"init_classes\" ) classes = samples . aggregate_array ( \"init_classes\" ) unique = classes . distinct () . sort () classes = ee . Array ( classes ) feature_arr = ee . Array ( samples . aggregate_array ( rank_feature )) class_means = unique . map ( _cluster_center ) if ranking == \"min\" : ranker = ee . Reducer . min () elif ranking == \"max\" : ranker = ee . Reducer . max () else : raise NotImplementedError ( \"ranking selection is not implemented. options are 'min' or 'max'\" ) ranked_mean = class_means . reduce ( ranker ) water_class = class_means . indexOf ( ranked_mean ) binary_samples = samples . map ( lambda x : ( ee . Feature ( x ) . set ( \"init_classes\" , ee . Number ( x . get ( \"init_classes\" )) . eq ( water_class ) ) ) ) classifier = ( ee . Classifier . smileRandomForest ( numberOfTrees = n_trees ) . setOutputMode ( \"PROBABILITY\" ) . train ( binary_samples , \"init_classes\" , features ) ) return classifier","title":"unsupervised_rf()"},{"location":"thresholding/","text":"hydrafloods.thresholding bmax_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , thresh_no_data = None , invert = False , grid_size = 0.1 , bmax_threshold = 0.75 , iters = 1 , max_boxes = 100 , seed = 7 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1000000.0 , return_threshold = False ) Implementation of the B-Max Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None region ee.Geometry | None region to determine threshold, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 initial_threshold float initial estimate of water/no-water for estimating the probabilities of classes in segment. default = 0 0 thresh_no_data float threshold to be used when histogram is empty (likely little to no water present in image). default = -0.2 None invert bool boolean switch to determine if to threshold greater than (True) or less than (False). default = False False grid_size float size in decimal degrees to tile image/region to check for bimodality. default = 0.1 0.1 bmax_threshold float value 0-1 to determine if a value of bmax is bimodal or not. default = 0.75 0.75 iters int number of iterations to successively shrink the bmax tiles to refine threshold. 1 uses defined grid_size. default = 1 1 max_boxes int maximum number of tiles/boxes to use when determining threshold, will select based on maximum bmax ordering. default = None 100 seed int random number generator seed for randomly selected max_boxes. default = 7 7 max_buckets int The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 255 min_bucket_width float The minimum histogram bucket width to allow any power of 2. default = 0.001 0.001 max_raw int The number of values to accumulate before building the initial histogram. default = 1e6 1000000.0 return_threshold bool boolean switch, if set to true then function will return threshold number, else thresholded image. default = False False Returns: Type Description ee.Image thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm Source code in hydrafloods/thresholding.py @decorators . keep_attrs def bmax_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , thresh_no_data = None , invert = False , grid_size = 0.1 , bmax_threshold = 0.75 , iters = 1 , max_boxes = 100 , seed = 7 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1e6 , return_threshold = False , ): \"\"\"Implementation of the B-Max Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 args: img (ee.Image): input image to thresholding algorithm band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None region (ee.Geometry | None, optional): region to determine threshold, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 initial_threshold (float, optional): initial estimate of water/no-water for estimating the probabilities of classes in segment. default = 0 thresh_no_data (float, optional): threshold to be used when histogram is empty (likely little to no water present in image). default = -0.2 invert (bool, optional): boolean switch to determine if to threshold greater than (True) or less than (False). default = False grid_size (float, optional): size in decimal degrees to tile image/region to check for bimodality. default = 0.1 bmax_threshold (float, optional): value 0-1 to determine if a value of bmax is bimodal or not. default = 0.75 iters (int, optional): number of iterations to successively shrink the bmax tiles to refine threshold. 1 uses defined grid_size. default = 1 max_boxes (int, optional): maximum number of tiles/boxes to use when determining threshold, will select based on maximum bmax ordering. default = None seed (int, optional): random number generator seed for randomly selected max_boxes. default = 7 max_buckets (int, optional): The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 min_bucket_width (float, optional): The minimum histogram bucket width to allow any power of 2. default = 0.001 max_raw (int, optional): The number of values to accumulate before building the initial histogram. default = 1e6 return_threshold (bool, optional): boolean switch, if set to true then function will return threshold number, else thresholded image. default = False returns: ee.Image: thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm \"\"\" def calcBmax ( feature ): \"\"\"Closure function to calculate Bmax for each feature covering image\"\"\" segment = img initial = segment . lt ( initial_threshold ) p1 = ee . Number ( initial . reduceRegion ( reducer = ee . Reducer . mean (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) . get ( histBand ) ) p1 = ee . Number ( ee . Algorithms . If ( p1 , p1 , 0.9999 )) p2 = ee . Number ( 1 ) . subtract ( p1 ) m = ( segment . updateMask ( initial ) . rename ( \"m1\" ) . addBands ( segment . updateMask ( initial . Not ()) . rename ( \"m2\" )) ) mReduced = m . reduceRegion ( reducer = ee . Reducer . mean (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) m1 = ee . Number ( mReduced . get ( \"m1\" )) m2 = ee . Number ( mReduced . get ( \"m2\" )) m1 = ee . Number ( ee . Algorithms . If ( m1 , m1 , - 25 )) m2 = ee . Number ( ee . Algorithms . If ( m2 , m2 , 0 )) sigmab = p1 . multiply ( p2 . multiply ( m1 . subtract ( m2 ) . pow ( 2 ))) sigmat = ee . Number ( segment . reduceRegion ( reducer = ee . Reducer . variance (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) . get ( histBand ) ) sigmat = ee . Number ( ee . Algorithms . If ( sigmat , sigmat , 2 )) bmax = sigmab . divide ( sigmat ) return feature . set ({ \"bmax\" : bmax }) if band is None : img = img . select ([ 0 ]) histBand = ee . String ( img . bandNames () . get ( 0 )) else : histBand = ee . String ( band ) img = img . select ( histBand ) if region is None : region = img . geometry () grid = geeutils . tile_region ( region , centroid_within = region , grid_size = grid_size ) bmaxes = grid . map ( calcBmax ) . filter ( ee . Filter . gt ( \"bmax\" , bmax_threshold )) if iters > 1 : for i in range ( iters - 1 ): grid_size /= 2.0 grid = geeutils . tile_region ( bmaxes . geometry (), centroid_within = bmaxes , grid_size = grid_size ) bmaxes = grid . map ( calcBmax ) . filter ( ee . Filter . gt ( \"bmax\" , bmax_threshold )) if max_boxes is not None : selection = bmaxes . limit ( max_boxes , \"bmax\" ) else : selection = bmaxes histogram = img . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), selection , scale , bestEffort = True , tileScale = 16 , ) if thresh_no_data is not None : threshold = ee . Number ( ee . Algorithms . If ( ee . Dictionary ( histogram . get ( histBand . cat ( \"_histogram\" ))) . contains ( \"bucketMeans\" ), otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))), thresh_no_data , ) ) else : threshold = otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))) if return_threshold is True : return ee . Image ( threshold ) else : water = ee . Image ( ee . Algorithms . If ( invert , img . gt ( threshold ), img . lt ( threshold ))) return water . rename ( \"water\" ) . uint8 () edge_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , thresh_no_data = None , invert = False , canny_threshold = 0.05 , canny_sigma = 0 , canny_lt = 0.05 , connected_pixels = 200 , edge_length = 50 , edge_buffer = 100 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1000000.0 , return_threshold = False ) Implementation of the Edge Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None region ee.Geometry | None region to determine threshold, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 initial_threshold float initial estimate of water/no-water for estimating the edges. default = 0 0 thresh_no_data float threshold to be used when histogram is empty (likely little to no water present in image). default = -0.2 None invert bool boolean switch to determine if to threshold greater than (True) or less than (False). default = False False canny_threshold float threshold for canny edge detection. default = 0.05 0.05 canny_sigma float sigma value for gaussian filter in canny edge detection. default = 0 0 canny_lt float lower threshold for canny detection. default = 0.05 0.05 connected_pixels int maximum size of the neighborhood in pixels to determine if connected. default = 200 200 edge_length int minimum length of edges from canny detection to be considered edge. default = 50 50 edge_buffer int distance in meters to buffer edges on a side for histogram sampling. default = 100 100 max_buckets int The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 255 min_bucket_width float The minimum histogram bucket width to allow any power of 2. default = 0.001 0.001 max_raw int The number of values to accumulate before building the initial histogram. default = 1e6 1000000.0 return_threshold bool boolean switch, if set to true then function will return threshold number, else thresholded image. default = False False Returns: Type Description ee.Image thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm Source code in hydrafloods/thresholding.py @decorators . keep_attrs def edge_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , thresh_no_data = None , invert = False , canny_threshold = 0.05 , canny_sigma = 0 , canny_lt = 0.05 , connected_pixels = 200 , edge_length = 50 , edge_buffer = 100 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1e6 , return_threshold = False , ): \"\"\"Implementation of the Edge Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 args: img (ee.Image): input image to thresholding algorithm band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None region (ee.Geometry | None, optional): region to determine threshold, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 initial_threshold (float, optional): initial estimate of water/no-water for estimating the edges. default = 0 thresh_no_data (float, optional): threshold to be used when histogram is empty (likely little to no water present in image). default = -0.2 invert (bool, optional): boolean switch to determine if to threshold greater than (True) or less than (False). default = False canny_threshold (float, optional): threshold for canny edge detection. default = 0.05 canny_sigma (float, optional): sigma value for gaussian filter in canny edge detection. default = 0 canny_lt (float, optional): lower threshold for canny detection. default = 0.05 connected_pixels (int, optional): maximum size of the neighborhood in pixels to determine if connected. default = 200 edge_length (int, optional): minimum length of edges from canny detection to be considered edge. default = 50 edge_buffer (int, optional): distance in meters to buffer edges on a side for histogram sampling. default = 100 max_buckets (int, optional): The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 min_bucket_width (float, optional): The minimum histogram bucket width to allow any power of 2. default = 0.001 max_raw (int, optional): The number of values to accumulate before building the initial histogram. default = 1e6 return_threshold (bool, optional): boolean switch, if set to true then function will return threshold number, else thresholded image. default = False returns: ee.Image: thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm \"\"\" if band is None : img = img . select ([ 0 ]) histBand = ee . String ( img . bandNames () . get ( 0 )) else : histBand = ee . String ( band ) img = img . select ( histBand ) if region is None : region = img . geometry () binary = img . lt ( initial_threshold ) . rename ( \"binary\" ) # get canny edges canny = ee . Algorithms . CannyEdgeDetector ( binary , canny_threshold , canny_sigma ) # process canny edges connected = ( canny . mask ( canny ) . lt ( canny_lt ) . connectedPixelCount ( connected_pixels , True ) ) edges = connected . gte ( edge_length ) edgeBuffer = edges . focal_max ( edge_buffer , \"square\" , \"meters\" ) # mask out areas to get histogram for Otsu histogram_image = img . updateMask ( edgeBuffer ) histogram = histogram_image . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), region , scale , bestEffort = True , tileScale = 16 , ) if thresh_no_data is not None : threshold = ee . Number ( ee . Algorithms . If ( ee . Dictionary ( histogram . get ( histBand . cat ( \"_histogram\" ))) . contains ( \"bucketMeans\" ), otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))), thresh_no_data , ) ) else : threshold = otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))) if return_threshold is True : return threshold else : water = ee . Image ( ee . Algorithms . If ( invert , img . gt ( threshold ), img . lt ( threshold ))) return water . rename ( \"water\" ) . uint8 () fuzzy_otsu ( img , band = None , region = None , scale = 90 , initial_threshold =- 15.5 , grid_size = 0.1 , max_boxes = 20 , seed = 0 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1000000.0 ) Implementation of Otsu thresholding algorithm. Segment the grids into water and land representation using initial threshold and randomly select features to calculate minimum and maximum threshold of the image. Calculate Midpoint of min and max threshold using Fuzzy_Gaussian to map water. Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None region ee.Geometry | None region to determine threshold, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 initial_threshold float initial estimate of water/no-water for estimating the probabilities of classes in segment. default = -15.5 -15.5 grid_size float size in decimal degrees to tile image/region to check for bimodality. default = 0.1 0.1 max_boxes int maximum number of tiles/boxes to use when determining threshold. default = 20 20 seed int random number generator seed for randomly selected max_boxes. default = 7 0 max_buckets int The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 255 min_bucket_width float The minimum histogram bucket width to allow any power of 2. default = 0.001 0.001 max_raw int The number of values to accumulate before building the initial histogram. default = 1e6 1000000.0 Returns: Type Description ee.Image thresholded water image. Source code in hydrafloods/thresholding.py @decorators . keep_attrs def fuzzy_otsu ( img , band = None , region = None , scale = 90 , initial_threshold =- 15.5 , grid_size = 0.1 , max_boxes = 20 , seed = 0 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1e6 , ): \"\"\"Implementation of Otsu thresholding algorithm. Segment the grids into water and land representation using initial threshold and randomly select features to calculate minimum and maximum threshold of the image. Calculate Midpoint of min and max threshold using Fuzzy_Gaussian to map water. args: img (ee.Image): input image to thresholding algorithm band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None region (ee.Geometry | None, optional): region to determine threshold, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 initial_threshold (float, optional): initial estimate of water/no-water for estimating the probabilities of classes in segment. default = -15.5 grid_size (float, optional): size in decimal degrees to tile image/region to check for bimodality. default = 0.1 max_boxes (int, optional): maximum number of tiles/boxes to use when determining threshold. default = 20 seed (int, optional): random number generator seed for randomly selected max_boxes. default = 7 max_buckets (int, optional): The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 min_bucket_width (float, optional): The minimum histogram bucket width to allow any power of 2. default = 0.001 max_raw (int, optional): The number of values to accumulate before building the initial histogram. default = 1e6 returns: ee.Image: thresholded water image. \"\"\" # Function to Segment Land and Water Grids def segment_grid ( feature ): counts = initImg . reduceRegion ( reducer = ee . Reducer . sum (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) return feature . set ( counts ) if region is None : region = img . geometry () if band is None : img = img . select ([ 0 ]) histBand = ee . String ( img . bandNames () . get ( 0 )) else : histBand = ee . String ( band ) img = img . select ( histBand ) grid = geeutils . tile_region ( region , intersect_geom = region , grid_size = grid_size ) # Prepare good representation of water and land initWater = img . lt ( initial_threshold ) . rename ( \"water\" ) initImg = initWater . addBands ( initWater . Not () . rename ( \"land\" )) grid = grid . map ( segment_grid ) # Select water and land grid selection = grid . filter ( ee . Filter . And ( ee . Filter . gt ( \"water\" , 1000 ), ee . Filter . gt ( \"land\" , 1000 )) ) # Randomly select features selection = selection . randomColumn ( \"random\" ) nBoxes = ee . Number ( selection . size ()) randomSelection = ee . Number ( max_boxes ) . divide ( nBoxes ) selection = selection . filter ( ee . Filter . lt ( \"random\" , randomSelection )) # Create histogram for selected features to calculate min threshold histogram = img . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), selection . geometry (), scale , bestEffort = True , tileScale = 16 , ) min_threshold = otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))) # Create histogram to calculate max threshold histogram2 = img . updateMask ( img . lt ( min_threshold )) . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), selection . geometry (), scale , bestEffort = True , tileScale = 16 , ) max_threshold = otsu ( histogram2 . get ( histBand . cat ( \"_histogram\" ))) # Calculate Midpoint of min and max threshold using Fuzzy_Gaussian midpoint = ee . Number ( ee . Number ( min_threshold ) . add ( ee . Number ( max_threshold ))) . divide ( 2 ) spread = 0.2 gauss = fuzzy . fuzzy_gaussian ( img , midpoint , spread ) . clip ( region ) waterImg = img . lt ( midpoint ) waterImg = waterImg . where ( waterImg . eq ( 0 ), gauss ) return ee . Image ( waterImg ) kmeans_extent ( img , hand , initial_threshold = 0 , region = None , band = None , n_samples = 500 , seed = 7 , invert = False , scale = 90 ) Water thresholding methodology using image values and HAND. Method from https://doi.org/10.1016/j.rse.2020.111732 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required hand ee.Image Height Above Nearest Drainage image used as axis in clustering required initial_threshold float initial estimate of water/no-water for stratified sampling. default = 0 0 region ee.Geometry | None region to sample values for KMeans clustering, if set to None will use img.geometry(). default = None None band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None samples int number of stratified samples to gather for clustering from the initial water/no-water map. default=500 required seed int random number generator seed for sampling. default = 7 7 scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 Returns: Type Description ee.Image clustered image from KMeans clusterer. Classes assumed to be water/no-water Source code in hydrafloods/thresholding.py def kmeans_extent ( img , hand , initial_threshold = 0 , region = None , band = None , n_samples = 500 , seed = 7 , invert = False , scale = 90 , ): \"\"\"Water thresholding methodology using image values and HAND. Method from https://doi.org/10.1016/j.rse.2020.111732 args: img (ee.Image): input image to thresholding algorithm hand (ee.Image): Height Above Nearest Drainage image used as axis in clustering initial_threshold (float, optional): initial estimate of water/no-water for stratified sampling. default = 0 region (ee.Geometry | None, optional): region to sample values for KMeans clustering, if set to `None` will use img.geometry(). default = None band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None samples (int, optional): number of stratified samples to gather for clustering from the initial water/no-water map. default=500 seed (int, optional): random number generator seed for sampling. default = 7 scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 returns: ee.Image: clustered image from KMeans clusterer. Classes assumed to be water/no-water \"\"\" def _cluster_center ( x ): return ee . Number ( ( band_arr . mask ( classes . eq ( ee . Number ( x ))) . reduce ( ee . Reducer . mean (), [ 0 ]) ) . get ([ 0 ]) ) if region is None : region = img . geometry () if band is None : img = img . select ([ 0 ]) band = ee . String ( img . bandNames () . get ( 0 )) else : img = img . select ( band ) hand_band = ee . String ( hand . bandNames () . get ( 0 )) # convert invert to a number 0 or 1 for ee server-side invert = 1 if invert else 0 img = img . addBands ( hand . unmask ( 0 )) strata = img . select ( band ) . gt ( initial_threshold ) . rename ( \"strata\" ) samples = img . addBands ( strata ) . stratifiedSample ( numPoints = n_samples , classBand = \"strata\" , region = region , scale = scale , classValues = [ 0 , 1 ], classPoints = [ n_samples , n_samples ], tileScale = 16 , seed = seed , ) clusterer = ee . Clusterer . wekaKMeans ( 2 , 1 ) . train ( samples , [ band , hand_band ]) samples = samples . cluster ( clusterer , \"classes\" ) classes = samples . aggregate_array ( \"classes\" ) unique = classes . distinct () . sort () classes = ee . Array ( classes ) band_arr = ee . Array ( samples . aggregate_array ( band )) class_means = unique . map ( _cluster_center ) min_mean = class_means . reduce ( ee . Reducer . min ()) water_class = class_means . indexOf ( min_mean ) water = img . cluster ( clusterer ) water = ee . Image ( ee . Algorithms . If ( water_class . eq ( 0 ), water . Not (), water )) return water . rename ( \"water\" ) . uint8 () modis_flood ( img ) Implementation of the NASA MODIS Flood algorithm. Expects that imagery has https://cdn.earthdata.nasa.gov/conduit/upload/17162/MCDWD_UserGuide_RevB.pdf Parameters: Name Type Description Default img ee.Image image to apply algorithm to, should be either MODIS or VIIRS sensor data required Returns: Type Description ee.Image resulting water map Source code in hydrafloods/thresholding.py @decorators . keep_attrs def modis_flood ( img ): \"\"\"Implementation of the NASA MODIS Flood algorithm. Expects that imagery has https://cdn.earthdata.nasa.gov/conduit/upload/17162/MCDWD_UserGuide_RevB.pdf args: img (ee.Image): image to apply algorithm to, should be either MODIS or VIIRS sensor data returns: ee.Image: resulting water map \"\"\" # coefficients for the algorithm a = 0.0013500 b = 0.10811 c = 0.7 d = 0.2027 e = 0.06757 water = img . expression ( \"((nir+a)/(red+b) < c) and (red < d) and (swir2 < e)\" ,{ \"red\" : img . select ( \"red\" ), \"nir\" : img . select ( \"nir\" ), \"swir2\" : img . select ( \"swir2\" ), \"a\" : a , \"b\" : b , \"c\" : c , \"d\" : d , \"e\" : e }) . uint8 () . rename ( \"water\" ) return water multidim_semisupervised ( img , bands , rank_band = None , ranking = 'min' , region = None , n_samples = 500 , seed = 7 , scale = 90 , proba_threshold = None ) Implementation of the Automatic water detection from multidimensional hierarchical clustering algorithm. Method details: https://doi.org/10.1016/j.rse.2020.112209 Note: this is a similar method, not exact from the paper Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required bands list | ee.List band names to use for the semi supervised classification required rank_band str band name used to rank which unserpervised class is water. If None then first band name in bands is used. default = None None ranking str method to rank the classes by rank_band . Options are 'min' or 'max'. If 'min', then the lowest class mean is considered water. default = 'min' 'min' region ee.Geometry | None region to sample values for KMeans clustering, if set to None will use img.geometry(). default = None None samples int number of stratified samples to gather for clustering from the initial water/no-water map. default=500 required seed int random number generator seed for sampling. default = 7 7 scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 proba_threshold float probability threshold to create a binary water mask, should be in range of 0-1. If None, then the probability values are returned. default = None None Source code in hydrafloods/thresholding.py def multidim_semisupervised ( img , bands , rank_band = None , ranking = \"min\" , region = None , n_samples = 500 , seed = 7 , scale = 90 , proba_threshold = None , ): \"\"\"Implementation of the Automatic water detection from multidimensional hierarchical clustering algorithm. Method details: https://doi.org/10.1016/j.rse.2020.112209 Note: this is a similar method, not exact from the paper args: img (ee.Image): input image to thresholding algorithm bands (list | ee.List): band names to use for the semi supervised classification rank_band (str, optional): band name used to rank which unserpervised class is water. If None then first band name in `bands` is used. default = None ranking (str, optional): method to rank the classes by `rank_band`. Options are 'min' or 'max'. If 'min', then the lowest class mean is considered water. default = 'min' region (ee.Geometry | None, optional): region to sample values for KMeans clustering, if set to `None` will use img.geometry(). default = None samples (int, optional): number of stratified samples to gather for clustering from the initial water/no-water map. default=500 seed (int, optional): random number generator seed for sampling. default = 7 scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 proba_threshold (float, optional): probability threshold to create a binary water mask, should be in range of 0-1. If None, then the probability values are returned. default = None \"\"\" if region is None : region = img . geometry () if bands is None : bands = img . bandNames () else : bands = ee . List ( bands ) if rank_band is None : rank_band = ee . String ( bands . get ( 0 )) samples = img . select ( bands ) . sample ( region = region , scale = scale , numPixels = n_samples , seed = seed , dropNulls = True , tileScale = 16 , ) classifier = ml . unsupervised_rf ( 100 , samples , features = bands , rank_feature = rank_band , ranking = ranking ) probas = img . select ( bands ) . classify ( classifier ) if proba_threshold is None : output = probas . rename ( \"water_proba\" ) else : output = probas . gt ( proba_threshold ) . rename ( \"water\" ) . uint8 () return output otsu ( histogram ) Otsu's method threhsolding algorithm. Computes single intensity threshold that separate histogram into two classes, foreground and background Parameters: Name Type Description Default histogram ee.Dictionary computed object from ee.Reducer.histogram with keys \"histogram\" and \"bucketMeans\" required Returns: Type Description ee.Number value of maximum inter-class intensity variance based on histogram Source code in hydrafloods/thresholding.py def otsu ( histogram ): \"\"\"Otsu's method threhsolding algorithm. Computes single intensity threshold that separate histogram into two classes, foreground and background args: histogram (ee.Dictionary): computed object from ee.Reducer.histogram with keys \"histogram\" and \"bucketMeans\" returns: ee.Number: value of maximum inter-class intensity variance based on histogram \"\"\" counts = ee . Array ( ee . Dictionary ( histogram ) . get ( \"histogram\" )) means = ee . Array ( ee . Dictionary ( histogram ) . get ( \"bucketMeans\" )) size = means . length () . get ([ 0 ]) total = counts . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) sums = means . multiply ( counts ) . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) mean = sums . divide ( total ) indices = ee . List . sequence ( 1 , size ) # Compute between sum of squares, where each mean partitions the data. def bss_function ( i ): aCounts = counts . slice ( 0 , 0 , i ) aCount = aCounts . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) aMeans = means . slice ( 0 , 0 , i ) aMean = ( aMeans . multiply ( aCounts ) . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) . divide ( aCount ) ) bCount = total . subtract ( aCount ) bMean = sums . subtract ( aCount . multiply ( aMean )) . divide ( bCount ) return aCount . multiply ( aMean . subtract ( mean ) . pow ( 2 )) . add ( bCount . multiply ( bMean . subtract ( mean ) . pow ( 2 )) ) bss = indices . map ( bss_function ) output = means . sort ( bss ) . get ([ - 1 ]) return ee . Number ( output )","title":"thresholding module"},{"location":"thresholding/#hydrafloods.thresholding","text":"","title":"thresholding"},{"location":"thresholding/#hydrafloods.thresholding.bmax_otsu","text":"Implementation of the B-Max Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None region ee.Geometry | None region to determine threshold, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 initial_threshold float initial estimate of water/no-water for estimating the probabilities of classes in segment. default = 0 0 thresh_no_data float threshold to be used when histogram is empty (likely little to no water present in image). default = -0.2 None invert bool boolean switch to determine if to threshold greater than (True) or less than (False). default = False False grid_size float size in decimal degrees to tile image/region to check for bimodality. default = 0.1 0.1 bmax_threshold float value 0-1 to determine if a value of bmax is bimodal or not. default = 0.75 0.75 iters int number of iterations to successively shrink the bmax tiles to refine threshold. 1 uses defined grid_size. default = 1 1 max_boxes int maximum number of tiles/boxes to use when determining threshold, will select based on maximum bmax ordering. default = None 100 seed int random number generator seed for randomly selected max_boxes. default = 7 7 max_buckets int The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 255 min_bucket_width float The minimum histogram bucket width to allow any power of 2. default = 0.001 0.001 max_raw int The number of values to accumulate before building the initial histogram. default = 1e6 1000000.0 return_threshold bool boolean switch, if set to true then function will return threshold number, else thresholded image. default = False False Returns: Type Description ee.Image thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm Source code in hydrafloods/thresholding.py @decorators . keep_attrs def bmax_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , thresh_no_data = None , invert = False , grid_size = 0.1 , bmax_threshold = 0.75 , iters = 1 , max_boxes = 100 , seed = 7 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1e6 , return_threshold = False , ): \"\"\"Implementation of the B-Max Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 args: img (ee.Image): input image to thresholding algorithm band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None region (ee.Geometry | None, optional): region to determine threshold, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 initial_threshold (float, optional): initial estimate of water/no-water for estimating the probabilities of classes in segment. default = 0 thresh_no_data (float, optional): threshold to be used when histogram is empty (likely little to no water present in image). default = -0.2 invert (bool, optional): boolean switch to determine if to threshold greater than (True) or less than (False). default = False grid_size (float, optional): size in decimal degrees to tile image/region to check for bimodality. default = 0.1 bmax_threshold (float, optional): value 0-1 to determine if a value of bmax is bimodal or not. default = 0.75 iters (int, optional): number of iterations to successively shrink the bmax tiles to refine threshold. 1 uses defined grid_size. default = 1 max_boxes (int, optional): maximum number of tiles/boxes to use when determining threshold, will select based on maximum bmax ordering. default = None seed (int, optional): random number generator seed for randomly selected max_boxes. default = 7 max_buckets (int, optional): The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 min_bucket_width (float, optional): The minimum histogram bucket width to allow any power of 2. default = 0.001 max_raw (int, optional): The number of values to accumulate before building the initial histogram. default = 1e6 return_threshold (bool, optional): boolean switch, if set to true then function will return threshold number, else thresholded image. default = False returns: ee.Image: thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm \"\"\" def calcBmax ( feature ): \"\"\"Closure function to calculate Bmax for each feature covering image\"\"\" segment = img initial = segment . lt ( initial_threshold ) p1 = ee . Number ( initial . reduceRegion ( reducer = ee . Reducer . mean (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) . get ( histBand ) ) p1 = ee . Number ( ee . Algorithms . If ( p1 , p1 , 0.9999 )) p2 = ee . Number ( 1 ) . subtract ( p1 ) m = ( segment . updateMask ( initial ) . rename ( \"m1\" ) . addBands ( segment . updateMask ( initial . Not ()) . rename ( \"m2\" )) ) mReduced = m . reduceRegion ( reducer = ee . Reducer . mean (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) m1 = ee . Number ( mReduced . get ( \"m1\" )) m2 = ee . Number ( mReduced . get ( \"m2\" )) m1 = ee . Number ( ee . Algorithms . If ( m1 , m1 , - 25 )) m2 = ee . Number ( ee . Algorithms . If ( m2 , m2 , 0 )) sigmab = p1 . multiply ( p2 . multiply ( m1 . subtract ( m2 ) . pow ( 2 ))) sigmat = ee . Number ( segment . reduceRegion ( reducer = ee . Reducer . variance (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) . get ( histBand ) ) sigmat = ee . Number ( ee . Algorithms . If ( sigmat , sigmat , 2 )) bmax = sigmab . divide ( sigmat ) return feature . set ({ \"bmax\" : bmax }) if band is None : img = img . select ([ 0 ]) histBand = ee . String ( img . bandNames () . get ( 0 )) else : histBand = ee . String ( band ) img = img . select ( histBand ) if region is None : region = img . geometry () grid = geeutils . tile_region ( region , centroid_within = region , grid_size = grid_size ) bmaxes = grid . map ( calcBmax ) . filter ( ee . Filter . gt ( \"bmax\" , bmax_threshold )) if iters > 1 : for i in range ( iters - 1 ): grid_size /= 2.0 grid = geeutils . tile_region ( bmaxes . geometry (), centroid_within = bmaxes , grid_size = grid_size ) bmaxes = grid . map ( calcBmax ) . filter ( ee . Filter . gt ( \"bmax\" , bmax_threshold )) if max_boxes is not None : selection = bmaxes . limit ( max_boxes , \"bmax\" ) else : selection = bmaxes histogram = img . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), selection , scale , bestEffort = True , tileScale = 16 , ) if thresh_no_data is not None : threshold = ee . Number ( ee . Algorithms . If ( ee . Dictionary ( histogram . get ( histBand . cat ( \"_histogram\" ))) . contains ( \"bucketMeans\" ), otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))), thresh_no_data , ) ) else : threshold = otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))) if return_threshold is True : return ee . Image ( threshold ) else : water = ee . Image ( ee . Algorithms . If ( invert , img . gt ( threshold ), img . lt ( threshold ))) return water . rename ( \"water\" ) . uint8 ()","title":"bmax_otsu()"},{"location":"thresholding/#hydrafloods.thresholding.edge_otsu","text":"Implementation of the Edge Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None region ee.Geometry | None region to determine threshold, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 initial_threshold float initial estimate of water/no-water for estimating the edges. default = 0 0 thresh_no_data float threshold to be used when histogram is empty (likely little to no water present in image). default = -0.2 None invert bool boolean switch to determine if to threshold greater than (True) or less than (False). default = False False canny_threshold float threshold for canny edge detection. default = 0.05 0.05 canny_sigma float sigma value for gaussian filter in canny edge detection. default = 0 0 canny_lt float lower threshold for canny detection. default = 0.05 0.05 connected_pixels int maximum size of the neighborhood in pixels to determine if connected. default = 200 200 edge_length int minimum length of edges from canny detection to be considered edge. default = 50 50 edge_buffer int distance in meters to buffer edges on a side for histogram sampling. default = 100 100 max_buckets int The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 255 min_bucket_width float The minimum histogram bucket width to allow any power of 2. default = 0.001 0.001 max_raw int The number of values to accumulate before building the initial histogram. default = 1e6 1000000.0 return_threshold bool boolean switch, if set to true then function will return threshold number, else thresholded image. default = False False Returns: Type Description ee.Image thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm Source code in hydrafloods/thresholding.py @decorators . keep_attrs def edge_otsu ( img , band = None , region = None , scale = 90 , initial_threshold = 0 , thresh_no_data = None , invert = False , canny_threshold = 0.05 , canny_sigma = 0 , canny_lt = 0.05 , connected_pixels = 200 , edge_length = 50 , edge_buffer = 100 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1e6 , return_threshold = False , ): \"\"\"Implementation of the Edge Otsu thresholding algorithm. Detailed explanation of algorithm can be found at https://doi.org/10.3390/rs12152469 args: img (ee.Image): input image to thresholding algorithm band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None region (ee.Geometry | None, optional): region to determine threshold, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 initial_threshold (float, optional): initial estimate of water/no-water for estimating the edges. default = 0 thresh_no_data (float, optional): threshold to be used when histogram is empty (likely little to no water present in image). default = -0.2 invert (bool, optional): boolean switch to determine if to threshold greater than (True) or less than (False). default = False canny_threshold (float, optional): threshold for canny edge detection. default = 0.05 canny_sigma (float, optional): sigma value for gaussian filter in canny edge detection. default = 0 canny_lt (float, optional): lower threshold for canny detection. default = 0.05 connected_pixels (int, optional): maximum size of the neighborhood in pixels to determine if connected. default = 200 edge_length (int, optional): minimum length of edges from canny detection to be considered edge. default = 50 edge_buffer (int, optional): distance in meters to buffer edges on a side for histogram sampling. default = 100 max_buckets (int, optional): The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 min_bucket_width (float, optional): The minimum histogram bucket width to allow any power of 2. default = 0.001 max_raw (int, optional): The number of values to accumulate before building the initial histogram. default = 1e6 return_threshold (bool, optional): boolean switch, if set to true then function will return threshold number, else thresholded image. default = False returns: ee.Image: thresholded image based (if return_threshold==False) or threshold value (if return_threshold==True) based on the threshold determined by the algorithm \"\"\" if band is None : img = img . select ([ 0 ]) histBand = ee . String ( img . bandNames () . get ( 0 )) else : histBand = ee . String ( band ) img = img . select ( histBand ) if region is None : region = img . geometry () binary = img . lt ( initial_threshold ) . rename ( \"binary\" ) # get canny edges canny = ee . Algorithms . CannyEdgeDetector ( binary , canny_threshold , canny_sigma ) # process canny edges connected = ( canny . mask ( canny ) . lt ( canny_lt ) . connectedPixelCount ( connected_pixels , True ) ) edges = connected . gte ( edge_length ) edgeBuffer = edges . focal_max ( edge_buffer , \"square\" , \"meters\" ) # mask out areas to get histogram for Otsu histogram_image = img . updateMask ( edgeBuffer ) histogram = histogram_image . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), region , scale , bestEffort = True , tileScale = 16 , ) if thresh_no_data is not None : threshold = ee . Number ( ee . Algorithms . If ( ee . Dictionary ( histogram . get ( histBand . cat ( \"_histogram\" ))) . contains ( \"bucketMeans\" ), otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))), thresh_no_data , ) ) else : threshold = otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))) if return_threshold is True : return threshold else : water = ee . Image ( ee . Algorithms . If ( invert , img . gt ( threshold ), img . lt ( threshold ))) return water . rename ( \"water\" ) . uint8 ()","title":"edge_otsu()"},{"location":"thresholding/#hydrafloods.thresholding.fuzzy_otsu","text":"Implementation of Otsu thresholding algorithm. Segment the grids into water and land representation using initial threshold and randomly select features to calculate minimum and maximum threshold of the image. Calculate Midpoint of min and max threshold using Fuzzy_Gaussian to map water. Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None region ee.Geometry | None region to determine threshold, if set to None will use img.geometry(). default = None None scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 initial_threshold float initial estimate of water/no-water for estimating the probabilities of classes in segment. default = -15.5 -15.5 grid_size float size in decimal degrees to tile image/region to check for bimodality. default = 0.1 0.1 max_boxes int maximum number of tiles/boxes to use when determining threshold. default = 20 20 seed int random number generator seed for randomly selected max_boxes. default = 7 0 max_buckets int The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 255 min_bucket_width float The minimum histogram bucket width to allow any power of 2. default = 0.001 0.001 max_raw int The number of values to accumulate before building the initial histogram. default = 1e6 1000000.0 Returns: Type Description ee.Image thresholded water image. Source code in hydrafloods/thresholding.py @decorators . keep_attrs def fuzzy_otsu ( img , band = None , region = None , scale = 90 , initial_threshold =- 15.5 , grid_size = 0.1 , max_boxes = 20 , seed = 0 , max_buckets = 255 , min_bucket_width = 0.001 , max_raw = 1e6 , ): \"\"\"Implementation of Otsu thresholding algorithm. Segment the grids into water and land representation using initial threshold and randomly select features to calculate minimum and maximum threshold of the image. Calculate Midpoint of min and max threshold using Fuzzy_Gaussian to map water. args: img (ee.Image): input image to thresholding algorithm band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None region (ee.Geometry | None, optional): region to determine threshold, if set to `None` will use img.geometry(). default = None scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 initial_threshold (float, optional): initial estimate of water/no-water for estimating the probabilities of classes in segment. default = -15.5 grid_size (float, optional): size in decimal degrees to tile image/region to check for bimodality. default = 0.1 max_boxes (int, optional): maximum number of tiles/boxes to use when determining threshold. default = 20 seed (int, optional): random number generator seed for randomly selected max_boxes. default = 7 max_buckets (int, optional): The maximum number of buckets to use when building a histogram; will be rounded up to a power of 2. default = 255 min_bucket_width (float, optional): The minimum histogram bucket width to allow any power of 2. default = 0.001 max_raw (int, optional): The number of values to accumulate before building the initial histogram. default = 1e6 returns: ee.Image: thresholded water image. \"\"\" # Function to Segment Land and Water Grids def segment_grid ( feature ): counts = initImg . reduceRegion ( reducer = ee . Reducer . sum (), geometry = feature . geometry (), bestEffort = True , scale = scale , ) return feature . set ( counts ) if region is None : region = img . geometry () if band is None : img = img . select ([ 0 ]) histBand = ee . String ( img . bandNames () . get ( 0 )) else : histBand = ee . String ( band ) img = img . select ( histBand ) grid = geeutils . tile_region ( region , intersect_geom = region , grid_size = grid_size ) # Prepare good representation of water and land initWater = img . lt ( initial_threshold ) . rename ( \"water\" ) initImg = initWater . addBands ( initWater . Not () . rename ( \"land\" )) grid = grid . map ( segment_grid ) # Select water and land grid selection = grid . filter ( ee . Filter . And ( ee . Filter . gt ( \"water\" , 1000 ), ee . Filter . gt ( \"land\" , 1000 )) ) # Randomly select features selection = selection . randomColumn ( \"random\" ) nBoxes = ee . Number ( selection . size ()) randomSelection = ee . Number ( max_boxes ) . divide ( nBoxes ) selection = selection . filter ( ee . Filter . lt ( \"random\" , randomSelection )) # Create histogram for selected features to calculate min threshold histogram = img . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), selection . geometry (), scale , bestEffort = True , tileScale = 16 , ) min_threshold = otsu ( histogram . get ( histBand . cat ( \"_histogram\" ))) # Create histogram to calculate max threshold histogram2 = img . updateMask ( img . lt ( min_threshold )) . reduceRegion ( ee . Reducer . histogram ( max_buckets , min_bucket_width , max_raw ) . combine ( \"mean\" , None , True ) . combine ( \"variance\" , None , True ), selection . geometry (), scale , bestEffort = True , tileScale = 16 , ) max_threshold = otsu ( histogram2 . get ( histBand . cat ( \"_histogram\" ))) # Calculate Midpoint of min and max threshold using Fuzzy_Gaussian midpoint = ee . Number ( ee . Number ( min_threshold ) . add ( ee . Number ( max_threshold ))) . divide ( 2 ) spread = 0.2 gauss = fuzzy . fuzzy_gaussian ( img , midpoint , spread ) . clip ( region ) waterImg = img . lt ( midpoint ) waterImg = waterImg . where ( waterImg . eq ( 0 ), gauss ) return ee . Image ( waterImg )","title":"fuzzy_otsu()"},{"location":"thresholding/#hydrafloods.thresholding.kmeans_extent","text":"Water thresholding methodology using image values and HAND. Method from https://doi.org/10.1016/j.rse.2020.111732 Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required hand ee.Image Height Above Nearest Drainage image used as axis in clustering required initial_threshold float initial estimate of water/no-water for stratified sampling. default = 0 0 region ee.Geometry | None region to sample values for KMeans clustering, if set to None will use img.geometry(). default = None None band str | None,optional band name to use for thresholding, if set to None will use first band in image. default = None None samples int number of stratified samples to gather for clustering from the initial water/no-water map. default=500 required seed int random number generator seed for sampling. default = 7 7 scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 Returns: Type Description ee.Image clustered image from KMeans clusterer. Classes assumed to be water/no-water Source code in hydrafloods/thresholding.py def kmeans_extent ( img , hand , initial_threshold = 0 , region = None , band = None , n_samples = 500 , seed = 7 , invert = False , scale = 90 , ): \"\"\"Water thresholding methodology using image values and HAND. Method from https://doi.org/10.1016/j.rse.2020.111732 args: img (ee.Image): input image to thresholding algorithm hand (ee.Image): Height Above Nearest Drainage image used as axis in clustering initial_threshold (float, optional): initial estimate of water/no-water for stratified sampling. default = 0 region (ee.Geometry | None, optional): region to sample values for KMeans clustering, if set to `None` will use img.geometry(). default = None band (str | None,optional): band name to use for thresholding, if set to `None` will use first band in image. default = None samples (int, optional): number of stratified samples to gather for clustering from the initial water/no-water map. default=500 seed (int, optional): random number generator seed for sampling. default = 7 scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 returns: ee.Image: clustered image from KMeans clusterer. Classes assumed to be water/no-water \"\"\" def _cluster_center ( x ): return ee . Number ( ( band_arr . mask ( classes . eq ( ee . Number ( x ))) . reduce ( ee . Reducer . mean (), [ 0 ]) ) . get ([ 0 ]) ) if region is None : region = img . geometry () if band is None : img = img . select ([ 0 ]) band = ee . String ( img . bandNames () . get ( 0 )) else : img = img . select ( band ) hand_band = ee . String ( hand . bandNames () . get ( 0 )) # convert invert to a number 0 or 1 for ee server-side invert = 1 if invert else 0 img = img . addBands ( hand . unmask ( 0 )) strata = img . select ( band ) . gt ( initial_threshold ) . rename ( \"strata\" ) samples = img . addBands ( strata ) . stratifiedSample ( numPoints = n_samples , classBand = \"strata\" , region = region , scale = scale , classValues = [ 0 , 1 ], classPoints = [ n_samples , n_samples ], tileScale = 16 , seed = seed , ) clusterer = ee . Clusterer . wekaKMeans ( 2 , 1 ) . train ( samples , [ band , hand_band ]) samples = samples . cluster ( clusterer , \"classes\" ) classes = samples . aggregate_array ( \"classes\" ) unique = classes . distinct () . sort () classes = ee . Array ( classes ) band_arr = ee . Array ( samples . aggregate_array ( band )) class_means = unique . map ( _cluster_center ) min_mean = class_means . reduce ( ee . Reducer . min ()) water_class = class_means . indexOf ( min_mean ) water = img . cluster ( clusterer ) water = ee . Image ( ee . Algorithms . If ( water_class . eq ( 0 ), water . Not (), water )) return water . rename ( \"water\" ) . uint8 ()","title":"kmeans_extent()"},{"location":"thresholding/#hydrafloods.thresholding.modis_flood","text":"Implementation of the NASA MODIS Flood algorithm. Expects that imagery has https://cdn.earthdata.nasa.gov/conduit/upload/17162/MCDWD_UserGuide_RevB.pdf Parameters: Name Type Description Default img ee.Image image to apply algorithm to, should be either MODIS or VIIRS sensor data required Returns: Type Description ee.Image resulting water map Source code in hydrafloods/thresholding.py @decorators . keep_attrs def modis_flood ( img ): \"\"\"Implementation of the NASA MODIS Flood algorithm. Expects that imagery has https://cdn.earthdata.nasa.gov/conduit/upload/17162/MCDWD_UserGuide_RevB.pdf args: img (ee.Image): image to apply algorithm to, should be either MODIS or VIIRS sensor data returns: ee.Image: resulting water map \"\"\" # coefficients for the algorithm a = 0.0013500 b = 0.10811 c = 0.7 d = 0.2027 e = 0.06757 water = img . expression ( \"((nir+a)/(red+b) < c) and (red < d) and (swir2 < e)\" ,{ \"red\" : img . select ( \"red\" ), \"nir\" : img . select ( \"nir\" ), \"swir2\" : img . select ( \"swir2\" ), \"a\" : a , \"b\" : b , \"c\" : c , \"d\" : d , \"e\" : e }) . uint8 () . rename ( \"water\" ) return water","title":"modis_flood()"},{"location":"thresholding/#hydrafloods.thresholding.multidim_semisupervised","text":"Implementation of the Automatic water detection from multidimensional hierarchical clustering algorithm. Method details: https://doi.org/10.1016/j.rse.2020.112209 Note: this is a similar method, not exact from the paper Parameters: Name Type Description Default img ee.Image input image to thresholding algorithm required bands list | ee.List band names to use for the semi supervised classification required rank_band str band name used to rank which unserpervised class is water. If None then first band name in bands is used. default = None None ranking str method to rank the classes by rank_band . Options are 'min' or 'max'. If 'min', then the lowest class mean is considered water. default = 'min' 'min' region ee.Geometry | None region to sample values for KMeans clustering, if set to None will use img.geometry(). default = None None samples int number of stratified samples to gather for clustering from the initial water/no-water map. default=500 required seed int random number generator seed for sampling. default = 7 7 scale int scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 90 proba_threshold float probability threshold to create a binary water mask, should be in range of 0-1. If None, then the probability values are returned. default = None None Source code in hydrafloods/thresholding.py def multidim_semisupervised ( img , bands , rank_band = None , ranking = \"min\" , region = None , n_samples = 500 , seed = 7 , scale = 90 , proba_threshold = None , ): \"\"\"Implementation of the Automatic water detection from multidimensional hierarchical clustering algorithm. Method details: https://doi.org/10.1016/j.rse.2020.112209 Note: this is a similar method, not exact from the paper args: img (ee.Image): input image to thresholding algorithm bands (list | ee.List): band names to use for the semi supervised classification rank_band (str, optional): band name used to rank which unserpervised class is water. If None then first band name in `bands` is used. default = None ranking (str, optional): method to rank the classes by `rank_band`. Options are 'min' or 'max'. If 'min', then the lowest class mean is considered water. default = 'min' region (ee.Geometry | None, optional): region to sample values for KMeans clustering, if set to `None` will use img.geometry(). default = None samples (int, optional): number of stratified samples to gather for clustering from the initial water/no-water map. default=500 seed (int, optional): random number generator seed for sampling. default = 7 scale (int, optional): scale at which to perform reduction operations, setting higher will prevent OOM errors. default = 90 proba_threshold (float, optional): probability threshold to create a binary water mask, should be in range of 0-1. If None, then the probability values are returned. default = None \"\"\" if region is None : region = img . geometry () if bands is None : bands = img . bandNames () else : bands = ee . List ( bands ) if rank_band is None : rank_band = ee . String ( bands . get ( 0 )) samples = img . select ( bands ) . sample ( region = region , scale = scale , numPixels = n_samples , seed = seed , dropNulls = True , tileScale = 16 , ) classifier = ml . unsupervised_rf ( 100 , samples , features = bands , rank_feature = rank_band , ranking = ranking ) probas = img . select ( bands ) . classify ( classifier ) if proba_threshold is None : output = probas . rename ( \"water_proba\" ) else : output = probas . gt ( proba_threshold ) . rename ( \"water\" ) . uint8 () return output","title":"multidim_semisupervised()"},{"location":"thresholding/#hydrafloods.thresholding.otsu","text":"Otsu's method threhsolding algorithm. Computes single intensity threshold that separate histogram into two classes, foreground and background Parameters: Name Type Description Default histogram ee.Dictionary computed object from ee.Reducer.histogram with keys \"histogram\" and \"bucketMeans\" required Returns: Type Description ee.Number value of maximum inter-class intensity variance based on histogram Source code in hydrafloods/thresholding.py def otsu ( histogram ): \"\"\"Otsu's method threhsolding algorithm. Computes single intensity threshold that separate histogram into two classes, foreground and background args: histogram (ee.Dictionary): computed object from ee.Reducer.histogram with keys \"histogram\" and \"bucketMeans\" returns: ee.Number: value of maximum inter-class intensity variance based on histogram \"\"\" counts = ee . Array ( ee . Dictionary ( histogram ) . get ( \"histogram\" )) means = ee . Array ( ee . Dictionary ( histogram ) . get ( \"bucketMeans\" )) size = means . length () . get ([ 0 ]) total = counts . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) sums = means . multiply ( counts ) . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) mean = sums . divide ( total ) indices = ee . List . sequence ( 1 , size ) # Compute between sum of squares, where each mean partitions the data. def bss_function ( i ): aCounts = counts . slice ( 0 , 0 , i ) aCount = aCounts . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) aMeans = means . slice ( 0 , 0 , i ) aMean = ( aMeans . multiply ( aCounts ) . reduce ( ee . Reducer . sum (), [ 0 ]) . get ([ 0 ]) . divide ( aCount ) ) bCount = total . subtract ( aCount ) bMean = sums . subtract ( aCount . multiply ( aMean )) . divide ( bCount ) return aCount . multiply ( aMean . subtract ( mean ) . pow ( 2 )) . add ( bCount . multiply ( bMean . subtract ( mean ) . pow ( 2 )) ) bss = indices . map ( bss_function ) output = means . sort ( bss ) . get ([ - 1 ]) return ee . Number ( output )","title":"otsu()"},{"location":"timeseries/","text":"hydrafloods.timeseries add_harmonic_coefs ( image , n_cycles = 2 ) Function to add harmonic coefficients as bands to images Harmonic coefficients are calculated as sin and cos of frequency within year Parameters: Name Type Description Default image ee.Image image object to add harmonic coefficiencts to. Expects that image has time band required n_cycles int number of interannual cycles to include. default = 2 2 Returns: Type Description ee.Image image with harmonic coefficient bands added Source code in hydrafloods/timeseries.py def add_harmonic_coefs ( image , n_cycles = 2 ): \"\"\"Function to add harmonic coefficients as bands to images Harmonic coefficients are calculated as sin and cos of frequency within year args: image (ee.Image): image object to add harmonic coefficiencts to. Expects that image has time band n_cycles (int, optional): number of interannual cycles to include. default = 2 returns: ee.Image: image with harmonic coefficient bands added \"\"\" cosNames = _get_names ( \"cos\" , n_cycles ) sinNames = _get_names ( \"sin\" , n_cycles ) frequencyImg = ee . Image . constant ( ee . List . sequence ( 1 , n_cycles )) timeRadians = image . select ( \"time\" ) . multiply ( 2 * math . pi ) cosines = timeRadians . multiply ( frequencyImg ) . cos () . rename ( cosNames ) sines = timeRadians . multiply ( frequencyImg ) . sin () . rename ( sinNames ) return image . addBands ( cosines ) . addBands ( sines ) add_time_band ( img , offset = 'year' , apply_mask = False ) Function to add time band to image. Expects image has system:time_start property. Added band will have name \"time\" Parameters: Name Type Description Default img ee.Image image with system:time_start to add time band too required offset str units to calculate from 1970-01-01. default = \"year\" 'year' apply_mask bool boolean switch to apply image mask to time band. if False, then time band will have full coverage False Returns: Type Description ee.Image image object with time band added Source code in hydrafloods/timeseries.py def add_time_band ( img , offset = \"year\" , apply_mask = False ): \"\"\"Function to add time band to image. Expects image has `system:time_start` property. Added band will have name \"time\" args: img (ee.Image): image with `system:time_start` to add time band too offset (str, optional): units to calculate from 1970-01-01. default = \"year\" apply_mask (bool, optional): boolean switch to apply image mask to time band. if False, then time band will have full coverage returns: ee.Image: image object with time band added \"\"\" t = img . date () tDiff = t . difference ( ee . Date ( \"1970-01-01\" ), offset ) time = ee . Image ( tDiff ) . float () . rename ( \"time\" ) if apply_mask : time = time . updateMask ( img . select ([ 0 ]) . mask ()) return img . addBands ( time ) anomalies ( collection , baseline ) Function to calculate anomalies of Source code in hydrafloods/timeseries.py def anomalies ( collection , baseline ): \"\"\"Function to calculate anomalies of\"\"\" @decorators . keep_attrs def img_anomaly ( img ): return img . subtract ( baseline ) return collection . map ( img_anomaly ) fit_harmonic_trend ( collection , n_cycles = 2 , independents = [ 'constant' , 'time' ], dependent = None , output_err = False ) Function to fit a harmonic trend on image collection along the time dimension. Uses ee.Reducer.linearRegression to solve for coefficients Parameters: Name Type Description Default collection ee.ImageCollection | hydrafloods.Dataset image collection to fit trend line for required n_cycles int number of interannual cycles to model. default = 2 2 independents list[str] list of band names to use for fitting regression. default = [\"constant\", \"time\"] ['constant', 'time'] dependent str | None band name of values to fit, if None then uses the first band. default = None None output_err bool switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False False Returns: Type Description ee.Image output image with regression coeffients as bands named \"constant\", \"time\", \"cos_n\", and \"sin_n\" where n is a sequnces of cycles. Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True Exceptions: Type Description ValueError if collection is not of type ee.ImageCollection or hydrafloods.Dataset Source code in hydrafloods/timeseries.py def fit_harmonic_trend ( collection , n_cycles = 2 , independents = [ \"constant\" , \"time\" ], dependent = None , output_err = False , ): \"\"\"Function to fit a harmonic trend on image collection along the time dimension. Uses ee.Reducer.linearRegression to solve for coefficients args: collection (ee.ImageCollection | hydrafloods.Dataset): image collection to fit trend line for n_cycles (int, optional): number of interannual cycles to model. default = 2 independents (list[str], optional): list of band names to use for fitting regression. default = [\"constant\", \"time\"] dependent (str | None, optional): band name of values to fit, if None then uses the first band. default = None output_err (bool, optional): switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False returns: ee.Image: output image with regression coeffients as bands named \"constant\", \"time\", \"cos_n\", and \"sin_n\" where n is a sequnces of cycles. Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True raises: ValueError: if collection is not of type ee.ImageCollection or hydrafloods.Dataset \"\"\" if not isinstance ( collection , ee . ImageCollection ): try : collection = collection . collection except AttributeError : raise ValueError ( \"collection argument expected type ee.ImageCollection or hydrafloods.Dataset,\" + f \"got { type ( collection ) } \" ) if dependent is None : dependent = ee . String ( ee . Image ( collection . first ()) . bandNames () . get ( 0 )) else : dependent = ee . String ( dependent ) independents = ( ee . List ( independents ) . cat ( _get_names ( \"cos\" , n_cycles )) . cat ( _get_names ( \"sin\" , n_cycles )) ) _add_coefs = partial ( add_harmonic_coefs , n_cycles = n_cycles ) harmonic_collection = prep_inputs ( collection , keep_bands = [ dependent ], apply_mask = True ) . map ( _add_coefs ) harmonic_trend = harmonic_collection . select ( independents . add ( dependent )) . reduce ( ee . Reducer . linearRegression ( numX = independents . length (), numY = 1 ), 16 ) n = harmonic_collection . select ( dependent ) . reduce ( ee . Reducer . count (), 16 ) . rename ( \"n\" ) # Turn the array image into a multi-band image of coefficients harmonic_coefficients = ( harmonic_trend . select ( \"coefficients\" ) . arrayProject ([ 0 ]) . arrayFlatten ([ independents ]) ) . addBands ( n ) if output_err : harmonic_mse = ( harmonic_trend . select ( \"residuals\" ) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"residual_y\" ]]) ) t_mean = ( harmonic_collection . select ( \"time\" ) . reduce ( ee . Reducer . mean (), 16 ) . rename ( \"mean_x\" ) ) x_err = ( harmonic_collection . select ( \"time\" ) . map ( lambda x : x . subtract ( t_mean ) . pow ( 2 )) . reduce ( ee . Reducer . sum (), 16 ) . rename ( \"residual_x\" ) ) harmonic_coefficients = ee . Image . cat ( [ harmonic_coefficients , harmonic_mse , t_mean , x_err ] ) return harmonic_coefficients fit_linear_trend ( collection , independents = [ 'constant' , 'time' ], dependent = None , regression_method = 'ols' , output_err = False ) Function to fit a linear reducer on image collection along the time dimension. Parameters: Name Type Description Default collection ee.ImageCollection image collection to fit trend line for required independents list[str] list of band names to use for fitting regression. default = [\"constant\", \"time\"] ['constant', 'time'] dependent str | None band name of values to fit, if None then uses the first band. default = None None regression_method str name of regression reducer to use. options are \"simple\", \"ols\", \"robust\", \"ridge\", \"sen\". default = \"ols\" 'ols' output_err bool switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False False Returns: Type Description ee.Image output image with regression coeffients as bands named \"offset\" and \"slope\". Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True Source code in hydrafloods/timeseries.py def fit_linear_trend ( collection , independents = [ \"constant\" , \"time\" ], dependent = None , regression_method = \"ols\" , output_err = False , ): \"\"\"Function to fit a linear reducer on image collection along the time dimension. args: collection (ee.ImageCollection): image collection to fit trend line for independents (list[str], optional): list of band names to use for fitting regression. default = [\"constant\", \"time\"] dependent (str | None, optional): band name of values to fit, if None then uses the first band. default = None regression_method (str, optional): name of regression reducer to use. options are \"simple\", \"ols\", \"robust\", \"ridge\", \"sen\". default = \"ols\" output_err (bool, optional): switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False returns: ee.Image: output image with regression coeffients as bands named \"offset\" and \"slope\". Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True \"\"\" independents = ee . List ( independents ) if dependent is None : dependent = ee . String ( ee . Image ( collection . first ()) . bandNames () . get ( 0 )) else : dependent = ee . String ( dependent ) methods = [ \"simple\" , \"ols\" , \"robust\" , \"ridge\" , \"sen\" ] reducers = [ ee . Reducer . linearFit (), ee . Reducer . linearRegression ( independents . length (), 1 ), ee . Reducer . robustLinearRegression ( independents . length (), 1 ), ee . Reducer . ridgeRegression ( independents . length (), 1 ), ee . Reducer . sensSlope (), ] method_lookup = { v : reducers [ i ] for i , v in enumerate ( methods )} if regression_method not in methods : raise ValueError () else : lin_reducer = method_lookup [ regression_method ] if not isinstance ( collection , ee . ImageCollection ): collection = collection . collection reduction_coll = prep_inputs ( collection , keep_bands = [ dependent ], apply_mask = True ) . select ( independents . add ( dependent )) n = reduction_coll . select ( dependent ) . reduce ( \"count\" ) . rename ( \"n\" ) if regression_method in [ \"sen\" , \"ridge\" ]: independents = ee . List ([ \"constant\" ]) . cat ( independents ) if regression_method == \"sen\" : lr = reduction_coll . reduce ( lin_reducer , 16 ) . select ( [ \"offset\" , \"slope\" ], independents ) else : lr_arr = reduction_coll . reduce ( lin_reducer , 16 ) lr = ( lr_arr . select ([ \"coefficients\" ]) . arrayProject ([ 0 ]) . arrayFlatten ([ independents ]) ) if output_err and regression_method != \"sen\" : linear_mse = ( lr_arr . select ( \"residuals\" ) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"residual_y\" ]]) ) t_mean = reduction_coll . select ( \"time\" ) . mean () . rename ( \"mean_x\" ) x_err = ( reduction_coll . select ( \"time\" ) . map ( lambda x : x . subtract ( t_mean ) . pow ( 2 )) . reduce ( ee . Reducer . sum (), 16 ) . rename ( \"residual_x\" ) ) lr = ee . Image . cat ([ lr , linear_mse , t_mean , x_err ]) return lr . addBands ( n ) get_dummy_collection ( start_time = None , end_time = None , dates = None ) Helper function to create image collection of images to apply time series prediction on Creates daily imagery between start_time and end_time Parameters: Name Type Description Default start_time str | ee.Date string or ee.Date string to start creating images on (inclusive) None end_time str | ee.Date string or ee.Date string to end creating images on (exclusive) None Returns: Type Description ee.ImageCollection image collection with image containing time and constant bands Source code in hydrafloods/timeseries.py def get_dummy_collection ( start_time = None , end_time = None , dates = None ): \"\"\"Helper function to create image collection of images to apply time series prediction on Creates daily imagery between start_time and end_time args: start_time (str | ee.Date): string or ee.Date string to start creating images on (inclusive) end_time (str | ee.Date): string or ee.Date string to end creating images on (exclusive) returns: ee.ImageCollection: image collection with image containing time and constant bands \"\"\" def _gen_image_seq ( i ): t = start_time . advance ( ee . Number ( i ), \"day\" ) return ee . Image () . rename ( \"blank\" ) . set ( \"system:time_start\" , t . millis ()) def _gen_image ( d ): d = ee . Date ( d ) return ee . Image () . rename ( \"blank\" ) . set ( \"system:time_start\" , d . millis ()) if ( start_time is not None ) and ( end_time is not None ): if not isinstance ( start_time , ee . Date ): start_time = ee . Date ( start_time ) if not isinstance ( end_time , ee . Date ): end_time = ee . Date ( end_time ) n = end_time . difference ( start_time , \"day\" ) coll = ee . ImageCollection ( ee . List . sequence ( 0 , n ) . map ( _gen_image_seq )) elif dates is not None : coll = ee . ImageCollection ( dates . map ( _gen_image )) else : raise ValueError ( \"Either 'dates' or 'start_time'/'end_time' need to be defined\" ) return prep_inputs ( coll ) get_dummy_img ( t ) Helper function to get an image readily available to use for predictions Resulting image will include time based on year and constant band of 1 Parameters: Name Type Description Default t str | ee.Date string or ee.Date string to create dummy image for required Returns: Type Description ee.Image image object with time and constant bands Source code in hydrafloods/timeseries.py def get_dummy_img ( t ): \"\"\"Helper function to get an image readily available to use for predictions Resulting image will include time based on year and constant band of 1 args: t (str | ee.Date): string or ee.Date string to create dummy image for returns: ee.Image: image object with time and constant bands \"\"\" if not isinstance ( t , ee . Date ): t = ee . Date ( t ) img = ee . Image . constant ( 1 ) . set ( \"system:time_start\" , t . millis ()) time_band = ( ee . Image ( t . difference ( ee . Date ( \"1970-01-01\" ), \"year\" )) . float () . rename ( \"time\" ) ) return img . addBands ( time_band ) predict_harmonics ( collection , harmonics , n_cycles = 2 , independents = [ 'constant' , 'time' ]) Helper function to apply harmonic trend prediction Parameters: Name Type Description Default collection ee.ImageCollection image collection to apply prediction on required harmonics ee.Image harmonic coefficient image with coeffiecient bands required n_cycles int number of interannual cycles to model, note n_cycles must equal the number of cycle coefficients in harmonics . default = 2 2 independents list[str] list of independent band names to use in model. These are other than the harmonic coefficient names. default = [\"constant\", \"time\"] ['constant', 'time'] returns ee.ImageCollection: image collection with predicted values Source code in hydrafloods/timeseries.py def predict_harmonics ( collection , harmonics , n_cycles = 2 , independents = [ \"constant\" , \"time\" ] ): \"\"\"Helper function to apply harmonic trend prediction args: collection (ee.ImageCollection): image collection to apply prediction on harmonics (ee.Image): harmonic coefficient image with coeffiecient bands n_cycles (int, optional): number of interannual cycles to model, note n_cycles must equal the number of cycle coefficients in `harmonics`. default = 2 independents (list[str], optional): list of independent band names to use in model. These are other than the harmonic coefficient names. default = [\"constant\", \"time\"] returns ee.ImageCollection: image collection with predicted values \"\"\" @decorators . keep_attrs def _apply_prediction ( image ): \"\"\"Closure function to apply prediction\"\"\" return ( image . select ( independents ) . multiply ( harmonics ) . reduce ( \"sum\" ) . rename ( \"predicted\" ) ) independents = ( ee . List ( independents ) . cat ( _get_names ( \"cos\" , n_cycles )) . cat ( _get_names ( \"sin\" , n_cycles )) ) _add_coefs = partial ( add_harmonic_coefs , n_cycles = n_cycles ) harmonic_collection = prep_inputs ( collection ) . map ( _add_coefs ) # Compute fitted values. predicted = harmonic_collection . map ( _apply_prediction ) return predicted prep_inputs ( collection , keep_bands = None , apply_mask = False ) Helper function to prepare inputs into time series algorithms. Will check if each image in collection has a time and constant band, if not it will add to collection Wraps add_time_band() for adding the time band Parameters: Name Type Description Default collection ee.ImageCollection image collection to check and add time/constant band too required keep_bands list[str] | None regex name or list of band names to drop during prep and include in the result Will check if \"time\" or \"constant\" in list, if not then add to collection. default = None None apply_mask bool boolean switch to apply image mask to time band. if False, then time band will have full coverage False Returns: Type Description ee.ImageCollection collection with time and constant bands included Source code in hydrafloods/timeseries.py def prep_inputs ( collection , keep_bands = None , apply_mask = False ): \"\"\"Helper function to prepare inputs into time series algorithms. Will check if each image in collection has a time and constant band, if not it will add to collection Wraps `add_time_band()` for adding the time band args: collection (ee.ImageCollection): image collection to check and add time/constant band too keep_bands (list[str] | None, optional): regex name or list of band names to drop during prep and include in the result Will check if \"time\" or \"constant\" in list, if not then add to collection. default = None apply_mask (bool, optional): boolean switch to apply image mask to time band. if False, then time band will have full coverage returns: ee.ImageCollection: collection with time and constant bands included \"\"\" if not isinstance ( collection , ee . ImageCollection ): collection = collection . collection first = ee . Image ( collection . first ()) outCollection = copy . deepcopy ( collection ) if keep_bands is None : keep_bands = [] prepfunc = None if \"time\" not in keep_bands : prepfunc = partial ( add_time_band , apply_mask = apply_mask ) # outCollection = outCollection.map(tband) if \"constant\" not in keep_bands : add_const = lambda x : x . addBands ( ee . Image ( 1 )) if \"time\" in keep_bands : prepfunc = add_const else : prepfunc = pipe | prepfunc | add_const if ( \"time\" not in keep_bands ) or ( \"constant\" not in keep_bands ): outCollection = outCollection . map ( prepfunc ) out_band_order = ee . List ([ \"constant\" , \"time\" ]) . cat ( keep_bands ) return outCollection . select ( out_band_order ) temporal_iqr_filter ( collection ) Function to filter values outside of IQR in time on image collection Parameters: Name Type Description Default collection ee.ImageCollection image collection to apply filter in time on required Returns: Type Description ee.ImageCollection image collection with values filtered Source code in hydrafloods/timeseries.py def temporal_iqr_filter ( collection ): \"\"\"Function to filter values outside of IQR in time on image collection args: collection (ee.ImageCollection): image collection to apply filter in time on returns: ee.ImageCollection: image collection with values filtered \"\"\" @decorators . keep_attrs def _filter ( img ): \"\"\"Closure function to apply smoothing in between window\"\"\" mask = img . gt ( low_bounds ) . And ( img . lt ( upper_bounds )) return img . updateMask ( mask ) percentiles = collection . reduce ( ee . Reducer . percentile ([ 25 , 75 ])) iqr = percentiles . select ( 1 ) . subtract ( percentiles . select ( 0 )) low_bounds = percentiles . select ( 0 ) . subtract ( iqr . multiply ( 1.5 )) upper_bounds = percentiles . select ( 1 ) . add ( iqr . multiply ( 1.5 )) return collection . map ( _filter ) temporal_smoothing ( collection , reducer , days = 10 ) Function to apply moving window reducer in time on image collection Parameters: Name Type Description Default collection ee.ImageCollection image collection to apply moving window reducer in time on required reducer ee.Reducer earth engine reducer object to apply required days int,optional size of moving time window in days to apply reducer. default = 10 10 Returns: Type Description ee.ImageCollection image collection with reducer applied in time Source code in hydrafloods/timeseries.py def temporal_smoothing ( collection , reducer , days = 10 ): \"\"\"Function to apply moving window reducer in time on image collection args: collection (ee.ImageCollection): image collection to apply moving window reducer in time on reducer (ee.Reducer): earth engine reducer object to apply days (int,optional): size of moving time window in days to apply reducer. default = 10 returns: ee.ImageCollection: image collection with reducer applied in time \"\"\" @decorators . keep_attrs def _smooth ( img ): \"\"\"Closure function to apply smoothing in between window\"\"\" t = img . date () band_names = img . bandNames () t_start = t . advance ( - days // 2 , \"day\" ) t_stop = t . advance ( days // 2 , \"day\" ) return ( collection . filterDate ( t_start , t_stop ) . reduce ( reducer , 8 ) . rename ( band_names ) ) return collection . map ( _smooth )","title":"timeseries module"},{"location":"timeseries/#hydrafloods.timeseries","text":"","title":"timeseries"},{"location":"timeseries/#hydrafloods.timeseries.add_harmonic_coefs","text":"Function to add harmonic coefficients as bands to images Harmonic coefficients are calculated as sin and cos of frequency within year Parameters: Name Type Description Default image ee.Image image object to add harmonic coefficiencts to. Expects that image has time band required n_cycles int number of interannual cycles to include. default = 2 2 Returns: Type Description ee.Image image with harmonic coefficient bands added Source code in hydrafloods/timeseries.py def add_harmonic_coefs ( image , n_cycles = 2 ): \"\"\"Function to add harmonic coefficients as bands to images Harmonic coefficients are calculated as sin and cos of frequency within year args: image (ee.Image): image object to add harmonic coefficiencts to. Expects that image has time band n_cycles (int, optional): number of interannual cycles to include. default = 2 returns: ee.Image: image with harmonic coefficient bands added \"\"\" cosNames = _get_names ( \"cos\" , n_cycles ) sinNames = _get_names ( \"sin\" , n_cycles ) frequencyImg = ee . Image . constant ( ee . List . sequence ( 1 , n_cycles )) timeRadians = image . select ( \"time\" ) . multiply ( 2 * math . pi ) cosines = timeRadians . multiply ( frequencyImg ) . cos () . rename ( cosNames ) sines = timeRadians . multiply ( frequencyImg ) . sin () . rename ( sinNames ) return image . addBands ( cosines ) . addBands ( sines )","title":"add_harmonic_coefs()"},{"location":"timeseries/#hydrafloods.timeseries.add_time_band","text":"Function to add time band to image. Expects image has system:time_start property. Added band will have name \"time\" Parameters: Name Type Description Default img ee.Image image with system:time_start to add time band too required offset str units to calculate from 1970-01-01. default = \"year\" 'year' apply_mask bool boolean switch to apply image mask to time band. if False, then time band will have full coverage False Returns: Type Description ee.Image image object with time band added Source code in hydrafloods/timeseries.py def add_time_band ( img , offset = \"year\" , apply_mask = False ): \"\"\"Function to add time band to image. Expects image has `system:time_start` property. Added band will have name \"time\" args: img (ee.Image): image with `system:time_start` to add time band too offset (str, optional): units to calculate from 1970-01-01. default = \"year\" apply_mask (bool, optional): boolean switch to apply image mask to time band. if False, then time band will have full coverage returns: ee.Image: image object with time band added \"\"\" t = img . date () tDiff = t . difference ( ee . Date ( \"1970-01-01\" ), offset ) time = ee . Image ( tDiff ) . float () . rename ( \"time\" ) if apply_mask : time = time . updateMask ( img . select ([ 0 ]) . mask ()) return img . addBands ( time )","title":"add_time_band()"},{"location":"timeseries/#hydrafloods.timeseries.anomalies","text":"Function to calculate anomalies of Source code in hydrafloods/timeseries.py def anomalies ( collection , baseline ): \"\"\"Function to calculate anomalies of\"\"\" @decorators . keep_attrs def img_anomaly ( img ): return img . subtract ( baseline ) return collection . map ( img_anomaly )","title":"anomalies()"},{"location":"timeseries/#hydrafloods.timeseries.fit_harmonic_trend","text":"Function to fit a harmonic trend on image collection along the time dimension. Uses ee.Reducer.linearRegression to solve for coefficients Parameters: Name Type Description Default collection ee.ImageCollection | hydrafloods.Dataset image collection to fit trend line for required n_cycles int number of interannual cycles to model. default = 2 2 independents list[str] list of band names to use for fitting regression. default = [\"constant\", \"time\"] ['constant', 'time'] dependent str | None band name of values to fit, if None then uses the first band. default = None None output_err bool switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False False Returns: Type Description ee.Image output image with regression coeffients as bands named \"constant\", \"time\", \"cos_n\", and \"sin_n\" where n is a sequnces of cycles. Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True Exceptions: Type Description ValueError if collection is not of type ee.ImageCollection or hydrafloods.Dataset Source code in hydrafloods/timeseries.py def fit_harmonic_trend ( collection , n_cycles = 2 , independents = [ \"constant\" , \"time\" ], dependent = None , output_err = False , ): \"\"\"Function to fit a harmonic trend on image collection along the time dimension. Uses ee.Reducer.linearRegression to solve for coefficients args: collection (ee.ImageCollection | hydrafloods.Dataset): image collection to fit trend line for n_cycles (int, optional): number of interannual cycles to model. default = 2 independents (list[str], optional): list of band names to use for fitting regression. default = [\"constant\", \"time\"] dependent (str | None, optional): band name of values to fit, if None then uses the first band. default = None output_err (bool, optional): switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False returns: ee.Image: output image with regression coeffients as bands named \"constant\", \"time\", \"cos_n\", and \"sin_n\" where n is a sequnces of cycles. Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True raises: ValueError: if collection is not of type ee.ImageCollection or hydrafloods.Dataset \"\"\" if not isinstance ( collection , ee . ImageCollection ): try : collection = collection . collection except AttributeError : raise ValueError ( \"collection argument expected type ee.ImageCollection or hydrafloods.Dataset,\" + f \"got { type ( collection ) } \" ) if dependent is None : dependent = ee . String ( ee . Image ( collection . first ()) . bandNames () . get ( 0 )) else : dependent = ee . String ( dependent ) independents = ( ee . List ( independents ) . cat ( _get_names ( \"cos\" , n_cycles )) . cat ( _get_names ( \"sin\" , n_cycles )) ) _add_coefs = partial ( add_harmonic_coefs , n_cycles = n_cycles ) harmonic_collection = prep_inputs ( collection , keep_bands = [ dependent ], apply_mask = True ) . map ( _add_coefs ) harmonic_trend = harmonic_collection . select ( independents . add ( dependent )) . reduce ( ee . Reducer . linearRegression ( numX = independents . length (), numY = 1 ), 16 ) n = harmonic_collection . select ( dependent ) . reduce ( ee . Reducer . count (), 16 ) . rename ( \"n\" ) # Turn the array image into a multi-band image of coefficients harmonic_coefficients = ( harmonic_trend . select ( \"coefficients\" ) . arrayProject ([ 0 ]) . arrayFlatten ([ independents ]) ) . addBands ( n ) if output_err : harmonic_mse = ( harmonic_trend . select ( \"residuals\" ) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"residual_y\" ]]) ) t_mean = ( harmonic_collection . select ( \"time\" ) . reduce ( ee . Reducer . mean (), 16 ) . rename ( \"mean_x\" ) ) x_err = ( harmonic_collection . select ( \"time\" ) . map ( lambda x : x . subtract ( t_mean ) . pow ( 2 )) . reduce ( ee . Reducer . sum (), 16 ) . rename ( \"residual_x\" ) ) harmonic_coefficients = ee . Image . cat ( [ harmonic_coefficients , harmonic_mse , t_mean , x_err ] ) return harmonic_coefficients","title":"fit_harmonic_trend()"},{"location":"timeseries/#hydrafloods.timeseries.fit_linear_trend","text":"Function to fit a linear reducer on image collection along the time dimension. Parameters: Name Type Description Default collection ee.ImageCollection image collection to fit trend line for required independents list[str] list of band names to use for fitting regression. default = [\"constant\", \"time\"] ['constant', 'time'] dependent str | None band name of values to fit, if None then uses the first band. default = None None regression_method str name of regression reducer to use. options are \"simple\", \"ols\", \"robust\", \"ridge\", \"sen\". default = \"ols\" 'ols' output_err bool switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False False Returns: Type Description ee.Image output image with regression coeffients as bands named \"offset\" and \"slope\". Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True Source code in hydrafloods/timeseries.py def fit_linear_trend ( collection , independents = [ \"constant\" , \"time\" ], dependent = None , regression_method = \"ols\" , output_err = False , ): \"\"\"Function to fit a linear reducer on image collection along the time dimension. args: collection (ee.ImageCollection): image collection to fit trend line for independents (list[str], optional): list of band names to use for fitting regression. default = [\"constant\", \"time\"] dependent (str | None, optional): band name of values to fit, if None then uses the first band. default = None regression_method (str, optional): name of regression reducer to use. options are \"simple\", \"ols\", \"robust\", \"ridge\", \"sen\". default = \"ols\" output_err (bool, optional): switch to output regression x and y errors, if true output will have \"mean_x\", \"residual_x\" and \"residual_y\" bands. Useful for estimating confidence intervals. default = False returns: ee.Image: output image with regression coeffients as bands named \"offset\" and \"slope\". Will have \"mean_x\", \"residual_x\" and \"residual_y\" if ouput_err == True \"\"\" independents = ee . List ( independents ) if dependent is None : dependent = ee . String ( ee . Image ( collection . first ()) . bandNames () . get ( 0 )) else : dependent = ee . String ( dependent ) methods = [ \"simple\" , \"ols\" , \"robust\" , \"ridge\" , \"sen\" ] reducers = [ ee . Reducer . linearFit (), ee . Reducer . linearRegression ( independents . length (), 1 ), ee . Reducer . robustLinearRegression ( independents . length (), 1 ), ee . Reducer . ridgeRegression ( independents . length (), 1 ), ee . Reducer . sensSlope (), ] method_lookup = { v : reducers [ i ] for i , v in enumerate ( methods )} if regression_method not in methods : raise ValueError () else : lin_reducer = method_lookup [ regression_method ] if not isinstance ( collection , ee . ImageCollection ): collection = collection . collection reduction_coll = prep_inputs ( collection , keep_bands = [ dependent ], apply_mask = True ) . select ( independents . add ( dependent )) n = reduction_coll . select ( dependent ) . reduce ( \"count\" ) . rename ( \"n\" ) if regression_method in [ \"sen\" , \"ridge\" ]: independents = ee . List ([ \"constant\" ]) . cat ( independents ) if regression_method == \"sen\" : lr = reduction_coll . reduce ( lin_reducer , 16 ) . select ( [ \"offset\" , \"slope\" ], independents ) else : lr_arr = reduction_coll . reduce ( lin_reducer , 16 ) lr = ( lr_arr . select ([ \"coefficients\" ]) . arrayProject ([ 0 ]) . arrayFlatten ([ independents ]) ) if output_err and regression_method != \"sen\" : linear_mse = ( lr_arr . select ( \"residuals\" ) . arrayProject ([ 0 ]) . arrayFlatten ([[ \"residual_y\" ]]) ) t_mean = reduction_coll . select ( \"time\" ) . mean () . rename ( \"mean_x\" ) x_err = ( reduction_coll . select ( \"time\" ) . map ( lambda x : x . subtract ( t_mean ) . pow ( 2 )) . reduce ( ee . Reducer . sum (), 16 ) . rename ( \"residual_x\" ) ) lr = ee . Image . cat ([ lr , linear_mse , t_mean , x_err ]) return lr . addBands ( n )","title":"fit_linear_trend()"},{"location":"timeseries/#hydrafloods.timeseries.get_dummy_collection","text":"Helper function to create image collection of images to apply time series prediction on Creates daily imagery between start_time and end_time Parameters: Name Type Description Default start_time str | ee.Date string or ee.Date string to start creating images on (inclusive) None end_time str | ee.Date string or ee.Date string to end creating images on (exclusive) None Returns: Type Description ee.ImageCollection image collection with image containing time and constant bands Source code in hydrafloods/timeseries.py def get_dummy_collection ( start_time = None , end_time = None , dates = None ): \"\"\"Helper function to create image collection of images to apply time series prediction on Creates daily imagery between start_time and end_time args: start_time (str | ee.Date): string or ee.Date string to start creating images on (inclusive) end_time (str | ee.Date): string or ee.Date string to end creating images on (exclusive) returns: ee.ImageCollection: image collection with image containing time and constant bands \"\"\" def _gen_image_seq ( i ): t = start_time . advance ( ee . Number ( i ), \"day\" ) return ee . Image () . rename ( \"blank\" ) . set ( \"system:time_start\" , t . millis ()) def _gen_image ( d ): d = ee . Date ( d ) return ee . Image () . rename ( \"blank\" ) . set ( \"system:time_start\" , d . millis ()) if ( start_time is not None ) and ( end_time is not None ): if not isinstance ( start_time , ee . Date ): start_time = ee . Date ( start_time ) if not isinstance ( end_time , ee . Date ): end_time = ee . Date ( end_time ) n = end_time . difference ( start_time , \"day\" ) coll = ee . ImageCollection ( ee . List . sequence ( 0 , n ) . map ( _gen_image_seq )) elif dates is not None : coll = ee . ImageCollection ( dates . map ( _gen_image )) else : raise ValueError ( \"Either 'dates' or 'start_time'/'end_time' need to be defined\" ) return prep_inputs ( coll )","title":"get_dummy_collection()"},{"location":"timeseries/#hydrafloods.timeseries.get_dummy_img","text":"Helper function to get an image readily available to use for predictions Resulting image will include time based on year and constant band of 1 Parameters: Name Type Description Default t str | ee.Date string or ee.Date string to create dummy image for required Returns: Type Description ee.Image image object with time and constant bands Source code in hydrafloods/timeseries.py def get_dummy_img ( t ): \"\"\"Helper function to get an image readily available to use for predictions Resulting image will include time based on year and constant band of 1 args: t (str | ee.Date): string or ee.Date string to create dummy image for returns: ee.Image: image object with time and constant bands \"\"\" if not isinstance ( t , ee . Date ): t = ee . Date ( t ) img = ee . Image . constant ( 1 ) . set ( \"system:time_start\" , t . millis ()) time_band = ( ee . Image ( t . difference ( ee . Date ( \"1970-01-01\" ), \"year\" )) . float () . rename ( \"time\" ) ) return img . addBands ( time_band )","title":"get_dummy_img()"},{"location":"timeseries/#hydrafloods.timeseries.predict_harmonics","text":"Helper function to apply harmonic trend prediction Parameters: Name Type Description Default collection ee.ImageCollection image collection to apply prediction on required harmonics ee.Image harmonic coefficient image with coeffiecient bands required n_cycles int number of interannual cycles to model, note n_cycles must equal the number of cycle coefficients in harmonics . default = 2 2 independents list[str] list of independent band names to use in model. These are other than the harmonic coefficient names. default = [\"constant\", \"time\"] ['constant', 'time'] returns ee.ImageCollection: image collection with predicted values Source code in hydrafloods/timeseries.py def predict_harmonics ( collection , harmonics , n_cycles = 2 , independents = [ \"constant\" , \"time\" ] ): \"\"\"Helper function to apply harmonic trend prediction args: collection (ee.ImageCollection): image collection to apply prediction on harmonics (ee.Image): harmonic coefficient image with coeffiecient bands n_cycles (int, optional): number of interannual cycles to model, note n_cycles must equal the number of cycle coefficients in `harmonics`. default = 2 independents (list[str], optional): list of independent band names to use in model. These are other than the harmonic coefficient names. default = [\"constant\", \"time\"] returns ee.ImageCollection: image collection with predicted values \"\"\" @decorators . keep_attrs def _apply_prediction ( image ): \"\"\"Closure function to apply prediction\"\"\" return ( image . select ( independents ) . multiply ( harmonics ) . reduce ( \"sum\" ) . rename ( \"predicted\" ) ) independents = ( ee . List ( independents ) . cat ( _get_names ( \"cos\" , n_cycles )) . cat ( _get_names ( \"sin\" , n_cycles )) ) _add_coefs = partial ( add_harmonic_coefs , n_cycles = n_cycles ) harmonic_collection = prep_inputs ( collection ) . map ( _add_coefs ) # Compute fitted values. predicted = harmonic_collection . map ( _apply_prediction ) return predicted","title":"predict_harmonics()"},{"location":"timeseries/#hydrafloods.timeseries.prep_inputs","text":"Helper function to prepare inputs into time series algorithms. Will check if each image in collection has a time and constant band, if not it will add to collection Wraps add_time_band() for adding the time band Parameters: Name Type Description Default collection ee.ImageCollection image collection to check and add time/constant band too required keep_bands list[str] | None regex name or list of band names to drop during prep and include in the result Will check if \"time\" or \"constant\" in list, if not then add to collection. default = None None apply_mask bool boolean switch to apply image mask to time band. if False, then time band will have full coverage False Returns: Type Description ee.ImageCollection collection with time and constant bands included Source code in hydrafloods/timeseries.py def prep_inputs ( collection , keep_bands = None , apply_mask = False ): \"\"\"Helper function to prepare inputs into time series algorithms. Will check if each image in collection has a time and constant band, if not it will add to collection Wraps `add_time_band()` for adding the time band args: collection (ee.ImageCollection): image collection to check and add time/constant band too keep_bands (list[str] | None, optional): regex name or list of band names to drop during prep and include in the result Will check if \"time\" or \"constant\" in list, if not then add to collection. default = None apply_mask (bool, optional): boolean switch to apply image mask to time band. if False, then time band will have full coverage returns: ee.ImageCollection: collection with time and constant bands included \"\"\" if not isinstance ( collection , ee . ImageCollection ): collection = collection . collection first = ee . Image ( collection . first ()) outCollection = copy . deepcopy ( collection ) if keep_bands is None : keep_bands = [] prepfunc = None if \"time\" not in keep_bands : prepfunc = partial ( add_time_band , apply_mask = apply_mask ) # outCollection = outCollection.map(tband) if \"constant\" not in keep_bands : add_const = lambda x : x . addBands ( ee . Image ( 1 )) if \"time\" in keep_bands : prepfunc = add_const else : prepfunc = pipe | prepfunc | add_const if ( \"time\" not in keep_bands ) or ( \"constant\" not in keep_bands ): outCollection = outCollection . map ( prepfunc ) out_band_order = ee . List ([ \"constant\" , \"time\" ]) . cat ( keep_bands ) return outCollection . select ( out_band_order )","title":"prep_inputs()"},{"location":"timeseries/#hydrafloods.timeseries.temporal_iqr_filter","text":"Function to filter values outside of IQR in time on image collection Parameters: Name Type Description Default collection ee.ImageCollection image collection to apply filter in time on required Returns: Type Description ee.ImageCollection image collection with values filtered Source code in hydrafloods/timeseries.py def temporal_iqr_filter ( collection ): \"\"\"Function to filter values outside of IQR in time on image collection args: collection (ee.ImageCollection): image collection to apply filter in time on returns: ee.ImageCollection: image collection with values filtered \"\"\" @decorators . keep_attrs def _filter ( img ): \"\"\"Closure function to apply smoothing in between window\"\"\" mask = img . gt ( low_bounds ) . And ( img . lt ( upper_bounds )) return img . updateMask ( mask ) percentiles = collection . reduce ( ee . Reducer . percentile ([ 25 , 75 ])) iqr = percentiles . select ( 1 ) . subtract ( percentiles . select ( 0 )) low_bounds = percentiles . select ( 0 ) . subtract ( iqr . multiply ( 1.5 )) upper_bounds = percentiles . select ( 1 ) . add ( iqr . multiply ( 1.5 )) return collection . map ( _filter )","title":"temporal_iqr_filter()"},{"location":"timeseries/#hydrafloods.timeseries.temporal_smoothing","text":"Function to apply moving window reducer in time on image collection Parameters: Name Type Description Default collection ee.ImageCollection image collection to apply moving window reducer in time on required reducer ee.Reducer earth engine reducer object to apply required days int,optional size of moving time window in days to apply reducer. default = 10 10 Returns: Type Description ee.ImageCollection image collection with reducer applied in time Source code in hydrafloods/timeseries.py def temporal_smoothing ( collection , reducer , days = 10 ): \"\"\"Function to apply moving window reducer in time on image collection args: collection (ee.ImageCollection): image collection to apply moving window reducer in time on reducer (ee.Reducer): earth engine reducer object to apply days (int,optional): size of moving time window in days to apply reducer. default = 10 returns: ee.ImageCollection: image collection with reducer applied in time \"\"\" @decorators . keep_attrs def _smooth ( img ): \"\"\"Closure function to apply smoothing in between window\"\"\" t = img . date () band_names = img . bandNames () t_start = t . advance ( - days // 2 , \"day\" ) t_stop = t . advance ( days // 2 , \"day\" ) return ( collection . filterDate ( t_start , t_stop ) . reduce ( reducer , 8 ) . rename ( band_names ) ) return collection . map ( _smooth )","title":"temporal_smoothing()"},{"location":"using-datasets/","text":"Here are a more in depth examples of using hydrafloods.Dataset classes for working with imagery. It is expected that the code is run in an interactive python session such as IPython or in a Jupyter Notebook as later code blocks will use variables from previous ones. import ee ee . Initialze () import hydrafloods as hf Dataset structure region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-07-01\" # get a Landsat 8 collection lc8 = hf . Landsat8 ( region , start_time , end_time ) print ( lc8 ) # should look like # HYDRAFloods Dataset: # {'asset_id': 'LANDSAT/LC08/C01/T1_SR', # 'end_time': '2019-07-01', # 'name': 'Landsat8', # 'region': [[[...], [...], [...], [...], [...]]], # 'start_time': '2019-01-01'} A dataset object has a few properties that we can access to assist in processing or understanding the data contained in the dataset. Here is a list of properties and a description: Dataset.collection : Earth Engine image collection object that the dataset class wraps Dataset.n_images : client side number of images in collection Dataset.dates : client side list of datetime information of all images acquisition times Let's inspect some of these properties print ( lc8 . n_images ) # should equal 197 print ( lc8 . dates ) # should look something like # ['2019-01-12 03:06:42.950', # '2019-01-28 03:06:38.990', # ... , # '2019-06-01 03:32:06.850'] # since `Dataset.collection` is a server side object we will just # check that it is in fact a ee.ImageCollection object print ( isinstance ( lc8 . collection , ee . ImageCollection )) # should == True Specialized Datasets hydrafloods has specialized datasets classes that extend a hydrafloods.Dataset class and are common image collections used in surface water mapping. These specialized datasets include a custom qa() method based on quality assessment bands that gets called on initialization to mask poor quality pixels and custom methods that make harmonization easy. Furthermore, the optical sensor bands are automatically renamed to a common scheme so that they can be used together easily. Here is a list of the specialized datasets with links to information on methods: Really, one can think of the custom qa() method as a preprocessing step that you would like to happen on all images in the dataset so it is not just restricted to specific sensors as seen in a later section. Sentinel 1: hydrafloods.Sentinel1 Sentinel 2: hydrafloods.Sentinel2 Landsat 8: hydrafloods.Landsat8 Landsat 7: hydrafloods.Landsat7 VIIRS: hydrafloods.Viirs MODIS: hydrafloods.Modis To provide an example of using the internal qa() method and not we can redefine the Landsat 8 collection from before but with setting use_qa to False lc8 = hf . Landsat8 ( region , start_time , end_time ) lc8_noqa = hf . Landsat8 ( region , start_time , end_time , use_qa = False ) thumb_params = { \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"dimensions\" : 1024 } # get thumbnail images qa_thumb = ( lc8 . collection . first () . getThumbURL ( thumb_params ) ) noqa_thumb = ( lc8_noqa . collection . first () . getThumbURL ( thumb_params ) ) # print urls to view thumbnails print ( qa_thumb ) print ( noqa_thumb ) use_qa = True use_qa = False We can clearly see the image on the left has clouds and cloud shadows masked and can therefore be used directly in analysis with minimal effort. More information on the internals of these specialized datasets and how you can write your own can be found at the Writing your own dataset class section. Creating a Dataset from a computed ee.ImageCollection While HYDRAFloods provides some specialized Dataset classes for users to immediately access, there are often times when a user would like to use their own Image Collection. To this end, a method is available for users to create a dataset directly from an ee.ImageCollection object, hf.Dataset.from_imgcollection . This allows Dataset objects to be created from image collections that have been filtered or with additional computation applied. Here is a quick example grabbing the public Planet SkySat data, filtering to the United States, and calculating NDVI: us = hf . country_bbox ( \"United States\" ) # get the public SkySat ImageCollection for the USA # and compute a NDVI band ic = ( ee . ImageCollection ( \"SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL\" ) . filterBounds ( us ) . map ( lambda x : x . addBands ( x . normalizedDifference ([ \"N\" , \"R\" ]))) ) planet = hf . Dataset . from_imgcollection ( ic ) print ( planet . n_images ) # should equal 33 It should be noted that hydrafloods will attempt to call .getInfo() from the ee.ImageCollection to get property information such as image geometries and acquisition dates. Image collections used to create a hf.Dataset via this method needed to be bounded (i.e. have img.geometry() ) and have the system:time_start property defined. Additionally, since this passes data from the EE servers to the client, it may take some time to get the information required for the Dataset object. Therefore, writing your own dataset class is advised if a lot or advanced computations are needed to pre-process any ImageCollection into a hf.Dataset . Applying a function As we saw in the Getting Stated page, we can apply image processing functions using apply_func() by passing a function object or any keyword parameters. This method wraps a function that accepts an image as the first argument (which most hydrafloods image processing algorithms do) and maps it over the collection. For example, if want to create a water map using Landsat 8, we will calculate a water index and then apply a thresholding algorithm: region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-03-01\" # get a Landsat 8 collection lc8 = hf . Landsat8 ( region , start_time , end_time ) water_index = lc8 . apply_func ( hf . mndwi ) water_ds = water_index . apply_func ( hf . edge_otsu , initial_threshold = 0 , edge_buffer = 300 , scale = 150 , invert = True ) index_img = water_index . collection . median () water_img = water_ds . collection . mode () water_img . getThumbURL ({ \"min\" : - 1 , \"max\" : 1 , \"palette\" : \"beige,white,lightblue,blue,darkblue\" , \"dimensions\" : 1500 , \"region\" : region }) water_img . getThumbURL ({ \"min\" : 0 , \"max\" : 1 , \"palette\" : \"silver,navy\" , \"dimensions\" : 1500 , \"region\" : region }) Landsat 8 Water Index Landsat 8 Water Map Merging Datasets One of the simpilest ways to combine datasets is to merge. This takes the imagery in one collection and concatenates it with the original collection. We can use the merge() method to accomplish this. Additionally, the merge() method automatically sorts the image collections by date so we can start using dense time series right away. Here is an example of merging Landat8 and Sentinel2 datasets together: lc8 = hf . Landsat8 ( region , start_time , end_time ) # has 71 images s2 = hf . Sentinel2 ( region , start_time , end_time ) # has 798 images merged = lc8 . merge ( s2 ) print ( merged . n_images ) # now has 869 images! Joining Datasets Joining datasets is another way to bring together two datasets but by looking at coincident imagery and combines the bands into one image. Whereas merge combined the two collections irrespective of space time overlap, join() looks for overlapping data in space and time and will return only data that overlaps with the bands combined. Furthermore, the resulting images will be clipped to the overlapping region. This functionality is really helpful when looking for coincident data from multiple sensors. lc8 = hf . Landsat8 ( region , start_time , end_time ) # has 197 images s1 = hf . Sentinel1 ( region , start_time , end_time ) # has 628 images joined = lc8 . join ( s1 ) # has 131 coincident images # grab the first image in the collection # will have optical and sar bands first = joined . collection . first () print ( first . bandNames () . getInfo ()) # should equal the following: # ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'VV', 'VH', 'angle'] # both optical and SAR bands are included in the image # visualize the different bands optical_thumb = first . getThumbURL ({ \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"dimensions\" : 1024 }) sar_thumb = first . getThumbURL ({ \"min\" :[ - 25 , - 30 , - 25 ], \"max\" :[ 0 , - 5 , 0 ], \"bands\" : \"VV,VH,VV\" , \"dimensions\" : 1024 }) # print urls to view thumbnails print ( optical_thumb ) print ( sar_thumb ) Landsat 8 2019-01-28 Sentinel 1 2019-01-28 Temporal aggregation A common workflow is merging data and make composites for individual dates that data is available. A good example of this is the MODIS sensor that is onboard the Terra and Aqua satellite. We can create daily composites of the imagery by merging the datasets then looping over each day to mosaic the data. hydrafloods has a method aggregate_time() to do the mosaicing sequentially in time. Here we create a combined MODIS Terra and Aqua dataset. # define new time range start_time = \"2018-11-03\" end_time = \"2018-11-15\" # get the terra MODIS dataset terra = hf . Modis ( region , start_time , end_time ) # get the aqua MODIS dataset # note calling the asset_id explicitly aqua = hf . Modis ( region , start_time , end_time , asset_id = \"MODIS/006/MYD09GA\" ) # merge the collections into one merged = terra . merge ( aqua ) # aggregate in time agg = merged . aggregate_time ( reducer = \"median\" ) # get thumb for first image in terra dataset terra . collection . first () . getThumbURL ({ \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"region\" : region , \"dimensions\" : 1024 , \"crs\" : \"EPSG:4326\" }) # get thumb for first image in aqua dataset aqua . collection . first () . getThumbURL ({ \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"region\" : region , \"dimensions\" : 1024 , \"crs\" : \"EPSG:4326\" }) # get thumb for first image in merged dataset agg . collection . first () . getThumbURL ({ \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"region\" : region , \"dimensions\" : 1024 , \"crs\" : \"EPSG:4326\" }) MODIS Terra 2018-11-03 MODIS Aqua 2018-11-03 Aggregated By doing this we can fill in gaps where some data is missing with other sensors. We see in the above example that combining the MODIS data from Terra and Aqua we can get more coverage in the event of flooding. By default the method will take unique dates within the dataset and aggregate by one day as seen in the above example. We can also use this functionality to make monthly or yearly composites of data by specifying the dates that we want to start the aggregation with and a period after the start dates to do the aggregation. Here is an example creating yearly composites from 2015 through 2019: # define new time range start_time = \"2015-01-01\" end_time = \"2020-01-01\" # define the dates in which to start aggregation year_starts = [ \"2015-01-01\" , \"2016-01-01\" , \"2017-01-01\" , \"2018-01-01\" , \"2019-01-01\" ] # get the terra MODIS dataset terra = hf . Modis ( region , start_time , end_time ) # apply the aggregation yearly = terra . aggregate_time ( dates = year_starts , period = 365 ) print ( yearly . dates ) # should equal to: # ['2015-01-01 00:00:00.000', # '2016-01-01 00:00:00.000', # '2017-01-01 00:00:00.000', # '2018-01-01 00:00:00.000', # '2019-01-01 00:00:00.000'] As seen, this method allows for customization of when to start aggregations and how long/which dates to include in aggregation which can be helpful for unique timings like dekads. Piping multiple functions As seen in the \"Applying a function\" section, we can easily process imagery by passing individual functions into .apply_func() . While this method of writing the computation is easy to read syntaxually, it is however inefficient for for Earth Engien to apply the computations. This is because each function passed through .apply_func() applies the function to all imagery in the Dataset. For example, if there are three functions you want to apply, then it will loop through all of the imagery three times. This can cause computation timeout or memory errors on Earth Engine's side if there is a lot to compute using multiple mapped functions. The .pipe() method allows for users to apply multiple functions to a Dataset with only one pass through the imagery. This is the preferred method to chain together multiple functions. For example, if we want to create water maps from Landsat 8 we would calculate a water index (e.g. MNDWI) then apply the water mapping algorithm. Here we can tell .pipe() the order of functions to apply and the arguments (if any) and it will nest the functions into one to map over. region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-03-01\" # get a Landsat 8 collection lc8 = hf . Landsat8 ( region , start_time , end_time ) process_steps = ( hf . mndwi , ( hf . edge_otsu , dict ( initial_threshold = 0 , edge_buffer = 300 , scale = 150 , invert = True )) ) water = lc8 . pipe ( process_steps ) water_img = water . collection . mode () water_img . getThumbURL ({ \"min\" : 0 , \"max\" : 1 , \"palette\" : \"silver,navy\" , \"dimensions\" : 1500 , \"region\" : region }) The .pipe() methods allows for any function object to be passed as long as the first argument to the function is an ee.Image object. So, users can write their own custom functions or supply anonymous functions (i.e. lambda functions) and it will work. Again, this is the preferred method when doing a lot of preprocessing to prevent unnecessarily looping through the dataset multiple times. Writing your own dataset class The hydrafloods.Dataset class can be used to create custom dataset classes for sensors. This is helpful when there is a sensor that will be used often with other datasets using hydrafloods . Here is an example of writing a custom hydrafloods.Dataset class for the GOES16 collection. We will predefine the asset_id argument and define a qa() method to scale data to reflectance and mask poor quality pixels. class Goes16 ( hf . Dataset ): def __init__ ( self , * args , asset_id = \"NOAA/GOES/16/MCMIPF\" , use_qa = True , ** kwargs ): # initialize the parent class super ( Goes16 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) # list of band names to return with new names old_band_names = [ \"CMI_C01\" , \"green\" , \"CMI_C02\" , \"CMI_C03\" , \"CMI_C05\" , \"CMI_C06\" ] new_band_names = [ \"blue\" , \"green\" , \"red\" , \"nir\" , \"swir1\" , \"swir2\" ] # change the band names to something self . collection = self . collection . select ( old_band_names , new_band_names ) return # define a qa method and wrap in the carry_metadata decorator # retains metadata for each image # qa() will get called on super() if use_qa==True @hf . decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Goes17 data Scales data to reflectance and finds poor quality images add a psuedo-green band using methods from https://doi.org/10.1029/2018EA000379 \"\"\" band_names = img . bandNames () # get scale and offset values scale_properties = band_names . map ( lambda x : ee . String ( x ) . cat ( \"_scale\" )) offset_properties = band_names . map ( lambda x : ee . String ( x ) . cat ( \"_offset\" )) # convert scale/offset values to image scale_img = img . toDictionary ( scale_properties ) . toImage () offset_img = img . toDictionary ( offset_properties ) . toImage () # get qa bands and set 0 to 1 and everything else to 0 qa_img = img . select ( \"^(DQF).*\" ) . Not () # get the actual image data and apply qa mask img = img . select ( \"^(CMI).*\" ) . updateMask ( qa_img ) # scale imagery to reflectance img = img . multiply ( scale_img ) . add ( offset_img ) . multiply ( qa_img ) # compute psuedo green band green_weights = ee . Image . constant ([ 0.45 , 0.45 , 0.1 ]) green_band = ( img . select ([ \"CMI_C01\" , \"CMI_C02\" , \"CMI_C03\" ]) . multiply ( green_weights ) . reduce ( \"sum\" ) . rename ( \"green\" ) ) return img . addBands ( green_band ) # get a GOES collection over the United States us = hf . country_bbox ( \"United States\" ) goes = Goes16 ( us , \"2020-07-28T18:40:18\" , \"2020-07-29T00:00:00\" ) # view the results from the GOES16 collection first_img = goes . collection . first () viz_params = { \"min\" : 0.05 , \"max\" : 0.55 , \"bands\" : \"swir1,nir,green\" , \"gamma\" : 1.5 , \"region\" : us , \"dimensions\" : 1024 , \"crs\" : \"epsg:5070\" } print ( first_img . getThumbURL ( viz_params )) In this example of a custom dataset class for GOES16 imagery, the qa() method definition is more for preprocessing to scale the imagery. A custom cloud/shadow masking workflow can easily be included and applied on the imagery. Now we are ready to use our custom GOES16 imagery with the rest of the hydrafloods functions! More detailed information on the hydrafloods.Dataset class along with it's method fucntionality and arguments can be found in the datasets module API reference.","title":"Using the Dataset class"},{"location":"using-datasets/#dataset-structure","text":"region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-07-01\" # get a Landsat 8 collection lc8 = hf . Landsat8 ( region , start_time , end_time ) print ( lc8 ) # should look like # HYDRAFloods Dataset: # {'asset_id': 'LANDSAT/LC08/C01/T1_SR', # 'end_time': '2019-07-01', # 'name': 'Landsat8', # 'region': [[[...], [...], [...], [...], [...]]], # 'start_time': '2019-01-01'} A dataset object has a few properties that we can access to assist in processing or understanding the data contained in the dataset. Here is a list of properties and a description: Dataset.collection : Earth Engine image collection object that the dataset class wraps Dataset.n_images : client side number of images in collection Dataset.dates : client side list of datetime information of all images acquisition times Let's inspect some of these properties print ( lc8 . n_images ) # should equal 197 print ( lc8 . dates ) # should look something like # ['2019-01-12 03:06:42.950', # '2019-01-28 03:06:38.990', # ... , # '2019-06-01 03:32:06.850'] # since `Dataset.collection` is a server side object we will just # check that it is in fact a ee.ImageCollection object print ( isinstance ( lc8 . collection , ee . ImageCollection )) # should == True","title":"Dataset structure"},{"location":"using-datasets/#specialized-datasets","text":"hydrafloods has specialized datasets classes that extend a hydrafloods.Dataset class and are common image collections used in surface water mapping. These specialized datasets include a custom qa() method based on quality assessment bands that gets called on initialization to mask poor quality pixels and custom methods that make harmonization easy. Furthermore, the optical sensor bands are automatically renamed to a common scheme so that they can be used together easily. Here is a list of the specialized datasets with links to information on methods: Really, one can think of the custom qa() method as a preprocessing step that you would like to happen on all images in the dataset so it is not just restricted to specific sensors as seen in a later section. Sentinel 1: hydrafloods.Sentinel1 Sentinel 2: hydrafloods.Sentinel2 Landsat 8: hydrafloods.Landsat8 Landsat 7: hydrafloods.Landsat7 VIIRS: hydrafloods.Viirs MODIS: hydrafloods.Modis To provide an example of using the internal qa() method and not we can redefine the Landsat 8 collection from before but with setting use_qa to False lc8 = hf . Landsat8 ( region , start_time , end_time ) lc8_noqa = hf . Landsat8 ( region , start_time , end_time , use_qa = False ) thumb_params = { \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"dimensions\" : 1024 } # get thumbnail images qa_thumb = ( lc8 . collection . first () . getThumbURL ( thumb_params ) ) noqa_thumb = ( lc8_noqa . collection . first () . getThumbURL ( thumb_params ) ) # print urls to view thumbnails print ( qa_thumb ) print ( noqa_thumb ) use_qa = True use_qa = False We can clearly see the image on the left has clouds and cloud shadows masked and can therefore be used directly in analysis with minimal effort. More information on the internals of these specialized datasets and how you can write your own can be found at the Writing your own dataset class section.","title":"Specialized Datasets"},{"location":"using-datasets/#creating-a-dataset-from-a-computed-eeimagecollection","text":"While HYDRAFloods provides some specialized Dataset classes for users to immediately access, there are often times when a user would like to use their own Image Collection. To this end, a method is available for users to create a dataset directly from an ee.ImageCollection object, hf.Dataset.from_imgcollection . This allows Dataset objects to be created from image collections that have been filtered or with additional computation applied. Here is a quick example grabbing the public Planet SkySat data, filtering to the United States, and calculating NDVI: us = hf . country_bbox ( \"United States\" ) # get the public SkySat ImageCollection for the USA # and compute a NDVI band ic = ( ee . ImageCollection ( \"SKYSAT/GEN-A/PUBLIC/ORTHO/MULTISPECTRAL\" ) . filterBounds ( us ) . map ( lambda x : x . addBands ( x . normalizedDifference ([ \"N\" , \"R\" ]))) ) planet = hf . Dataset . from_imgcollection ( ic ) print ( planet . n_images ) # should equal 33 It should be noted that hydrafloods will attempt to call .getInfo() from the ee.ImageCollection to get property information such as image geometries and acquisition dates. Image collections used to create a hf.Dataset via this method needed to be bounded (i.e. have img.geometry() ) and have the system:time_start property defined. Additionally, since this passes data from the EE servers to the client, it may take some time to get the information required for the Dataset object. Therefore, writing your own dataset class is advised if a lot or advanced computations are needed to pre-process any ImageCollection into a hf.Dataset .","title":"Creating a Dataset from a computed ee.ImageCollection"},{"location":"using-datasets/#applying-a-function","text":"As we saw in the Getting Stated page, we can apply image processing functions using apply_func() by passing a function object or any keyword parameters. This method wraps a function that accepts an image as the first argument (which most hydrafloods image processing algorithms do) and maps it over the collection. For example, if want to create a water map using Landsat 8, we will calculate a water index and then apply a thresholding algorithm: region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-03-01\" # get a Landsat 8 collection lc8 = hf . Landsat8 ( region , start_time , end_time ) water_index = lc8 . apply_func ( hf . mndwi ) water_ds = water_index . apply_func ( hf . edge_otsu , initial_threshold = 0 , edge_buffer = 300 , scale = 150 , invert = True ) index_img = water_index . collection . median () water_img = water_ds . collection . mode () water_img . getThumbURL ({ \"min\" : - 1 , \"max\" : 1 , \"palette\" : \"beige,white,lightblue,blue,darkblue\" , \"dimensions\" : 1500 , \"region\" : region }) water_img . getThumbURL ({ \"min\" : 0 , \"max\" : 1 , \"palette\" : \"silver,navy\" , \"dimensions\" : 1500 , \"region\" : region }) Landsat 8 Water Index Landsat 8 Water Map","title":"Applying a function"},{"location":"using-datasets/#merging-datasets","text":"One of the simpilest ways to combine datasets is to merge. This takes the imagery in one collection and concatenates it with the original collection. We can use the merge() method to accomplish this. Additionally, the merge() method automatically sorts the image collections by date so we can start using dense time series right away. Here is an example of merging Landat8 and Sentinel2 datasets together: lc8 = hf . Landsat8 ( region , start_time , end_time ) # has 71 images s2 = hf . Sentinel2 ( region , start_time , end_time ) # has 798 images merged = lc8 . merge ( s2 ) print ( merged . n_images ) # now has 869 images!","title":"Merging Datasets"},{"location":"using-datasets/#joining-datasets","text":"Joining datasets is another way to bring together two datasets but by looking at coincident imagery and combines the bands into one image. Whereas merge combined the two collections irrespective of space time overlap, join() looks for overlapping data in space and time and will return only data that overlaps with the bands combined. Furthermore, the resulting images will be clipped to the overlapping region. This functionality is really helpful when looking for coincident data from multiple sensors. lc8 = hf . Landsat8 ( region , start_time , end_time ) # has 197 images s1 = hf . Sentinel1 ( region , start_time , end_time ) # has 628 images joined = lc8 . join ( s1 ) # has 131 coincident images # grab the first image in the collection # will have optical and sar bands first = joined . collection . first () print ( first . bandNames () . getInfo ()) # should equal the following: # ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'VV', 'VH', 'angle'] # both optical and SAR bands are included in the image # visualize the different bands optical_thumb = first . getThumbURL ({ \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"dimensions\" : 1024 }) sar_thumb = first . getThumbURL ({ \"min\" :[ - 25 , - 30 , - 25 ], \"max\" :[ 0 , - 5 , 0 ], \"bands\" : \"VV,VH,VV\" , \"dimensions\" : 1024 }) # print urls to view thumbnails print ( optical_thumb ) print ( sar_thumb ) Landsat 8 2019-01-28 Sentinel 1 2019-01-28","title":"Joining Datasets"},{"location":"using-datasets/#temporal-aggregation","text":"A common workflow is merging data and make composites for individual dates that data is available. A good example of this is the MODIS sensor that is onboard the Terra and Aqua satellite. We can create daily composites of the imagery by merging the datasets then looping over each day to mosaic the data. hydrafloods has a method aggregate_time() to do the mosaicing sequentially in time. Here we create a combined MODIS Terra and Aqua dataset. # define new time range start_time = \"2018-11-03\" end_time = \"2018-11-15\" # get the terra MODIS dataset terra = hf . Modis ( region , start_time , end_time ) # get the aqua MODIS dataset # note calling the asset_id explicitly aqua = hf . Modis ( region , start_time , end_time , asset_id = \"MODIS/006/MYD09GA\" ) # merge the collections into one merged = terra . merge ( aqua ) # aggregate in time agg = merged . aggregate_time ( reducer = \"median\" ) # get thumb for first image in terra dataset terra . collection . first () . getThumbURL ({ \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"region\" : region , \"dimensions\" : 1024 , \"crs\" : \"EPSG:4326\" }) # get thumb for first image in aqua dataset aqua . collection . first () . getThumbURL ({ \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"region\" : region , \"dimensions\" : 1024 , \"crs\" : \"EPSG:4326\" }) # get thumb for first image in merged dataset agg . collection . first () . getThumbURL ({ \"min\" : 50 , \"max\" : 5500 , \"bands\" : \"swir2,nir,green\" , \"gamma\" : 1.5 , \"region\" : region , \"dimensions\" : 1024 , \"crs\" : \"EPSG:4326\" }) MODIS Terra 2018-11-03 MODIS Aqua 2018-11-03 Aggregated By doing this we can fill in gaps where some data is missing with other sensors. We see in the above example that combining the MODIS data from Terra and Aqua we can get more coverage in the event of flooding. By default the method will take unique dates within the dataset and aggregate by one day as seen in the above example. We can also use this functionality to make monthly or yearly composites of data by specifying the dates that we want to start the aggregation with and a period after the start dates to do the aggregation. Here is an example creating yearly composites from 2015 through 2019: # define new time range start_time = \"2015-01-01\" end_time = \"2020-01-01\" # define the dates in which to start aggregation year_starts = [ \"2015-01-01\" , \"2016-01-01\" , \"2017-01-01\" , \"2018-01-01\" , \"2019-01-01\" ] # get the terra MODIS dataset terra = hf . Modis ( region , start_time , end_time ) # apply the aggregation yearly = terra . aggregate_time ( dates = year_starts , period = 365 ) print ( yearly . dates ) # should equal to: # ['2015-01-01 00:00:00.000', # '2016-01-01 00:00:00.000', # '2017-01-01 00:00:00.000', # '2018-01-01 00:00:00.000', # '2019-01-01 00:00:00.000'] As seen, this method allows for customization of when to start aggregations and how long/which dates to include in aggregation which can be helpful for unique timings like dekads.","title":"Temporal aggregation"},{"location":"using-datasets/#piping-multiple-functions","text":"As seen in the \"Applying a function\" section, we can easily process imagery by passing individual functions into .apply_func() . While this method of writing the computation is easy to read syntaxually, it is however inefficient for for Earth Engien to apply the computations. This is because each function passed through .apply_func() applies the function to all imagery in the Dataset. For example, if there are three functions you want to apply, then it will loop through all of the imagery three times. This can cause computation timeout or memory errors on Earth Engine's side if there is a lot to compute using multiple mapped functions. The .pipe() method allows for users to apply multiple functions to a Dataset with only one pass through the imagery. This is the preferred method to chain together multiple functions. For example, if we want to create water maps from Landsat 8 we would calculate a water index (e.g. MNDWI) then apply the water mapping algorithm. Here we can tell .pipe() the order of functions to apply and the arguments (if any) and it will nest the functions into one to map over. region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-03-01\" # get a Landsat 8 collection lc8 = hf . Landsat8 ( region , start_time , end_time ) process_steps = ( hf . mndwi , ( hf . edge_otsu , dict ( initial_threshold = 0 , edge_buffer = 300 , scale = 150 , invert = True )) ) water = lc8 . pipe ( process_steps ) water_img = water . collection . mode () water_img . getThumbURL ({ \"min\" : 0 , \"max\" : 1 , \"palette\" : \"silver,navy\" , \"dimensions\" : 1500 , \"region\" : region }) The .pipe() methods allows for any function object to be passed as long as the first argument to the function is an ee.Image object. So, users can write their own custom functions or supply anonymous functions (i.e. lambda functions) and it will work. Again, this is the preferred method when doing a lot of preprocessing to prevent unnecessarily looping through the dataset multiple times.","title":"Piping multiple functions"},{"location":"using-datasets/#writing-your-own-dataset-class","text":"The hydrafloods.Dataset class can be used to create custom dataset classes for sensors. This is helpful when there is a sensor that will be used often with other datasets using hydrafloods . Here is an example of writing a custom hydrafloods.Dataset class for the GOES16 collection. We will predefine the asset_id argument and define a qa() method to scale data to reflectance and mask poor quality pixels. class Goes16 ( hf . Dataset ): def __init__ ( self , * args , asset_id = \"NOAA/GOES/16/MCMIPF\" , use_qa = True , ** kwargs ): # initialize the parent class super ( Goes16 , self ) . __init__ ( * args , asset_id = asset_id , use_qa = use_qa , ** kwargs ) # list of band names to return with new names old_band_names = [ \"CMI_C01\" , \"green\" , \"CMI_C02\" , \"CMI_C03\" , \"CMI_C05\" , \"CMI_C06\" ] new_band_names = [ \"blue\" , \"green\" , \"red\" , \"nir\" , \"swir1\" , \"swir2\" ] # change the band names to something self . collection = self . collection . select ( old_band_names , new_band_names ) return # define a qa method and wrap in the carry_metadata decorator # retains metadata for each image # qa() will get called on super() if use_qa==True @hf . decorators . keep_attrs def qa ( self , img ): \"\"\"Custom QA masking method for Goes17 data Scales data to reflectance and finds poor quality images add a psuedo-green band using methods from https://doi.org/10.1029/2018EA000379 \"\"\" band_names = img . bandNames () # get scale and offset values scale_properties = band_names . map ( lambda x : ee . String ( x ) . cat ( \"_scale\" )) offset_properties = band_names . map ( lambda x : ee . String ( x ) . cat ( \"_offset\" )) # convert scale/offset values to image scale_img = img . toDictionary ( scale_properties ) . toImage () offset_img = img . toDictionary ( offset_properties ) . toImage () # get qa bands and set 0 to 1 and everything else to 0 qa_img = img . select ( \"^(DQF).*\" ) . Not () # get the actual image data and apply qa mask img = img . select ( \"^(CMI).*\" ) . updateMask ( qa_img ) # scale imagery to reflectance img = img . multiply ( scale_img ) . add ( offset_img ) . multiply ( qa_img ) # compute psuedo green band green_weights = ee . Image . constant ([ 0.45 , 0.45 , 0.1 ]) green_band = ( img . select ([ \"CMI_C01\" , \"CMI_C02\" , \"CMI_C03\" ]) . multiply ( green_weights ) . reduce ( \"sum\" ) . rename ( \"green\" ) ) return img . addBands ( green_band ) # get a GOES collection over the United States us = hf . country_bbox ( \"United States\" ) goes = Goes16 ( us , \"2020-07-28T18:40:18\" , \"2020-07-29T00:00:00\" ) # view the results from the GOES16 collection first_img = goes . collection . first () viz_params = { \"min\" : 0.05 , \"max\" : 0.55 , \"bands\" : \"swir1,nir,green\" , \"gamma\" : 1.5 , \"region\" : us , \"dimensions\" : 1024 , \"crs\" : \"epsg:5070\" } print ( first_img . getThumbURL ( viz_params )) In this example of a custom dataset class for GOES16 imagery, the qa() method definition is more for preprocessing to scale the imagery. A custom cloud/shadow masking workflow can easily be included and applied on the imagery. Now we are ready to use our custom GOES16 imagery with the rest of the hydrafloods functions! More detailed information on the hydrafloods.Dataset class along with it's method fucntionality and arguments can be found in the datasets module API reference.","title":"Writing your own dataset class"},{"location":"utils/","text":"hydrafloods.utils decode_date ( date ) Decodes a date from a command line argument, returning msec since epoch\". Parameters: Name Type Description Default date str date value in a format that can be parsed into datetime object required Returns: Type Description datetime.datetime decoded datetime value Exceptions: Type Description TypeError if string does not conform to a legal date format. Source code in hydrafloods/utils.py def decode_date ( date ): \"\"\"Decodes a date from a command line argument, returning msec since epoch\". args: date (str): date value in a format that can be parsed into datetime object returns: datetime.datetime: decoded datetime value raises: TypeError: if string does not conform to a legal date format. \"\"\" date_formats = [ \"%Y%m %d \" , \"%Y-%m- %d \" , \"%Y-%m- %d T%H:%M:%S\" , \"%Y-%m- %d T%H:%M:%S. %f \" , ] for date_format in date_formats : try : dt = datetime . datetime . strptime ( date , date_format ) return dt except ValueError : continue raise TypeError ( f \"Invalid value for property of type 'date': ' { date } '.\" ) list_gcs_objs ( bucket_path , pattern = None , output_url = False , project = None ) Function to list objects in Google Cloud Storage Bucket Parameters: Name Type Description Default bucket_path str Google Cloud Storage bucket name required pattern str | None regex pattern to search in bucket. Can seach folders by adding folder names (i.e. pattern = 'subfolder/*.txt). If None then will not use search pattern. default = None None output_url bool boolean switch to output google cloud storage http url or google cloud storage object uri. If false will output gcs uri. default = False False project str | None Cloud project name to use when initiation file spec. If None then use default gcloud config. default = None None Returns: Type Description list[str] List of objects in bucket that match pattern Source code in hydrafloods/utils.py def list_gcs_objs ( bucket_path , pattern = None , output_url = False , project = None ): \"\"\"Function to list objects in Google Cloud Storage Bucket args: bucket_path (str): Google Cloud Storage bucket name pattern (str | None, optional): regex pattern to search in bucket. Can seach folders by adding folder names (i.e. pattern = 'subfolder/*.txt). If None then will not use search pattern. default = None output_url (bool, optional): boolean switch to output google cloud storage http url or google cloud storage object uri. If false will output gcs uri. default = False project (str | None): Cloud project name to use when initiation file spec. If None then use default gcloud config. default = None returns: list[str]: List of objects in bucket that match pattern \"\"\" fs = gcsfs . GCSFileSystem ( project = project ) if pattern is not None : bucket_path = ( bucket_path + \"/\" if not bucket_path . endswith ( \"/\" ) else bucket_path ) blobs = fs . glob ( f \" { bucket_path }{ pattern } \" ) else : blobs = fs . ls ( bucket_path ) base = \"https://storage.cloud.google.com/ {0} \" if output_url else \"gs:// {0} \" return [ base . format ( blob ) for blob in blobs ] push_to_ee ( bucket_obj , asset_collection , properties = None , delete_bucket_obj = False ) Helper function to begin ingest process for imagery on GCS to GEE Thinly wraps earthengine upload image Parameters: Name Type Description Default bucket_obj str GCS bucket object to ingest into GEE. Expects that object has mime type of image/tiff required asset_collection str Earth Engine asset collection to push object to required properties list[str] list of properties to set when ingesting files. If None then no properties will be set. default = None None delete_bucket_obj bool boolean switch to delete GCS object once ingested into EE. If set to False then file will remain on GCS. default = False False Source code in hydrafloods/utils.py def push_to_ee ( bucket_obj , asset_collection , properties = None , delete_bucket_obj = False ): \"\"\"Helper function to begin ingest process for imagery on GCS to GEE Thinly wraps `earthengine upload image` args: bucket_obj (str): GCS bucket object to ingest into GEE. Expects that object has mime type of image/tiff asset_collection (str): Earth Engine asset collection to push object to properties (list[str], optional): list of properties to set when ingesting files. If None then no properties will be set. default = None delete_bucket_obj (bool, optional): boolean switch to delete GCS object once ingested into EE. If set to False then file will remain on GCS. default = False \"\"\" name = os . path . basename ( bucket_obj ) . replace ( \".\" , \"_\" ) asset = asset_collection + name pStr = \"\" for i in properties : pStr += \"-- {0} {1} \" . format ( i , properties [ i ]) binPath = os . path . dirname ( sys . executable ) cmd = \" {0} /earthengine upload image --asset_id= {1} {2} {3} \" . format ( binPath , asset , pStr , bucket_obj ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () if properties : pStr = \"\" running = True while running == True : tasks = ee . batch . Task . list () if \"COMPLETED\" in str ( tasks [ 0 ]): running = False elif \"FAILED\" in str ( tasks [ 0 ]): print ( \"EE upload process failed for image {} , check Earth Engine for error\" . format ( bucket_obj ) ) sys . exit ( 1 ) if delete_bucket_obj : cmd = \"gsutil rm {0} \" . format ( bucket_obj ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () return push_to_gcs ( file , bucket_path ) Helper function to copy local files to Google Cloud Storage Thinly wraps gsutil cp command line Parameters: Name Type Description Default file str file path to push to GCS required bucket_path str path on GCS to copy file to required Source code in hydrafloods/utils.py def push_to_gcs ( file , bucket_path ): \"\"\"Helper function to copy local files to Google Cloud Storage Thinly wraps `gsutil cp` command line args: file (str): file path to push to GCS bucket_path (str): path on GCS to copy file to \"\"\" if os . path . exists ( file ): cmd = \"gsutil cp {0} {1} \" . format ( file , bucket_path ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () else : raise ValueError ( 'file \" {0} does not exist' . format ( file )) return","title":"utils module"},{"location":"utils/#hydrafloods.utils","text":"","title":"utils"},{"location":"utils/#hydrafloods.utils.decode_date","text":"Decodes a date from a command line argument, returning msec since epoch\". Parameters: Name Type Description Default date str date value in a format that can be parsed into datetime object required Returns: Type Description datetime.datetime decoded datetime value Exceptions: Type Description TypeError if string does not conform to a legal date format. Source code in hydrafloods/utils.py def decode_date ( date ): \"\"\"Decodes a date from a command line argument, returning msec since epoch\". args: date (str): date value in a format that can be parsed into datetime object returns: datetime.datetime: decoded datetime value raises: TypeError: if string does not conform to a legal date format. \"\"\" date_formats = [ \"%Y%m %d \" , \"%Y-%m- %d \" , \"%Y-%m- %d T%H:%M:%S\" , \"%Y-%m- %d T%H:%M:%S. %f \" , ] for date_format in date_formats : try : dt = datetime . datetime . strptime ( date , date_format ) return dt except ValueError : continue raise TypeError ( f \"Invalid value for property of type 'date': ' { date } '.\" )","title":"decode_date()"},{"location":"utils/#hydrafloods.utils.list_gcs_objs","text":"Function to list objects in Google Cloud Storage Bucket Parameters: Name Type Description Default bucket_path str Google Cloud Storage bucket name required pattern str | None regex pattern to search in bucket. Can seach folders by adding folder names (i.e. pattern = 'subfolder/*.txt). If None then will not use search pattern. default = None None output_url bool boolean switch to output google cloud storage http url or google cloud storage object uri. If false will output gcs uri. default = False False project str | None Cloud project name to use when initiation file spec. If None then use default gcloud config. default = None None Returns: Type Description list[str] List of objects in bucket that match pattern Source code in hydrafloods/utils.py def list_gcs_objs ( bucket_path , pattern = None , output_url = False , project = None ): \"\"\"Function to list objects in Google Cloud Storage Bucket args: bucket_path (str): Google Cloud Storage bucket name pattern (str | None, optional): regex pattern to search in bucket. Can seach folders by adding folder names (i.e. pattern = 'subfolder/*.txt). If None then will not use search pattern. default = None output_url (bool, optional): boolean switch to output google cloud storage http url or google cloud storage object uri. If false will output gcs uri. default = False project (str | None): Cloud project name to use when initiation file spec. If None then use default gcloud config. default = None returns: list[str]: List of objects in bucket that match pattern \"\"\" fs = gcsfs . GCSFileSystem ( project = project ) if pattern is not None : bucket_path = ( bucket_path + \"/\" if not bucket_path . endswith ( \"/\" ) else bucket_path ) blobs = fs . glob ( f \" { bucket_path }{ pattern } \" ) else : blobs = fs . ls ( bucket_path ) base = \"https://storage.cloud.google.com/ {0} \" if output_url else \"gs:// {0} \" return [ base . format ( blob ) for blob in blobs ]","title":"list_gcs_objs()"},{"location":"utils/#hydrafloods.utils.push_to_ee","text":"Helper function to begin ingest process for imagery on GCS to GEE Thinly wraps earthengine upload image Parameters: Name Type Description Default bucket_obj str GCS bucket object to ingest into GEE. Expects that object has mime type of image/tiff required asset_collection str Earth Engine asset collection to push object to required properties list[str] list of properties to set when ingesting files. If None then no properties will be set. default = None None delete_bucket_obj bool boolean switch to delete GCS object once ingested into EE. If set to False then file will remain on GCS. default = False False Source code in hydrafloods/utils.py def push_to_ee ( bucket_obj , asset_collection , properties = None , delete_bucket_obj = False ): \"\"\"Helper function to begin ingest process for imagery on GCS to GEE Thinly wraps `earthengine upload image` args: bucket_obj (str): GCS bucket object to ingest into GEE. Expects that object has mime type of image/tiff asset_collection (str): Earth Engine asset collection to push object to properties (list[str], optional): list of properties to set when ingesting files. If None then no properties will be set. default = None delete_bucket_obj (bool, optional): boolean switch to delete GCS object once ingested into EE. If set to False then file will remain on GCS. default = False \"\"\" name = os . path . basename ( bucket_obj ) . replace ( \".\" , \"_\" ) asset = asset_collection + name pStr = \"\" for i in properties : pStr += \"-- {0} {1} \" . format ( i , properties [ i ]) binPath = os . path . dirname ( sys . executable ) cmd = \" {0} /earthengine upload image --asset_id= {1} {2} {3} \" . format ( binPath , asset , pStr , bucket_obj ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () if properties : pStr = \"\" running = True while running == True : tasks = ee . batch . Task . list () if \"COMPLETED\" in str ( tasks [ 0 ]): running = False elif \"FAILED\" in str ( tasks [ 0 ]): print ( \"EE upload process failed for image {} , check Earth Engine for error\" . format ( bucket_obj ) ) sys . exit ( 1 ) if delete_bucket_obj : cmd = \"gsutil rm {0} \" . format ( bucket_obj ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () return","title":"push_to_ee()"},{"location":"utils/#hydrafloods.utils.push_to_gcs","text":"Helper function to copy local files to Google Cloud Storage Thinly wraps gsutil cp command line Parameters: Name Type Description Default file str file path to push to GCS required bucket_path str path on GCS to copy file to required Source code in hydrafloods/utils.py def push_to_gcs ( file , bucket_path ): \"\"\"Helper function to copy local files to Google Cloud Storage Thinly wraps `gsutil cp` command line args: file (str): file path to push to GCS bucket_path (str): path on GCS to copy file to \"\"\" if os . path . exists ( file ): cmd = \"gsutil cp {0} {1} \" . format ( file , bucket_path ) proc = subprocess . Popen ( cmd , shell = True , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) out , err = proc . communicate () else : raise ValueError ( 'file \" {0} does not exist' . format ( file )) return","title":"push_to_gcs()"},{"location":"workflow-example/","text":"Workflows in the HYDRAFloods sense are related to high-level processes that chain together the lower-level functionality of the package. A defining feature of the workflows are that they are organized in a set of procedures (functions that return None ) that kick off a steps, when chained together result in surface water maps. For example, a workflow can be creating daily surface water maps using a data fusion process. Currently, only one workflow is implemented but it is possible to build more. Daily Surface Water Fusion Process (DSWFP) The DSWFP is based on a few concepts: data fusion, predicting long-term trends in surface water, and refining surface water estimate with short-term trends. The whole process is split into three broad functions to achieve this goal: Export samples of coincident SAR-Optical acquisitions for data fusion Export long-term surface water dynamics using harmonic analysis Predict daily surface water by applying long-term harmonic prediction and correcting for short-term trends hydrafloods has implemented this workflow as a module that users can call functions for each step detailed above. First we need to import the neccesary packages: import ee ee . Initialize () import hydrafloods as hf # import the DSWFP module from hydrafloods.workflows import dswfp 1. Export SAR-Optical fusion samples First step is to sample coincident SAR-Optical data so we can build a machine learning model to fuse the data. This process will kick off a Earth Engine export and result will be a feature collection with information. Keep in mind that this process will take a little while to run (over 30 min) so go grab a cup of coffee while you wait \u2615. # define a geographic region and time period region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-07-01\" # define the asset name of the output output_asset = ( \"users/<your_username>/fusion_sampling_\" + f \" { start_time . replace ( '-' , '' ) } _ { end_time . replace ( '-' , '' ) } \" ) # run the sampling process dswfp . export_fusion_samples ( region , start_time , end_time , stratify_samples = True , output_asset_path = output_asset , ) 2. Export surface water harmonic coefficients After we have exported our samples to fuse optical and SAR data we can run the process to export the surface water harmonic coefficients. This process takes the fusion samples creates a model to convert SAR data to a water index and then calculates changes in interannual surface water (based on the index). Again, this process can take a while depending on how large of an area and time period being processed, sometimes even days \u23f3. region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2015-01-01\" end_time = \"2020-01-01\" input_features = [ \"VV\" , \"VH\" , \"ratio\" , \"ndpi\" ] # SAR features to predict water index target_label = \"mndwi\" # water index to predict fusion_fc = output_asset # the ouput asset name from the earlier block ouput_asset = \"users/<your_username>/surface_water_harmonic_coefficients dswfp . export_surface_water_harmonics ( region , start_time , end_time , feature_names = input_features , label = target_label , fusion_samples = fusion_fc , output_asset_path = None , tile = False ) 3. Export daily water map Now that we have our data exported and ready to use, we can begin predicting daily surface water maps. Here we provide a date that will want to estimate water for and this algorithm will estimate a water index based on the long-term harmonic trend while correcting that with recent observations. This kicks off two exports, one for the fused water index and another for the water map. The final water index is segmented using on of the thresholding algorithms. target_date = \"2020-10-31\" dswfp . export_daily_surface_water ( region , target_date , harmonic_coefs = None , harmonic_collection = None , feature_names = None , label = None , look_back = 30 , output_confidence = True , fusion_samples = None , output_asset_path = None , initial_threshold = 0.1 , thresh_no_data =- 0.1 , tile = False ) Example outputs from the DSWFP workflow highlighting the fusion product and estimated water as compared to and observed Sentinel 1 image. Sentinel 1 2019-12-04 Fused product 2019-12-04 Estimated Water 2019-12-04","title":"Workflow Example"},{"location":"workflow-example/#daily-surface-water-fusion-process-dswfp","text":"The DSWFP is based on a few concepts: data fusion, predicting long-term trends in surface water, and refining surface water estimate with short-term trends. The whole process is split into three broad functions to achieve this goal: Export samples of coincident SAR-Optical acquisitions for data fusion Export long-term surface water dynamics using harmonic analysis Predict daily surface water by applying long-term harmonic prediction and correcting for short-term trends hydrafloods has implemented this workflow as a module that users can call functions for each step detailed above. First we need to import the neccesary packages: import ee ee . Initialize () import hydrafloods as hf # import the DSWFP module from hydrafloods.workflows import dswfp","title":"Daily Surface Water Fusion Process (DSWFP)"},{"location":"workflow-example/#1-export-sar-optical-fusion-samples","text":"First step is to sample coincident SAR-Optical data so we can build a machine learning model to fuse the data. This process will kick off a Earth Engine export and result will be a feature collection with information. Keep in mind that this process will take a little while to run (over 30 min) so go grab a cup of coffee while you wait \u2615. # define a geographic region and time period region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2019-01-01\" end_time = \"2019-07-01\" # define the asset name of the output output_asset = ( \"users/<your_username>/fusion_sampling_\" + f \" { start_time . replace ( '-' , '' ) } _ { end_time . replace ( '-' , '' ) } \" ) # run the sampling process dswfp . export_fusion_samples ( region , start_time , end_time , stratify_samples = True , output_asset_path = output_asset , )","title":"1. Export SAR-Optical fusion samples"},{"location":"workflow-example/#2-export-surface-water-harmonic-coefficients","text":"After we have exported our samples to fuse optical and SAR data we can run the process to export the surface water harmonic coefficients. This process takes the fusion samples creates a model to convert SAR data to a water index and then calculates changes in interannual surface water (based on the index). Again, this process can take a while depending on how large of an area and time period being processed, sometimes even days \u23f3. region = hf . country_bbox ( \"Cambodia\" ) start_time = \"2015-01-01\" end_time = \"2020-01-01\" input_features = [ \"VV\" , \"VH\" , \"ratio\" , \"ndpi\" ] # SAR features to predict water index target_label = \"mndwi\" # water index to predict fusion_fc = output_asset # the ouput asset name from the earlier block ouput_asset = \"users/<your_username>/surface_water_harmonic_coefficients dswfp . export_surface_water_harmonics ( region , start_time , end_time , feature_names = input_features , label = target_label , fusion_samples = fusion_fc , output_asset_path = None , tile = False )","title":"2. Export surface water harmonic coefficients"},{"location":"workflow-example/#3-export-daily-water-map","text":"Now that we have our data exported and ready to use, we can begin predicting daily surface water maps. Here we provide a date that will want to estimate water for and this algorithm will estimate a water index based on the long-term harmonic trend while correcting that with recent observations. This kicks off two exports, one for the fused water index and another for the water map. The final water index is segmented using on of the thresholding algorithms. target_date = \"2020-10-31\" dswfp . export_daily_surface_water ( region , target_date , harmonic_coefs = None , harmonic_collection = None , feature_names = None , label = None , look_back = 30 , output_confidence = True , fusion_samples = None , output_asset_path = None , initial_threshold = 0.1 , thresh_no_data =- 0.1 , tile = False ) Example outputs from the DSWFP workflow highlighting the fusion product and estimated water as compared to and observed Sentinel 1 image. Sentinel 1 2019-12-04 Fused product 2019-12-04 Estimated Water 2019-12-04","title":"3. Export daily water map"}]}